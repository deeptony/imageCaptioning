{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "For all the answers, the source of information is : https://arxiv.org/pdf/1411.4555.pdf\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** The model is comprised of a CNN that computes a low level representation of the images that are passed through it and in turn, this representation is fed into an LSTM cell that is in charge of producing the corresponding natural language description. \n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** The parameters in Resnet where trained by passing through it a series of images that were transformed in a specific way. The provided transformations match the latter. \n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** By looking at the paper I reference above(https://arxiv.org/pdf/1411.4555.pdf), the authors expressed the following regarding the matter:\n",
    "\n",
    "\"The above loss (referring to NLLLoss ) is minimized w.r.t. all the parameters of theLSTM, the top layer of the image embedder CNN and word embeddings We.\"\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** Following with the reference in Question 3, the authors used stochastic gradient descent. I quote: \"At training time, (S, I) is a training example pair, and we optimize the sum of the log probabilities as described in (2) over the whole training set using stochastic gradient descent\". By trial and error, I have found that Adam works better, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing imports first\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=0.89s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 784/414113 [00:00<01:52, 3679.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:32<00:00, 4469.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(inplace), MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "), AvgPool2d(kernel_size=7, stride=1, padding=0)]\n"
     ]
    }
   ],
   "source": [
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 256           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(encoder.embed.parameters()) + list(decoder.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1/6471], Loss: 9.0905, Perplexity: 8870.8137Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2/6471], Loss: 8.9630, Perplexity: 7808.6541Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [3/6471], Loss: 8.7759, Perplexity: 6476.2445Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [4/6471], Loss: 8.5691, Perplexity: 5266.4452Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [5/6471], Loss: 8.1110, Perplexity: 3331.0091Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [6/6471], Loss: 7.9977, Perplexity: 2974.2039Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [7/6471], Loss: 7.0023, Perplexity: 1099.1240Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [8/6471], Loss: 6.1609, Perplexity: 473.8573Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [9/6471], Loss: 5.6411, Perplexity: 281.7710Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [10/6471], Loss: 5.2584, Perplexity: 192.1806Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [11/6471], Loss: 4.8982, Perplexity: 134.0429Shape of captions\n",
      "torch.Size([64, 22, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 23, 256])\n",
      "Epoch [1/3], Step [12/6471], Loss: 5.4545, Perplexity: 233.8194Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [13/6471], Loss: 5.0772, Perplexity: 160.3169Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [14/6471], Loss: 4.9428, Perplexity: 140.1586Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [15/6471], Loss: 5.0297, Perplexity: 152.8867Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [16/6471], Loss: 4.8109, Perplexity: 122.8432Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [17/6471], Loss: 4.9019, Perplexity: 134.5388Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [18/6471], Loss: 4.9647, Perplexity: 143.2711Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [19/6471], Loss: 5.0049, Perplexity: 149.1351Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [20/6471], Loss: 4.8013, Perplexity: 121.6682Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [21/6471], Loss: 4.7813, Perplexity: 119.2600Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [22/6471], Loss: 4.7044, Perplexity: 110.4312Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [23/6471], Loss: 4.9402, Perplexity: 139.7968Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [24/6471], Loss: 4.8003, Perplexity: 121.5464Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [25/6471], Loss: 4.7410, Perplexity: 114.5533Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [26/6471], Loss: 4.8077, Perplexity: 122.4442Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [27/6471], Loss: 4.9544, Perplexity: 141.7960Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [28/6471], Loss: 4.8015, Perplexity: 121.6979Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [29/6471], Loss: 4.6088, Perplexity: 100.3637Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [30/6471], Loss: 4.5226, Perplexity: 92.0764Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [31/6471], Loss: 4.5768, Perplexity: 97.1980Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [32/6471], Loss: 4.4961, Perplexity: 89.6676Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [33/6471], Loss: 4.4673, Perplexity: 87.1232Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [34/6471], Loss: 4.4623, Perplexity: 86.6901Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [35/6471], Loss: 4.4996, Perplexity: 89.9772Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [36/6471], Loss: 4.4127, Perplexity: 82.4956Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [37/6471], Loss: 4.6300, Perplexity: 102.5134Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [38/6471], Loss: 4.4378, Perplexity: 84.5874Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [39/6471], Loss: 5.0723, Perplexity: 159.5422Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [40/6471], Loss: 4.4178, Perplexity: 82.9122Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [41/6471], Loss: 4.7065, Perplexity: 110.6685Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [42/6471], Loss: 4.1966, Perplexity: 66.4611Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [43/6471], Loss: 4.2361, Perplexity: 69.1381Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [44/6471], Loss: 4.1254, Perplexity: 61.8896Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [45/6471], Loss: 4.2721, Perplexity: 71.6685Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [46/6471], Loss: 4.4412, Perplexity: 84.8756Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [47/6471], Loss: 4.2765, Perplexity: 71.9907Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [48/6471], Loss: 4.2796, Perplexity: 72.2112Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [49/6471], Loss: 4.6654, Perplexity: 106.2096Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [50/6471], Loss: 4.1396, Perplexity: 62.7799Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [51/6471], Loss: 4.1430, Perplexity: 62.9906Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [52/6471], Loss: 4.0990, Perplexity: 60.2782Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [53/6471], Loss: 4.1563, Perplexity: 63.8336Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [54/6471], Loss: 4.4944, Perplexity: 89.5150Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [55/6471], Loss: 4.0438, Perplexity: 57.0409Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [56/6471], Loss: 4.0546, Perplexity: 57.6594Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [57/6471], Loss: 4.2397, Perplexity: 69.3860Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [58/6471], Loss: 4.3304, Perplexity: 75.9741Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [59/6471], Loss: 4.3320, Perplexity: 76.0925Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [60/6471], Loss: 4.1013, Perplexity: 60.4159Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [61/6471], Loss: 4.4930, Perplexity: 89.3931Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [62/6471], Loss: 4.2991, Perplexity: 73.6324Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [63/6471], Loss: 3.8544, Perplexity: 47.2023Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [64/6471], Loss: 4.1744, Perplexity: 65.0024Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [65/6471], Loss: 3.9379, Perplexity: 51.3089Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [66/6471], Loss: 4.0500, Perplexity: 57.3959Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [67/6471], Loss: 4.1027, Perplexity: 60.5057Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [68/6471], Loss: 3.9646, Perplexity: 52.6973Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [69/6471], Loss: 4.1455, Perplexity: 63.1490Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [70/6471], Loss: 4.4594, Perplexity: 86.4380Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [71/6471], Loss: 3.9866, Perplexity: 53.8703Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [72/6471], Loss: 3.9748, Perplexity: 53.2375Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [73/6471], Loss: 3.8907, Perplexity: 48.9468Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [74/6471], Loss: 3.8369, Perplexity: 46.3824Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [75/6471], Loss: 3.8292, Perplexity: 46.0264Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [76/6471], Loss: 3.9895, Perplexity: 54.0259Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [77/6471], Loss: 4.6144, Perplexity: 100.9239Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [78/6471], Loss: 4.0341, Perplexity: 56.4939Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [79/6471], Loss: 3.8644, Perplexity: 47.6759Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [80/6471], Loss: 4.5800, Perplexity: 97.5162Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [81/6471], Loss: 4.7674, Perplexity: 117.6103Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [82/6471], Loss: 4.1317, Perplexity: 62.2833Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [83/6471], Loss: 4.0442, Perplexity: 57.0651Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [84/6471], Loss: 3.8532, Perplexity: 47.1447Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [85/6471], Loss: 4.2384, Perplexity: 69.2968Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [86/6471], Loss: 4.1007, Perplexity: 60.3808Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [87/6471], Loss: 4.0526, Perplexity: 57.5485Shape of captions\n",
      "torch.Size([64, 39, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 40, 256])\n",
      "Epoch [1/3], Step [88/6471], Loss: 5.6228, Perplexity: 276.6526Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [89/6471], Loss: 4.0153, Perplexity: 55.4375Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [90/6471], Loss: 3.8935, Perplexity: 49.0819Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [91/6471], Loss: 3.9993, Perplexity: 54.5603Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [92/6471], Loss: 4.1308, Perplexity: 62.2270Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [93/6471], Loss: 4.0384, Perplexity: 56.7356Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [94/6471], Loss: 4.0873, Perplexity: 59.5816Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [95/6471], Loss: 3.9789, Perplexity: 53.4585Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [96/6471], Loss: 4.2456, Perplexity: 69.7977Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [97/6471], Loss: 4.1389, Perplexity: 62.7313Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [98/6471], Loss: 3.8025, Perplexity: 44.8141Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [99/6471], Loss: 3.7595, Perplexity: 42.9278Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [100/6471], Loss: 3.8790, Perplexity: 48.3761\n",
      "Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [101/6471], Loss: 4.2070, Perplexity: 67.1549Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [102/6471], Loss: 4.1207, Perplexity: 61.6047Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [103/6471], Loss: 3.7499, Perplexity: 42.5162Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [104/6471], Loss: 4.0830, Perplexity: 59.3237Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [105/6471], Loss: 4.0326, Perplexity: 56.4071Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [106/6471], Loss: 3.7904, Perplexity: 44.2730Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [107/6471], Loss: 3.9550, Perplexity: 52.1979Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [108/6471], Loss: 4.0154, Perplexity: 55.4440Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [109/6471], Loss: 3.8119, Perplexity: 45.2380Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [110/6471], Loss: 3.9407, Perplexity: 51.4529Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [111/6471], Loss: 3.7258, Perplexity: 41.5053Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [112/6471], Loss: 3.8520, Perplexity: 47.0887Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [113/6471], Loss: 3.8536, Perplexity: 47.1614Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [114/6471], Loss: 4.2621, Perplexity: 70.9566Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [115/6471], Loss: 3.8783, Perplexity: 48.3398Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [116/6471], Loss: 4.2102, Perplexity: 67.3712Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [117/6471], Loss: 3.7933, Perplexity: 44.4008Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [118/6471], Loss: 3.7744, Perplexity: 43.5729Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [119/6471], Loss: 3.6699, Perplexity: 39.2499Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [120/6471], Loss: 3.6961, Perplexity: 40.2895Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [121/6471], Loss: 3.7839, Perplexity: 43.9884Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [122/6471], Loss: 3.9105, Perplexity: 49.9220Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [123/6471], Loss: 3.6238, Perplexity: 37.4809Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [124/6471], Loss: 3.8410, Perplexity: 46.5729Shape of captions\n",
      "torch.Size([64, 25, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 26, 256])\n",
      "Epoch [1/3], Step [125/6471], Loss: 4.6644, Perplexity: 106.0986Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [126/6471], Loss: 3.7358, Perplexity: 41.9201Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [127/6471], Loss: 3.9762, Perplexity: 53.3150Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [128/6471], Loss: 3.9288, Perplexity: 50.8471Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [129/6471], Loss: 3.7888, Perplexity: 44.2041Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [130/6471], Loss: 4.1771, Perplexity: 65.1771Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [131/6471], Loss: 3.7769, Perplexity: 43.6807Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [132/6471], Loss: 3.9469, Perplexity: 51.7758Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [133/6471], Loss: 3.7114, Perplexity: 40.9116Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [134/6471], Loss: 3.5973, Perplexity: 36.5011Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [135/6471], Loss: 3.6722, Perplexity: 39.3403Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [136/6471], Loss: 3.8085, Perplexity: 45.0808Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [137/6471], Loss: 3.6230, Perplexity: 37.4485Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [138/6471], Loss: 3.8074, Perplexity: 45.0316Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [139/6471], Loss: 3.8799, Perplexity: 48.4170Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [140/6471], Loss: 3.6266, Perplexity: 37.5864Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [141/6471], Loss: 4.0165, Perplexity: 55.5069Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [142/6471], Loss: 3.7348, Perplexity: 41.8778Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [143/6471], Loss: 3.7576, Perplexity: 42.8476Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [144/6471], Loss: 3.5708, Perplexity: 35.5441Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [145/6471], Loss: 3.8724, Perplexity: 48.0564Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [146/6471], Loss: 3.9078, Perplexity: 49.7913Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [147/6471], Loss: 3.7049, Perplexity: 40.6452Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [148/6471], Loss: 3.7993, Perplexity: 44.6690Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [149/6471], Loss: 3.5537, Perplexity: 34.9429Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [150/6471], Loss: 3.6281, Perplexity: 37.6407Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [151/6471], Loss: 3.6445, Perplexity: 38.2630Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [152/6471], Loss: 3.5900, Perplexity: 36.2325Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [153/6471], Loss: 3.8016, Perplexity: 44.7731Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [154/6471], Loss: 3.6081, Perplexity: 36.8960Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [155/6471], Loss: 3.5973, Perplexity: 36.4992Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [156/6471], Loss: 3.6351, Perplexity: 37.9060Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [157/6471], Loss: 3.9585, Perplexity: 52.3775Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [158/6471], Loss: 3.5697, Perplexity: 35.5075Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [159/6471], Loss: 3.5957, Perplexity: 36.4396Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [160/6471], Loss: 3.5471, Perplexity: 34.7137Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [161/6471], Loss: 4.1381, Perplexity: 62.6849Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [162/6471], Loss: 3.8992, Perplexity: 49.3639Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [163/6471], Loss: 3.6923, Perplexity: 40.1388Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [164/6471], Loss: 3.8835, Perplexity: 48.5932Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [165/6471], Loss: 3.5626, Perplexity: 35.2553Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [166/6471], Loss: 3.5233, Perplexity: 33.8966Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [167/6471], Loss: 4.2125, Perplexity: 67.5222Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [168/6471], Loss: 3.7127, Perplexity: 40.9651Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [169/6471], Loss: 3.7794, Perplexity: 43.7890Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [170/6471], Loss: 3.6079, Perplexity: 36.8877Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [171/6471], Loss: 4.0932, Perplexity: 59.9290Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [172/6471], Loss: 3.5518, Perplexity: 34.8771Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [173/6471], Loss: 3.6617, Perplexity: 38.9264Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [174/6471], Loss: 3.6200, Perplexity: 37.3391Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [175/6471], Loss: 3.8408, Perplexity: 46.5636Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [176/6471], Loss: 3.4613, Perplexity: 31.8598Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [177/6471], Loss: 3.7186, Perplexity: 41.2051Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [178/6471], Loss: 3.6880, Perplexity: 39.9652Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [179/6471], Loss: 3.8655, Perplexity: 47.7261Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [180/6471], Loss: 3.7821, Perplexity: 43.9062Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [181/6471], Loss: 3.7794, Perplexity: 43.7916Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [182/6471], Loss: 3.8073, Perplexity: 45.0298Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [183/6471], Loss: 3.5044, Perplexity: 33.2623Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [184/6471], Loss: 3.5099, Perplexity: 33.4457Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [185/6471], Loss: 3.8265, Perplexity: 45.9028Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [186/6471], Loss: 3.7889, Perplexity: 44.2056Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [187/6471], Loss: 3.8600, Perplexity: 47.4650Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [188/6471], Loss: 3.4138, Perplexity: 30.3806Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [189/6471], Loss: 3.6349, Perplexity: 37.8971Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [190/6471], Loss: 3.5004, Perplexity: 33.1293Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [191/6471], Loss: 4.1699, Perplexity: 64.7118Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [192/6471], Loss: 3.3578, Perplexity: 28.7261Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [193/6471], Loss: 3.5355, Perplexity: 34.3133Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [194/6471], Loss: 3.4842, Perplexity: 32.5977Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [195/6471], Loss: 3.4072, Perplexity: 30.1810Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [196/6471], Loss: 3.4899, Perplexity: 32.7831Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [197/6471], Loss: 3.4885, Perplexity: 32.7369Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [198/6471], Loss: 3.7488, Perplexity: 42.4687Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [199/6471], Loss: 3.6873, Perplexity: 39.9376Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [200/6471], Loss: 3.5803, Perplexity: 35.8854\n",
      "Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [201/6471], Loss: 3.5392, Perplexity: 34.4411Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [202/6471], Loss: 3.7466, Perplexity: 42.3761Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [203/6471], Loss: 3.5337, Perplexity: 34.2493Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [204/6471], Loss: 3.6159, Perplexity: 37.1861Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [205/6471], Loss: 3.8214, Perplexity: 45.6700Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [206/6471], Loss: 3.4525, Perplexity: 31.5794Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [207/6471], Loss: 3.4130, Perplexity: 30.3567Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [208/6471], Loss: 3.5454, Perplexity: 34.6535Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [209/6471], Loss: 3.7655, Perplexity: 43.1833Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [210/6471], Loss: 3.7451, Perplexity: 42.3113Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [211/6471], Loss: 3.6323, Perplexity: 37.7984Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [212/6471], Loss: 3.4490, Perplexity: 31.4678Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [213/6471], Loss: 3.3673, Perplexity: 29.0007Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [214/6471], Loss: 3.5194, Perplexity: 33.7657Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [215/6471], Loss: 3.4163, Perplexity: 30.4551Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [216/6471], Loss: 3.4052, Perplexity: 30.1191Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [217/6471], Loss: 3.4497, Perplexity: 31.4898Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [218/6471], Loss: 3.2866, Perplexity: 26.7519Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [219/6471], Loss: 3.7794, Perplexity: 43.7893Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [220/6471], Loss: 3.5825, Perplexity: 35.9639Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [221/6471], Loss: 3.4068, Perplexity: 30.1682Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [222/6471], Loss: 3.5632, Perplexity: 35.2761Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [223/6471], Loss: 3.4687, Perplexity: 32.0940Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [224/6471], Loss: 3.6767, Perplexity: 39.5173Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [225/6471], Loss: 3.5625, Perplexity: 35.2503Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [226/6471], Loss: 3.4524, Perplexity: 31.5752Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [227/6471], Loss: 3.6348, Perplexity: 37.8959Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [228/6471], Loss: 3.4010, Perplexity: 29.9947Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [229/6471], Loss: 3.3825, Perplexity: 29.4439Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [230/6471], Loss: 3.8823, Perplexity: 48.5367Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [231/6471], Loss: 3.5813, Perplexity: 35.9209Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [232/6471], Loss: 4.0766, Perplexity: 58.9453Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [233/6471], Loss: 3.4454, Perplexity: 31.3567Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [234/6471], Loss: 3.5927, Perplexity: 36.3316Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [235/6471], Loss: 3.8041, Perplexity: 44.8854Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [236/6471], Loss: 3.6863, Perplexity: 39.8989Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [237/6471], Loss: 3.5188, Perplexity: 33.7436Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [238/6471], Loss: 3.3333, Perplexity: 28.0303Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [239/6471], Loss: 3.3042, Perplexity: 27.2256Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [240/6471], Loss: 3.3315, Perplexity: 27.9795Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [241/6471], Loss: 3.6240, Perplexity: 37.4885Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [242/6471], Loss: 3.4965, Perplexity: 33.0012Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [243/6471], Loss: 3.6161, Perplexity: 37.1931Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [244/6471], Loss: 3.5028, Perplexity: 33.2091Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [245/6471], Loss: 3.6470, Perplexity: 38.3597Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [246/6471], Loss: 3.4337, Perplexity: 30.9911Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [247/6471], Loss: 3.3580, Perplexity: 28.7313Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [248/6471], Loss: 3.8138, Perplexity: 45.3228Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [249/6471], Loss: 3.1973, Perplexity: 24.4654Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [250/6471], Loss: 3.6546, Perplexity: 38.6517Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [251/6471], Loss: 3.5185, Perplexity: 33.7329Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [252/6471], Loss: 3.4203, Perplexity: 30.5798Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [253/6471], Loss: 3.6962, Perplexity: 40.2946Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [254/6471], Loss: 3.9163, Perplexity: 50.2142Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [255/6471], Loss: 3.2262, Perplexity: 25.1831Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [256/6471], Loss: 3.3950, Perplexity: 29.8134Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [257/6471], Loss: 3.3943, Perplexity: 29.7951Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [258/6471], Loss: 3.6294, Perplexity: 37.6902Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [259/6471], Loss: 3.9883, Perplexity: 53.9609Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [260/6471], Loss: 3.3824, Perplexity: 29.4412Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [261/6471], Loss: 3.5151, Perplexity: 33.6199Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [262/6471], Loss: 3.6144, Perplexity: 37.1274Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [263/6471], Loss: 3.6092, Perplexity: 36.9371Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [264/6471], Loss: 3.4437, Perplexity: 31.3034Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [265/6471], Loss: 3.5639, Perplexity: 35.2998Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [266/6471], Loss: 3.5642, Perplexity: 35.3097Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [267/6471], Loss: 3.5992, Perplexity: 36.5707Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [268/6471], Loss: 3.3674, Perplexity: 29.0040Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [269/6471], Loss: 3.4228, Perplexity: 30.6545Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [270/6471], Loss: 3.7776, Perplexity: 43.7115Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [271/6471], Loss: 3.3179, Perplexity: 27.6036Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [272/6471], Loss: 3.5908, Perplexity: 36.2633Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [273/6471], Loss: 3.4779, Perplexity: 32.3927Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [274/6471], Loss: 3.7837, Perplexity: 43.9804Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [275/6471], Loss: 3.7434, Perplexity: 42.2393Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [276/6471], Loss: 3.3800, Perplexity: 29.3711Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [277/6471], Loss: 3.4078, Perplexity: 30.1990Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [278/6471], Loss: 3.2807, Perplexity: 26.5936Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [279/6471], Loss: 3.4868, Perplexity: 32.6818Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [280/6471], Loss: 3.3629, Perplexity: 28.8735Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [281/6471], Loss: 3.4309, Perplexity: 30.9030Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [282/6471], Loss: 3.6207, Perplexity: 37.3631Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [283/6471], Loss: 3.5172, Perplexity: 33.6890Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [284/6471], Loss: 3.5050, Perplexity: 33.2814Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [285/6471], Loss: 3.5758, Perplexity: 35.7222Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [286/6471], Loss: 3.5837, Perplexity: 36.0048Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [287/6471], Loss: 3.4582, Perplexity: 31.7592Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [288/6471], Loss: 3.5137, Perplexity: 33.5719Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [289/6471], Loss: 3.3564, Perplexity: 28.6861Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [290/6471], Loss: 3.5235, Perplexity: 33.9028Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [291/6471], Loss: 3.7323, Perplexity: 41.7741Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [292/6471], Loss: 3.6020, Perplexity: 36.6700Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [293/6471], Loss: 3.3174, Perplexity: 27.5877Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [294/6471], Loss: 3.3812, Perplexity: 29.4059Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [295/6471], Loss: 3.4865, Perplexity: 32.6700Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [296/6471], Loss: 3.5542, Perplexity: 34.9585Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [297/6471], Loss: 3.9157, Perplexity: 50.1858Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [298/6471], Loss: 3.4270, Perplexity: 30.7856Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [299/6471], Loss: 3.5099, Perplexity: 33.4442Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.7214, Perplexity: 41.3210\n",
      "Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [301/6471], Loss: 3.5210, Perplexity: 33.8169Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [302/6471], Loss: 3.3810, Perplexity: 29.4015Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [303/6471], Loss: 3.5503, Perplexity: 34.8244Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [304/6471], Loss: 3.3915, Perplexity: 29.7113Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [305/6471], Loss: 3.4556, Perplexity: 31.6774Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [306/6471], Loss: 3.4707, Perplexity: 32.1579Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [307/6471], Loss: 3.2577, Perplexity: 25.9898Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [308/6471], Loss: 3.6182, Perplexity: 37.2717Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [309/6471], Loss: 3.3381, Perplexity: 28.1646Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [310/6471], Loss: 3.7755, Perplexity: 43.6177Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [311/6471], Loss: 3.4479, Perplexity: 31.4346Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [312/6471], Loss: 3.3319, Perplexity: 27.9913Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [313/6471], Loss: 3.5148, Perplexity: 33.6090Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [314/6471], Loss: 3.6119, Perplexity: 37.0363Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [315/6471], Loss: 3.3628, Perplexity: 28.8685Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [316/6471], Loss: 3.1998, Perplexity: 24.5269Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [317/6471], Loss: 3.3645, Perplexity: 28.9179Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [318/6471], Loss: 3.5154, Perplexity: 33.6282Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [319/6471], Loss: 3.2849, Perplexity: 26.7068Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [320/6471], Loss: 3.3249, Perplexity: 27.7959Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [321/6471], Loss: 3.3107, Perplexity: 27.4033Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [322/6471], Loss: 3.6860, Perplexity: 39.8865Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [323/6471], Loss: 3.4758, Perplexity: 32.3240Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [324/6471], Loss: 3.1763, Perplexity: 23.9568Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [325/6471], Loss: 3.8543, Perplexity: 47.1971Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [326/6471], Loss: 3.3521, Perplexity: 28.5619Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [327/6471], Loss: 3.1103, Perplexity: 22.4276Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [328/6471], Loss: 3.9483, Perplexity: 51.8450Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [329/6471], Loss: 3.0581, Perplexity: 21.2875Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [330/6471], Loss: 3.2570, Perplexity: 25.9704Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [331/6471], Loss: 3.1568, Perplexity: 23.4955Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [332/6471], Loss: 3.3043, Perplexity: 27.2294Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [333/6471], Loss: 3.0440, Perplexity: 20.9898Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [334/6471], Loss: 3.4157, Perplexity: 30.4397Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [335/6471], Loss: 3.4946, Perplexity: 32.9371Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [336/6471], Loss: 3.2244, Perplexity: 25.1391Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [337/6471], Loss: 3.5399, Perplexity: 34.4621Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [338/6471], Loss: 3.4286, Perplexity: 30.8328Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [339/6471], Loss: 3.5056, Perplexity: 33.3005Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [340/6471], Loss: 3.1048, Perplexity: 22.3055Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [341/6471], Loss: 3.2879, Perplexity: 26.7872Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [342/6471], Loss: 3.1993, Perplexity: 24.5163Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [343/6471], Loss: 3.5016, Perplexity: 33.1700Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [344/6471], Loss: 3.4778, Perplexity: 32.3899Shape of captions\n",
      "torch.Size([64, 22, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 23, 256])\n",
      "Epoch [1/3], Step [345/6471], Loss: 4.1788, Perplexity: 65.2905Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [346/6471], Loss: 3.1976, Perplexity: 24.4734Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [347/6471], Loss: 3.2167, Perplexity: 24.9454Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [348/6471], Loss: 3.3369, Perplexity: 28.1331Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [349/6471], Loss: 3.3367, Perplexity: 28.1249Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [350/6471], Loss: 3.3979, Perplexity: 29.9002Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [351/6471], Loss: 3.5204, Perplexity: 33.7980Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [352/6471], Loss: 3.3375, Perplexity: 28.1488Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [353/6471], Loss: 3.3649, Perplexity: 28.9311Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [354/6471], Loss: 3.6129, Perplexity: 37.0728Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [355/6471], Loss: 3.1838, Perplexity: 24.1389Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [356/6471], Loss: 3.2617, Perplexity: 26.0942Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [357/6471], Loss: 3.1214, Perplexity: 22.6778Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [358/6471], Loss: 3.2294, Perplexity: 25.2639Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [359/6471], Loss: 3.3276, Perplexity: 27.8714Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [360/6471], Loss: 3.2760, Perplexity: 26.4700Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [361/6471], Loss: 3.2102, Perplexity: 24.7848Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [362/6471], Loss: 3.4123, Perplexity: 30.3359Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [363/6471], Loss: 3.1727, Perplexity: 23.8718Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [364/6471], Loss: 3.2562, Perplexity: 25.9516Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [365/6471], Loss: 3.2188, Perplexity: 24.9970Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [366/6471], Loss: 3.2254, Perplexity: 25.1646Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [367/6471], Loss: 3.3510, Perplexity: 28.5307Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [368/6471], Loss: 2.9005, Perplexity: 18.1831Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [369/6471], Loss: 3.3290, Perplexity: 27.9096Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [370/6471], Loss: 3.1896, Perplexity: 24.2776Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [371/6471], Loss: 3.1629, Perplexity: 23.6384Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [372/6471], Loss: 3.4684, Perplexity: 32.0865Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [373/6471], Loss: 3.3024, Perplexity: 27.1791Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [374/6471], Loss: 3.3350, Perplexity: 28.0772Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [375/6471], Loss: 3.5021, Perplexity: 33.1844Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [376/6471], Loss: 3.4655, Perplexity: 31.9935Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [377/6471], Loss: 3.4045, Perplexity: 30.0993Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [378/6471], Loss: 3.4391, Perplexity: 31.1599Shape of captions\n",
      "torch.Size([64, 37, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 38, 256])\n",
      "Epoch [1/3], Step [379/6471], Loss: 5.3382, Perplexity: 208.1473Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [380/6471], Loss: 3.2051, Perplexity: 24.6569Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [381/6471], Loss: 3.1640, Perplexity: 23.6642Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [382/6471], Loss: 3.3412, Perplexity: 28.2543Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [383/6471], Loss: 3.3618, Perplexity: 28.8424Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [384/6471], Loss: 3.3238, Perplexity: 27.7644Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [385/6471], Loss: 3.3030, Perplexity: 27.1937Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [386/6471], Loss: 3.2540, Perplexity: 25.8926Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [387/6471], Loss: 3.1896, Perplexity: 24.2786Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [388/6471], Loss: 3.3360, Perplexity: 28.1055Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [389/6471], Loss: 3.1600, Perplexity: 23.5702Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [390/6471], Loss: 3.2391, Perplexity: 25.5109Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [391/6471], Loss: 3.2938, Perplexity: 26.9463Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [392/6471], Loss: 3.4512, Perplexity: 31.5372Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [393/6471], Loss: 3.0631, Perplexity: 21.3929Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [394/6471], Loss: 3.2687, Perplexity: 26.2762Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [395/6471], Loss: 2.9205, Perplexity: 18.5503Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [396/6471], Loss: 3.0759, Perplexity: 21.6696Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [397/6471], Loss: 3.3033, Perplexity: 27.2019Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [398/6471], Loss: 4.0796, Perplexity: 59.1242Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [399/6471], Loss: 3.0891, Perplexity: 21.9565Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [400/6471], Loss: 3.1495, Perplexity: 23.3246\n",
      "Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [401/6471], Loss: 3.3012, Perplexity: 27.1457Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [402/6471], Loss: 3.3602, Perplexity: 28.7962Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [403/6471], Loss: 3.2392, Perplexity: 25.5132Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [404/6471], Loss: 3.4197, Perplexity: 30.5597Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [405/6471], Loss: 3.4490, Perplexity: 31.4679Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [406/6471], Loss: 3.0593, Perplexity: 21.3119Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [407/6471], Loss: 3.3663, Perplexity: 28.9700Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [408/6471], Loss: 3.2650, Perplexity: 26.1799Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [409/6471], Loss: 3.2420, Perplexity: 25.5853Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [410/6471], Loss: 3.2855, Perplexity: 26.7229Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [411/6471], Loss: 3.2509, Perplexity: 25.8133Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [412/6471], Loss: 3.5314, Perplexity: 34.1702Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [413/6471], Loss: 3.1252, Perplexity: 22.7650Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [414/6471], Loss: 3.0760, Perplexity: 21.6726Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [415/6471], Loss: 3.2851, Perplexity: 26.7114Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [416/6471], Loss: 3.7744, Perplexity: 43.5705Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [417/6471], Loss: 3.0331, Perplexity: 20.7625Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [418/6471], Loss: 3.3384, Perplexity: 28.1741Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [419/6471], Loss: 3.1292, Perplexity: 22.8548Shape of captions\n",
      "torch.Size([64, 22, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 23, 256])\n",
      "Epoch [1/3], Step [420/6471], Loss: 3.9077, Perplexity: 49.7847Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [421/6471], Loss: 3.3047, Perplexity: 27.2416Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [422/6471], Loss: 3.3035, Perplexity: 27.2078Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [423/6471], Loss: 3.3220, Perplexity: 27.7148Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [424/6471], Loss: 2.9450, Perplexity: 19.0111Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [425/6471], Loss: 3.2151, Perplexity: 24.9053Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [426/6471], Loss: 3.4352, Perplexity: 31.0385Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [427/6471], Loss: 3.2696, Perplexity: 26.2999Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [428/6471], Loss: 3.5912, Perplexity: 36.2770Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [429/6471], Loss: 3.5915, Perplexity: 36.2884Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [430/6471], Loss: 3.1967, Perplexity: 24.4509Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [431/6471], Loss: 3.1671, Perplexity: 23.7393Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [432/6471], Loss: 3.6881, Perplexity: 39.9675Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [433/6471], Loss: 3.1106, Perplexity: 22.4338Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [434/6471], Loss: 3.2509, Perplexity: 25.8127Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [435/6471], Loss: 3.1923, Perplexity: 24.3436Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [436/6471], Loss: 3.2266, Perplexity: 25.1945Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [437/6471], Loss: 3.3457, Perplexity: 28.3809Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [438/6471], Loss: 3.2819, Perplexity: 26.6252Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [439/6471], Loss: 3.3029, Perplexity: 27.1916Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [440/6471], Loss: 3.4770, Perplexity: 32.3634Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [441/6471], Loss: 3.6196, Perplexity: 37.3227Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [442/6471], Loss: 3.2147, Perplexity: 24.8956Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [443/6471], Loss: 3.3520, Perplexity: 28.5596Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [444/6471], Loss: 3.2483, Perplexity: 25.7460Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [445/6471], Loss: 2.9553, Perplexity: 19.2075Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [446/6471], Loss: 3.5025, Perplexity: 33.1991Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [447/6471], Loss: 3.2248, Perplexity: 25.1490Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [448/6471], Loss: 3.0698, Perplexity: 21.5378Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [449/6471], Loss: 3.3157, Perplexity: 27.5419Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [450/6471], Loss: 3.2298, Perplexity: 25.2739Shape of captions\n",
      "torch.Size([64, 22, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 23, 256])\n",
      "Epoch [1/3], Step [451/6471], Loss: 4.0181, Perplexity: 55.5967Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [452/6471], Loss: 3.3876, Perplexity: 29.5960Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [453/6471], Loss: 3.4873, Perplexity: 32.6989Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [454/6471], Loss: 3.3798, Perplexity: 29.3646Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [455/6471], Loss: 3.0533, Perplexity: 21.1841Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [456/6471], Loss: 3.8358, Perplexity: 46.3289Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [457/6471], Loss: 3.1068, Perplexity: 22.3496Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [458/6471], Loss: 3.1211, Perplexity: 22.6707Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [459/6471], Loss: 3.1946, Perplexity: 24.4014Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [460/6471], Loss: 3.0882, Perplexity: 21.9366Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [461/6471], Loss: 3.1524, Perplexity: 23.3915Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [462/6471], Loss: 3.4959, Perplexity: 32.9800Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [463/6471], Loss: 3.3630, Perplexity: 28.8750Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [464/6471], Loss: 3.4443, Perplexity: 31.3211Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [465/6471], Loss: 3.4083, Perplexity: 30.2153Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [466/6471], Loss: 3.2302, Perplexity: 25.2837Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [467/6471], Loss: 3.3074, Perplexity: 27.3131Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [468/6471], Loss: 3.1159, Perplexity: 22.5527Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [469/6471], Loss: 3.2165, Perplexity: 24.9412Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [470/6471], Loss: 3.2258, Perplexity: 25.1739Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [471/6471], Loss: 3.1442, Perplexity: 23.2014Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [472/6471], Loss: 3.0754, Perplexity: 21.6590Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [473/6471], Loss: 3.2293, Perplexity: 25.2616Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [474/6471], Loss: 3.4008, Perplexity: 29.9870Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [475/6471], Loss: 3.6578, Perplexity: 38.7772Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [476/6471], Loss: 3.4192, Perplexity: 30.5463Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [477/6471], Loss: 3.7792, Perplexity: 43.7799Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [478/6471], Loss: 3.3308, Perplexity: 27.9614Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [479/6471], Loss: 3.0767, Perplexity: 21.6868Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [480/6471], Loss: 2.9937, Perplexity: 19.9599Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [481/6471], Loss: 3.3068, Perplexity: 27.2990Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [482/6471], Loss: 3.7224, Perplexity: 41.3629Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [483/6471], Loss: 3.2554, Perplexity: 25.9292Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [484/6471], Loss: 2.9910, Perplexity: 19.9049Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [485/6471], Loss: 3.2322, Perplexity: 25.3343Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [486/6471], Loss: 3.2332, Perplexity: 25.3607Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [487/6471], Loss: 3.1651, Perplexity: 23.6920Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [488/6471], Loss: 2.9358, Perplexity: 18.8369Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [489/6471], Loss: 3.1510, Perplexity: 23.3592Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [490/6471], Loss: 3.6680, Perplexity: 39.1729Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [491/6471], Loss: 3.0643, Perplexity: 21.4198Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [492/6471], Loss: 2.9039, Perplexity: 18.2449Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [493/6471], Loss: 3.1689, Perplexity: 23.7811Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [494/6471], Loss: 3.2902, Perplexity: 26.8491Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [495/6471], Loss: 2.8414, Perplexity: 17.1394Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [496/6471], Loss: 3.2692, Perplexity: 26.2912Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [497/6471], Loss: 3.1142, Perplexity: 22.5157Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [498/6471], Loss: 2.9300, Perplexity: 18.7273Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [499/6471], Loss: 3.0879, Perplexity: 21.9313Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [500/6471], Loss: 3.2098, Perplexity: 24.7748\n",
      "Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [501/6471], Loss: 3.3003, Perplexity: 27.1219Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [502/6471], Loss: 3.1451, Perplexity: 23.2213Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [503/6471], Loss: 3.2643, Perplexity: 26.1614Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [504/6471], Loss: 3.3269, Perplexity: 27.8506Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [505/6471], Loss: 3.1182, Perplexity: 22.6061Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [506/6471], Loss: 3.0469, Perplexity: 21.0495Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [507/6471], Loss: 3.0892, Perplexity: 21.9602Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [508/6471], Loss: 3.1257, Perplexity: 22.7768Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [509/6471], Loss: 3.0465, Perplexity: 21.0420Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [510/6471], Loss: 3.2308, Perplexity: 25.2988Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [511/6471], Loss: 3.5964, Perplexity: 36.4662Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [512/6471], Loss: 3.0731, Perplexity: 21.6096Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [513/6471], Loss: 3.1146, Perplexity: 22.5242Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [514/6471], Loss: 3.0139, Perplexity: 20.3658Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [515/6471], Loss: 3.1850, Perplexity: 24.1666Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [516/6471], Loss: 2.8630, Perplexity: 17.5148Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [517/6471], Loss: 3.4559, Perplexity: 31.6870Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [518/6471], Loss: 3.7363, Perplexity: 41.9415Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [519/6471], Loss: 3.1724, Perplexity: 23.8636Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [520/6471], Loss: 3.0814, Perplexity: 21.7895Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [521/6471], Loss: 3.0781, Perplexity: 21.7165Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [522/6471], Loss: 2.8494, Perplexity: 17.2770Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [523/6471], Loss: 3.0585, Perplexity: 21.2954Shape of captions\n",
      "torch.Size([64, 21, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 22, 256])\n",
      "Epoch [1/3], Step [524/6471], Loss: 3.8701, Perplexity: 47.9480Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [525/6471], Loss: 2.8584, Perplexity: 17.4332Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [526/6471], Loss: 3.1289, Perplexity: 22.8494Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [527/6471], Loss: 3.0958, Perplexity: 22.1051Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [528/6471], Loss: 3.1001, Perplexity: 22.2000Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [529/6471], Loss: 3.2297, Perplexity: 25.2724Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [530/6471], Loss: 3.4132, Perplexity: 30.3617Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [531/6471], Loss: 3.5315, Perplexity: 34.1769Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [532/6471], Loss: 3.0857, Perplexity: 21.8827Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [533/6471], Loss: 3.0153, Perplexity: 20.3959Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [534/6471], Loss: 3.1620, Perplexity: 23.6176Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [535/6471], Loss: 3.1798, Perplexity: 24.0412Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [536/6471], Loss: 3.1274, Perplexity: 22.8156Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [537/6471], Loss: 2.9932, Perplexity: 19.9488Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [538/6471], Loss: 3.3001, Perplexity: 27.1147Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [539/6471], Loss: 3.1473, Perplexity: 23.2727Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [540/6471], Loss: 3.0858, Perplexity: 21.8843Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [541/6471], Loss: 3.1064, Perplexity: 22.3407Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [542/6471], Loss: 3.1482, Perplexity: 23.2931Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [543/6471], Loss: 2.9007, Perplexity: 18.1873Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [544/6471], Loss: 3.0334, Perplexity: 20.7675Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [545/6471], Loss: 2.9836, Perplexity: 19.7595Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [546/6471], Loss: 3.0865, Perplexity: 21.8995Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [547/6471], Loss: 3.0968, Perplexity: 22.1270Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [548/6471], Loss: 3.1970, Perplexity: 24.4602Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [549/6471], Loss: 3.7007, Perplexity: 40.4774Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [550/6471], Loss: 3.0821, Perplexity: 21.8035Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [551/6471], Loss: 3.7340, Perplexity: 41.8460Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [552/6471], Loss: 3.0898, Perplexity: 21.9732Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [553/6471], Loss: 3.1685, Perplexity: 23.7712Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [554/6471], Loss: 3.6740, Perplexity: 39.4079Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [555/6471], Loss: 3.1571, Perplexity: 23.5023Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [556/6471], Loss: 3.0031, Perplexity: 20.1487Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [557/6471], Loss: 3.4009, Perplexity: 29.9911Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [558/6471], Loss: 3.3966, Perplexity: 29.8630Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [559/6471], Loss: 2.9845, Perplexity: 19.7775Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [560/6471], Loss: 3.0996, Perplexity: 22.1893Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [561/6471], Loss: 3.0188, Perplexity: 20.4677Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [562/6471], Loss: 3.1546, Perplexity: 23.4438Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [563/6471], Loss: 3.1463, Perplexity: 23.2501Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [564/6471], Loss: 2.8990, Perplexity: 18.1562Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [565/6471], Loss: 3.1936, Perplexity: 24.3755Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [566/6471], Loss: 3.0085, Perplexity: 20.2570Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [567/6471], Loss: 3.4836, Perplexity: 32.5779Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [568/6471], Loss: 3.1015, Perplexity: 22.2311Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [569/6471], Loss: 3.2085, Perplexity: 24.7408Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [570/6471], Loss: 3.2251, Perplexity: 25.1572Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [571/6471], Loss: 3.0438, Perplexity: 20.9851Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [572/6471], Loss: 3.2445, Perplexity: 25.6481Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [573/6471], Loss: 3.2514, Perplexity: 25.8271Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [574/6471], Loss: 3.2658, Perplexity: 26.2007Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [575/6471], Loss: 3.2637, Perplexity: 26.1458Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [576/6471], Loss: 3.1094, Perplexity: 22.4076Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [577/6471], Loss: 3.1726, Perplexity: 23.8695Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [578/6471], Loss: 3.1321, Perplexity: 22.9221Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [579/6471], Loss: 3.4398, Perplexity: 31.1793Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [580/6471], Loss: 3.1671, Perplexity: 23.7397Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [581/6471], Loss: 2.9933, Perplexity: 19.9511Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [582/6471], Loss: 3.1981, Perplexity: 24.4852Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [583/6471], Loss: 2.9147, Perplexity: 18.4432Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [584/6471], Loss: 3.1828, Perplexity: 24.1148Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [585/6471], Loss: 3.1902, Perplexity: 24.2932Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [586/6471], Loss: 2.9652, Perplexity: 19.3983Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [587/6471], Loss: 3.6486, Perplexity: 38.4211Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [588/6471], Loss: 3.3070, Perplexity: 27.3020Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [589/6471], Loss: 3.0583, Perplexity: 21.2908Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [590/6471], Loss: 2.8267, Perplexity: 16.8892Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [591/6471], Loss: 3.0882, Perplexity: 21.9369Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [592/6471], Loss: 3.3699, Perplexity: 29.0764Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [593/6471], Loss: 2.8245, Perplexity: 16.8525Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [594/6471], Loss: 3.1422, Perplexity: 23.1537Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [595/6471], Loss: 2.9465, Perplexity: 19.0392Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [596/6471], Loss: 3.1551, Perplexity: 23.4558Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [597/6471], Loss: 3.1196, Perplexity: 22.6373Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [598/6471], Loss: 2.9586, Perplexity: 19.2709Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [599/6471], Loss: 2.8620, Perplexity: 17.4971Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [600/6471], Loss: 3.2086, Perplexity: 24.7439\n",
      "Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [601/6471], Loss: 3.3074, Perplexity: 27.3129Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [602/6471], Loss: 3.1341, Perplexity: 22.9682Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [603/6471], Loss: 3.2610, Perplexity: 26.0762Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [604/6471], Loss: 3.3682, Perplexity: 29.0272Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [605/6471], Loss: 3.0957, Perplexity: 22.1023Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [606/6471], Loss: 3.1255, Perplexity: 22.7701Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [607/6471], Loss: 2.7790, Perplexity: 16.1031Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [608/6471], Loss: 3.2846, Perplexity: 26.6971Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [609/6471], Loss: 3.2126, Perplexity: 24.8446Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [610/6471], Loss: 2.9904, Perplexity: 19.8944Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [611/6471], Loss: 2.9048, Perplexity: 18.2611Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [612/6471], Loss: 2.9036, Perplexity: 18.2398Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [613/6471], Loss: 3.1431, Perplexity: 23.1761Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [614/6471], Loss: 3.2929, Perplexity: 26.9201Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [615/6471], Loss: 2.9755, Perplexity: 19.5992Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [616/6471], Loss: 3.0506, Perplexity: 21.1280Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [617/6471], Loss: 3.1158, Perplexity: 22.5510Shape of captions\n",
      "torch.Size([64, 25, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 26, 256])\n",
      "Epoch [1/3], Step [618/6471], Loss: 4.1100, Perplexity: 60.9485Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [619/6471], Loss: 3.1627, Perplexity: 23.6332Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [620/6471], Loss: 3.0047, Perplexity: 20.1809Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [621/6471], Loss: 3.5123, Perplexity: 33.5261Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [622/6471], Loss: 3.1120, Perplexity: 22.4663Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [623/6471], Loss: 3.1966, Perplexity: 24.4498Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [624/6471], Loss: 2.9480, Perplexity: 19.0686Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [625/6471], Loss: 3.2231, Perplexity: 25.1068Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [626/6471], Loss: 3.2091, Perplexity: 24.7570Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [627/6471], Loss: 3.0935, Perplexity: 22.0535Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [628/6471], Loss: 3.0164, Perplexity: 20.4185Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [629/6471], Loss: 2.9701, Perplexity: 19.4939Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [630/6471], Loss: 3.5201, Perplexity: 33.7869Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [631/6471], Loss: 3.0761, Perplexity: 21.6745Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [632/6471], Loss: 3.1822, Perplexity: 24.0998Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [633/6471], Loss: 3.0385, Perplexity: 20.8731Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [634/6471], Loss: 3.3388, Perplexity: 28.1842Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [635/6471], Loss: 3.2048, Perplexity: 24.6499Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [636/6471], Loss: 3.2837, Perplexity: 26.6735Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [637/6471], Loss: 2.9126, Perplexity: 18.4041Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [638/6471], Loss: 2.9688, Perplexity: 19.4677Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [639/6471], Loss: 3.1360, Perplexity: 23.0113Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [640/6471], Loss: 2.9686, Perplexity: 19.4654Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [641/6471], Loss: 3.1234, Perplexity: 22.7244Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [642/6471], Loss: 2.8954, Perplexity: 18.0911Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [643/6471], Loss: 3.2146, Perplexity: 24.8941Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [644/6471], Loss: 3.3865, Perplexity: 29.5636Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [645/6471], Loss: 3.4623, Perplexity: 31.8913Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [646/6471], Loss: 3.1563, Perplexity: 23.4840Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [647/6471], Loss: 3.0882, Perplexity: 21.9370Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [648/6471], Loss: 2.8797, Perplexity: 17.8083Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [649/6471], Loss: 3.2325, Perplexity: 25.3423Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [650/6471], Loss: 3.2157, Perplexity: 24.9203Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [651/6471], Loss: 3.1062, Perplexity: 22.3353Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [652/6471], Loss: 3.0309, Perplexity: 20.7156Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [653/6471], Loss: 3.0341, Perplexity: 20.7821Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [654/6471], Loss: 3.0787, Perplexity: 21.7302Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [655/6471], Loss: 3.2064, Perplexity: 24.6912Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [656/6471], Loss: 3.0654, Perplexity: 21.4430Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [657/6471], Loss: 3.0776, Perplexity: 21.7066Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [658/6471], Loss: 3.0940, Perplexity: 22.0650Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [659/6471], Loss: 2.8506, Perplexity: 17.2979Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [660/6471], Loss: 2.9266, Perplexity: 18.6641Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [661/6471], Loss: 3.1553, Perplexity: 23.4594Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [662/6471], Loss: 3.0822, Perplexity: 21.8058Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [663/6471], Loss: 3.3071, Perplexity: 27.3054Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [664/6471], Loss: 3.1381, Perplexity: 23.0593Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [665/6471], Loss: 2.9760, Perplexity: 19.6099Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [666/6471], Loss: 2.8921, Perplexity: 18.0311Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [667/6471], Loss: 3.0116, Perplexity: 20.3192Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [668/6471], Loss: 2.9711, Perplexity: 19.5134Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [669/6471], Loss: 2.7902, Perplexity: 16.2847Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [670/6471], Loss: 3.2391, Perplexity: 25.5102Shape of captions\n",
      "torch.Size([64, 24, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 25, 256])\n",
      "Epoch [1/3], Step [671/6471], Loss: 4.0202, Perplexity: 55.7098Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [672/6471], Loss: 2.9353, Perplexity: 18.8269Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [673/6471], Loss: 3.0571, Perplexity: 21.2654Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [674/6471], Loss: 2.9550, Perplexity: 19.2020Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [675/6471], Loss: 3.0908, Perplexity: 21.9949Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [676/6471], Loss: 2.9252, Perplexity: 18.6380Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [677/6471], Loss: 2.8189, Perplexity: 16.7577Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [678/6471], Loss: 3.4403, Perplexity: 31.1961Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [679/6471], Loss: 3.0928, Perplexity: 22.0389Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [680/6471], Loss: 3.1560, Perplexity: 23.4764Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [681/6471], Loss: 3.0202, Perplexity: 20.4949Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [682/6471], Loss: 2.9628, Perplexity: 19.3530Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [683/6471], Loss: 2.9927, Perplexity: 19.9404Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [684/6471], Loss: 2.8936, Perplexity: 18.0589Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [685/6471], Loss: 2.9300, Perplexity: 18.7284Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [686/6471], Loss: 2.9127, Perplexity: 18.4073Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [687/6471], Loss: 2.9452, Perplexity: 19.0152Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [688/6471], Loss: 2.9612, Perplexity: 19.3202Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [689/6471], Loss: 2.9714, Perplexity: 19.5183Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [690/6471], Loss: 3.0192, Perplexity: 20.4749Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [691/6471], Loss: 2.9057, Perplexity: 18.2785Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [692/6471], Loss: 3.0332, Perplexity: 20.7632Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [693/6471], Loss: 2.8265, Perplexity: 16.8859Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [694/6471], Loss: 3.3483, Perplexity: 28.4557Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [695/6471], Loss: 2.8665, Perplexity: 17.5754Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [696/6471], Loss: 2.8350, Perplexity: 17.0296Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [697/6471], Loss: 3.1415, Perplexity: 23.1395Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [698/6471], Loss: 3.0473, Perplexity: 21.0591Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [699/6471], Loss: 2.7545, Perplexity: 15.7129Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [700/6471], Loss: 2.8275, Perplexity: 16.9034\n",
      "Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [701/6471], Loss: 3.3565, Perplexity: 28.6889Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [702/6471], Loss: 2.9856, Perplexity: 19.7985Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [703/6471], Loss: 3.1178, Perplexity: 22.5966Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [704/6471], Loss: 2.8826, Perplexity: 17.8610Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [705/6471], Loss: 2.7436, Perplexity: 15.5424Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [706/6471], Loss: 3.2850, Perplexity: 26.7095Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [707/6471], Loss: 3.1552, Perplexity: 23.4579Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [708/6471], Loss: 2.9643, Perplexity: 19.3813Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [709/6471], Loss: 3.0681, Perplexity: 21.5002Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [710/6471], Loss: 2.9598, Perplexity: 19.2941Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [711/6471], Loss: 2.8146, Perplexity: 16.6867Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [712/6471], Loss: 3.1579, Perplexity: 23.5207Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [713/6471], Loss: 3.0908, Perplexity: 21.9949Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [714/6471], Loss: 2.9562, Perplexity: 19.2241Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [715/6471], Loss: 3.0193, Perplexity: 20.4765Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [716/6471], Loss: 3.0853, Perplexity: 21.8749Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [717/6471], Loss: 2.7544, Perplexity: 15.7115Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [718/6471], Loss: 2.9827, Perplexity: 19.7408Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [719/6471], Loss: 3.1388, Perplexity: 23.0758Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [720/6471], Loss: 3.4513, Perplexity: 31.5406Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [721/6471], Loss: 2.9496, Perplexity: 19.0979Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [722/6471], Loss: 2.8502, Perplexity: 17.2920Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [723/6471], Loss: 2.9111, Perplexity: 18.3762Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [724/6471], Loss: 3.1360, Perplexity: 23.0124Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [725/6471], Loss: 2.9509, Perplexity: 19.1234Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [726/6471], Loss: 2.9917, Perplexity: 19.9187Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [727/6471], Loss: 3.0966, Perplexity: 22.1222Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [728/6471], Loss: 2.9470, Perplexity: 19.0484Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [729/6471], Loss: 2.7488, Perplexity: 15.6234Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [730/6471], Loss: 2.9535, Perplexity: 19.1730Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [731/6471], Loss: 3.2538, Perplexity: 25.8878Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [732/6471], Loss: 2.8742, Perplexity: 17.7113Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [733/6471], Loss: 2.9035, Perplexity: 18.2383Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [734/6471], Loss: 2.8872, Perplexity: 17.9423Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [735/6471], Loss: 3.1467, Perplexity: 23.2602Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [736/6471], Loss: 3.0106, Perplexity: 20.2987Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [737/6471], Loss: 2.9386, Perplexity: 18.8896Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [738/6471], Loss: 3.0091, Perplexity: 20.2698Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [739/6471], Loss: 3.2145, Perplexity: 24.8914Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [740/6471], Loss: 2.7517, Perplexity: 15.6694Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [741/6471], Loss: 2.9846, Perplexity: 19.7784Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [742/6471], Loss: 2.7914, Perplexity: 16.3030Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [743/6471], Loss: 3.0123, Perplexity: 20.3335Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [744/6471], Loss: 2.9305, Perplexity: 18.7373Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [745/6471], Loss: 2.9812, Perplexity: 19.7121Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [746/6471], Loss: 3.1205, Perplexity: 22.6583Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [747/6471], Loss: 2.7594, Perplexity: 15.7909Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [748/6471], Loss: 3.4810, Perplexity: 32.4909Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [749/6471], Loss: 2.8778, Perplexity: 17.7743Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [750/6471], Loss: 2.9365, Perplexity: 18.8498Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [751/6471], Loss: 3.1677, Perplexity: 23.7534Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [752/6471], Loss: 2.9906, Perplexity: 19.8969Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [753/6471], Loss: 3.6249, Perplexity: 37.5212Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [754/6471], Loss: 2.7817, Perplexity: 16.1460Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [755/6471], Loss: 2.9473, Perplexity: 19.0554Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [756/6471], Loss: 2.8180, Perplexity: 16.7427Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [757/6471], Loss: 2.8358, Perplexity: 17.0439Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [758/6471], Loss: 3.0457, Perplexity: 21.0247Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [759/6471], Loss: 2.8772, Perplexity: 17.7636Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [760/6471], Loss: 2.8552, Perplexity: 17.3774Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [761/6471], Loss: 2.9334, Perplexity: 18.7906Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [762/6471], Loss: 3.3608, Perplexity: 28.8128Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [763/6471], Loss: 3.0870, Perplexity: 21.9109Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [764/6471], Loss: 2.8117, Perplexity: 16.6383Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [765/6471], Loss: 3.0512, Perplexity: 21.1412Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [766/6471], Loss: 2.7449, Perplexity: 15.5632Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [767/6471], Loss: 2.8516, Perplexity: 17.3160Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [768/6471], Loss: 2.9323, Perplexity: 18.7705Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [769/6471], Loss: 2.8758, Perplexity: 17.7387Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [770/6471], Loss: 3.2537, Perplexity: 25.8867Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [771/6471], Loss: 3.2367, Perplexity: 25.4503Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [772/6471], Loss: 3.1534, Perplexity: 23.4167Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [773/6471], Loss: 2.9619, Perplexity: 19.3338Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [774/6471], Loss: 3.4314, Perplexity: 30.9212Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [775/6471], Loss: 3.4258, Perplexity: 30.7484Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [776/6471], Loss: 3.4084, Perplexity: 30.2183Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [777/6471], Loss: 2.9229, Perplexity: 18.5952Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [778/6471], Loss: 3.0659, Perplexity: 21.4539Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [779/6471], Loss: 2.9884, Perplexity: 19.8536Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [780/6471], Loss: 2.9302, Perplexity: 18.7320Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [781/6471], Loss: 2.8527, Perplexity: 17.3348Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [782/6471], Loss: 2.8552, Perplexity: 17.3783Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [783/6471], Loss: 2.8898, Perplexity: 17.9898Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [784/6471], Loss: 2.8170, Perplexity: 16.7264Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [785/6471], Loss: 2.9724, Perplexity: 19.5380Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [786/6471], Loss: 3.0307, Perplexity: 20.7110Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [787/6471], Loss: 2.9152, Perplexity: 18.4519Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [788/6471], Loss: 2.7423, Perplexity: 15.5228Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [789/6471], Loss: 2.9055, Perplexity: 18.2736Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [790/6471], Loss: 3.0377, Perplexity: 20.8565Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [791/6471], Loss: 3.1321, Perplexity: 22.9226Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [792/6471], Loss: 2.8962, Perplexity: 18.1058Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [793/6471], Loss: 3.2923, Perplexity: 26.9039Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [794/6471], Loss: 2.8153, Perplexity: 16.6989Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [795/6471], Loss: 2.8920, Perplexity: 18.0301Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [796/6471], Loss: 3.0489, Perplexity: 21.0916Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [797/6471], Loss: 3.1020, Perplexity: 22.2419Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [798/6471], Loss: 2.9834, Perplexity: 19.7557Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [799/6471], Loss: 2.7813, Perplexity: 16.1406Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [800/6471], Loss: 2.9216, Perplexity: 18.5704\n",
      "Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [801/6471], Loss: 2.8096, Perplexity: 16.6036Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [802/6471], Loss: 3.0908, Perplexity: 21.9950Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [803/6471], Loss: 3.2755, Perplexity: 26.4576Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [804/6471], Loss: 2.8546, Perplexity: 17.3669Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [805/6471], Loss: 3.0476, Perplexity: 21.0639Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [806/6471], Loss: 3.0826, Perplexity: 21.8142Shape of captions\n",
      "torch.Size([64, 25, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 26, 256])\n",
      "Epoch [1/3], Step [807/6471], Loss: 3.9928, Perplexity: 54.2081Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [808/6471], Loss: 2.7872, Perplexity: 16.2357Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [809/6471], Loss: 2.8859, Perplexity: 17.9198Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [810/6471], Loss: 2.9187, Perplexity: 18.5171Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [811/6471], Loss: 2.9823, Perplexity: 19.7335Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [812/6471], Loss: 2.8567, Perplexity: 17.4043Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [813/6471], Loss: 2.6583, Perplexity: 14.2723Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [814/6471], Loss: 2.7988, Perplexity: 16.4251Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [815/6471], Loss: 2.9780, Perplexity: 19.6494Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [816/6471], Loss: 3.0057, Perplexity: 20.1996Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [817/6471], Loss: 2.9050, Perplexity: 18.2648Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [818/6471], Loss: 2.8952, Perplexity: 18.0869Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [819/6471], Loss: 2.8738, Perplexity: 17.7049Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [820/6471], Loss: 2.7707, Perplexity: 15.9698Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [821/6471], Loss: 2.9544, Perplexity: 19.1899Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [822/6471], Loss: 3.1194, Perplexity: 22.6335Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [823/6471], Loss: 3.1280, Perplexity: 22.8293Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [824/6471], Loss: 2.7838, Perplexity: 16.1808Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [825/6471], Loss: 3.2556, Perplexity: 25.9348Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [826/6471], Loss: 3.0938, Perplexity: 22.0608Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [827/6471], Loss: 2.8431, Perplexity: 17.1690Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [828/6471], Loss: 2.9254, Perplexity: 18.6420Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [829/6471], Loss: 3.2911, Perplexity: 26.8717Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [830/6471], Loss: 2.8253, Perplexity: 16.8653Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [831/6471], Loss: 2.8828, Perplexity: 17.8647Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [832/6471], Loss: 2.8299, Perplexity: 16.9440Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [833/6471], Loss: 2.9283, Perplexity: 18.6960Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [834/6471], Loss: 3.1407, Perplexity: 23.1192Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [835/6471], Loss: 2.8866, Perplexity: 17.9314Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [836/6471], Loss: 2.9105, Perplexity: 18.3669Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [837/6471], Loss: 2.9593, Perplexity: 19.2838Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [838/6471], Loss: 2.6162, Perplexity: 13.6837Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [839/6471], Loss: 2.8680, Perplexity: 17.6012Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [840/6471], Loss: 2.8058, Perplexity: 16.5403Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [841/6471], Loss: 2.8866, Perplexity: 17.9317Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [842/6471], Loss: 2.8928, Perplexity: 18.0445Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [843/6471], Loss: 2.8811, Perplexity: 17.8342Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [844/6471], Loss: 2.8887, Perplexity: 17.9693Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [845/6471], Loss: 2.9194, Perplexity: 18.5297Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [846/6471], Loss: 2.9861, Perplexity: 19.8088Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [847/6471], Loss: 2.8493, Perplexity: 17.2762Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [848/6471], Loss: 2.7812, Perplexity: 16.1389Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [849/6471], Loss: 2.8890, Perplexity: 17.9753Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [850/6471], Loss: 2.9826, Perplexity: 19.7382Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [851/6471], Loss: 2.7936, Perplexity: 16.3396Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [852/6471], Loss: 2.8002, Perplexity: 16.4483Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [853/6471], Loss: 2.9638, Perplexity: 19.3717Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [854/6471], Loss: 2.8658, Perplexity: 17.5624Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [855/6471], Loss: 2.7173, Perplexity: 15.1398Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [856/6471], Loss: 2.8441, Perplexity: 17.1859Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [857/6471], Loss: 2.8321, Perplexity: 16.9811Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [858/6471], Loss: 3.2085, Perplexity: 24.7428Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [859/6471], Loss: 3.0117, Perplexity: 20.3226Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [860/6471], Loss: 2.8467, Perplexity: 17.2308Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [861/6471], Loss: 3.1567, Perplexity: 23.4922Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [862/6471], Loss: 2.9805, Perplexity: 19.6977Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [863/6471], Loss: 3.0584, Perplexity: 21.2924Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [864/6471], Loss: 2.7801, Perplexity: 16.1209Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [865/6471], Loss: 2.8119, Perplexity: 16.6412Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [866/6471], Loss: 2.9922, Perplexity: 19.9286Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [867/6471], Loss: 3.0260, Perplexity: 20.6150Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [868/6471], Loss: 2.9636, Perplexity: 19.3671Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [869/6471], Loss: 2.6171, Perplexity: 13.6954Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [870/6471], Loss: 3.1840, Perplexity: 24.1426Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [871/6471], Loss: 2.9062, Perplexity: 18.2879Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [872/6471], Loss: 2.7602, Perplexity: 15.8030Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [873/6471], Loss: 2.6506, Perplexity: 14.1632Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [874/6471], Loss: 2.6330, Perplexity: 13.9156Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [875/6471], Loss: 2.8590, Perplexity: 17.4439Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [876/6471], Loss: 2.7218, Perplexity: 15.2077Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [877/6471], Loss: 3.1382, Perplexity: 23.0623Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [878/6471], Loss: 2.6240, Perplexity: 13.7909Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [879/6471], Loss: 2.9515, Perplexity: 19.1339Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [880/6471], Loss: 2.7593, Perplexity: 15.7883Shape of captions\n",
      "torch.Size([64, 30, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 31, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [881/6471], Loss: 4.3403, Perplexity: 76.7314Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [882/6471], Loss: 2.8994, Perplexity: 18.1627Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [883/6471], Loss: 3.1361, Perplexity: 23.0133Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [884/6471], Loss: 2.9970, Perplexity: 20.0248Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [885/6471], Loss: 3.0611, Perplexity: 21.3514Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [886/6471], Loss: 2.7079, Perplexity: 14.9981Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [887/6471], Loss: 2.9757, Perplexity: 19.6042Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [888/6471], Loss: 2.8286, Perplexity: 16.9224Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [889/6471], Loss: 2.6186, Perplexity: 13.7171Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [890/6471], Loss: 2.8986, Perplexity: 18.1490Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [891/6471], Loss: 3.1914, Perplexity: 24.3236Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [892/6471], Loss: 2.9726, Perplexity: 19.5420Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [893/6471], Loss: 2.8587, Perplexity: 17.4394Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [894/6471], Loss: 2.7352, Perplexity: 15.4126Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [895/6471], Loss: 3.0003, Perplexity: 20.0918Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [896/6471], Loss: 2.5258, Perplexity: 12.5008Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [897/6471], Loss: 2.8353, Perplexity: 17.0360Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [898/6471], Loss: 2.7176, Perplexity: 15.1439Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [899/6471], Loss: 2.6911, Perplexity: 14.7482Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [900/6471], Loss: 2.7401, Perplexity: 15.4881\n",
      "Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [901/6471], Loss: 2.9722, Perplexity: 19.5348Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [902/6471], Loss: 3.6398, Perplexity: 38.0856Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [903/6471], Loss: 2.8265, Perplexity: 16.8854Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [904/6471], Loss: 2.7827, Perplexity: 16.1627Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [905/6471], Loss: 2.9060, Perplexity: 18.2838Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [906/6471], Loss: 2.9411, Perplexity: 18.9373Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [907/6471], Loss: 3.0028, Perplexity: 20.1423Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [908/6471], Loss: 3.3095, Perplexity: 27.3716Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [909/6471], Loss: 2.7098, Perplexity: 15.0258Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [910/6471], Loss: 2.8405, Perplexity: 17.1244Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [911/6471], Loss: 2.5311, Perplexity: 12.5676Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [912/6471], Loss: 3.3679, Perplexity: 29.0178Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [913/6471], Loss: 2.7609, Perplexity: 15.8134Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [914/6471], Loss: 2.6414, Perplexity: 14.0332Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [915/6471], Loss: 2.8986, Perplexity: 18.1496Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [916/6471], Loss: 2.8373, Perplexity: 17.0704Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [917/6471], Loss: 2.6936, Perplexity: 14.7852Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [918/6471], Loss: 2.7822, Perplexity: 16.1545Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [919/6471], Loss: 2.8151, Perplexity: 16.6949Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [920/6471], Loss: 2.8038, Perplexity: 16.5077Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [921/6471], Loss: 2.6136, Perplexity: 13.6480Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [922/6471], Loss: 3.0138, Perplexity: 20.3648Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [923/6471], Loss: 2.7799, Perplexity: 16.1181Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [924/6471], Loss: 2.7549, Perplexity: 15.7194Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [925/6471], Loss: 2.9956, Perplexity: 19.9974Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [926/6471], Loss: 2.7201, Perplexity: 15.1811Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [927/6471], Loss: 2.8166, Perplexity: 16.7196Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [928/6471], Loss: 2.6564, Perplexity: 14.2454Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [929/6471], Loss: 2.6790, Perplexity: 14.5701Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [930/6471], Loss: 3.1989, Perplexity: 24.5053Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [931/6471], Loss: 3.2589, Perplexity: 26.0219Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [932/6471], Loss: 2.8877, Perplexity: 17.9521Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [933/6471], Loss: 2.9461, Perplexity: 19.0309Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [934/6471], Loss: 2.6731, Perplexity: 14.4853Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [935/6471], Loss: 2.5798, Perplexity: 13.1943Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [936/6471], Loss: 2.7384, Perplexity: 15.4628Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [937/6471], Loss: 2.6552, Perplexity: 14.2282Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [938/6471], Loss: 2.7297, Perplexity: 15.3289Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [939/6471], Loss: 2.8261, Perplexity: 16.8801Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [940/6471], Loss: 2.6787, Perplexity: 14.5669Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [941/6471], Loss: 2.7792, Perplexity: 16.1057Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [942/6471], Loss: 2.7649, Perplexity: 15.8771Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [943/6471], Loss: 3.0017, Perplexity: 20.1190Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [944/6471], Loss: 2.8100, Perplexity: 16.6106Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [945/6471], Loss: 2.9245, Perplexity: 18.6243Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [946/6471], Loss: 2.7837, Perplexity: 16.1785Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [947/6471], Loss: 2.8080, Perplexity: 16.5763Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [948/6471], Loss: 3.0307, Perplexity: 20.7109Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [949/6471], Loss: 3.3587, Perplexity: 28.7526Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [950/6471], Loss: 3.1110, Perplexity: 22.4425Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [951/6471], Loss: 2.8816, Perplexity: 17.8436Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [952/6471], Loss: 2.7641, Perplexity: 15.8653Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [953/6471], Loss: 3.0163, Perplexity: 20.4153Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [954/6471], Loss: 2.6408, Perplexity: 14.0239Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [955/6471], Loss: 2.7033, Perplexity: 14.9297Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [956/6471], Loss: 2.7743, Perplexity: 16.0278Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [957/6471], Loss: 2.9139, Perplexity: 18.4290Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [958/6471], Loss: 3.1778, Perplexity: 23.9936Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [959/6471], Loss: 3.2287, Perplexity: 25.2479Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [960/6471], Loss: 2.6216, Perplexity: 13.7576Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [961/6471], Loss: 2.8051, Perplexity: 16.5286Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [962/6471], Loss: 2.9229, Perplexity: 18.5946Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [963/6471], Loss: 2.8752, Perplexity: 17.7282Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [964/6471], Loss: 3.0531, Perplexity: 21.1808Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [965/6471], Loss: 2.6390, Perplexity: 13.9988Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [966/6471], Loss: 2.6966, Perplexity: 14.8292Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [967/6471], Loss: 3.0397, Perplexity: 20.8989Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [968/6471], Loss: 2.7231, Perplexity: 15.2274Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [969/6471], Loss: 2.9891, Perplexity: 19.8674Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [970/6471], Loss: 2.5930, Perplexity: 13.3692Shape of captions\n",
      "torch.Size([64, 24, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 25, 256])\n",
      "Epoch [1/3], Step [971/6471], Loss: 3.7325, Perplexity: 41.7831Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [972/6471], Loss: 2.8304, Perplexity: 16.9530Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [973/6471], Loss: 2.8025, Perplexity: 16.4863Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [974/6471], Loss: 2.9609, Perplexity: 19.3160Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [975/6471], Loss: 3.0095, Perplexity: 20.2781Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [976/6471], Loss: 2.6418, Perplexity: 14.0390Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [977/6471], Loss: 2.8109, Perplexity: 16.6251Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [978/6471], Loss: 2.6782, Perplexity: 14.5585Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [979/6471], Loss: 3.0021, Perplexity: 20.1274Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [980/6471], Loss: 3.0176, Perplexity: 20.4430Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [981/6471], Loss: 3.0112, Perplexity: 20.3115Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [982/6471], Loss: 2.6619, Perplexity: 14.3241Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [983/6471], Loss: 3.0224, Perplexity: 20.5400Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [984/6471], Loss: 2.6820, Perplexity: 14.6137Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [985/6471], Loss: 2.5832, Perplexity: 13.2400Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [986/6471], Loss: 3.0248, Perplexity: 20.5890Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [987/6471], Loss: 2.5968, Perplexity: 13.4214Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [988/6471], Loss: 2.6504, Perplexity: 14.1599Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [989/6471], Loss: 2.5943, Perplexity: 13.3866Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [990/6471], Loss: 2.8217, Perplexity: 16.8057Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [991/6471], Loss: 2.7608, Perplexity: 15.8118Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [992/6471], Loss: 2.9641, Perplexity: 19.3780Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [993/6471], Loss: 2.8884, Perplexity: 17.9638Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [994/6471], Loss: 2.6654, Perplexity: 14.3736Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [995/6471], Loss: 2.7497, Perplexity: 15.6380Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [996/6471], Loss: 2.9165, Perplexity: 18.4766Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [997/6471], Loss: 2.7266, Perplexity: 15.2815Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [998/6471], Loss: 2.7791, Perplexity: 16.1051Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [999/6471], Loss: 2.7911, Perplexity: 16.2990Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1000/6471], Loss: 2.9484, Perplexity: 19.0759\n",
      "Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1001/6471], Loss: 2.7131, Perplexity: 15.0766Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1002/6471], Loss: 2.7251, Perplexity: 15.2586Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1003/6471], Loss: 2.7982, Perplexity: 16.4147Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1004/6471], Loss: 2.6870, Perplexity: 14.6874Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1005/6471], Loss: 2.7753, Perplexity: 16.0432Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1006/6471], Loss: 3.0727, Perplexity: 21.5995Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1007/6471], Loss: 2.7195, Perplexity: 15.1733Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1008/6471], Loss: 2.9668, Perplexity: 19.4292Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1009/6471], Loss: 2.8136, Perplexity: 16.6704Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [1010/6471], Loss: 3.5697, Perplexity: 35.5068Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1011/6471], Loss: 2.8112, Perplexity: 16.6303Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1012/6471], Loss: 2.7667, Perplexity: 15.9068Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1013/6471], Loss: 2.7649, Perplexity: 15.8777Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1014/6471], Loss: 2.6213, Perplexity: 13.7543Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1015/6471], Loss: 2.8913, Perplexity: 18.0164Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1016/6471], Loss: 2.7095, Perplexity: 15.0222Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1017/6471], Loss: 2.6296, Perplexity: 13.8682Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1018/6471], Loss: 3.4813, Perplexity: 32.5034Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1019/6471], Loss: 3.1251, Perplexity: 22.7631Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1020/6471], Loss: 2.8387, Perplexity: 17.0928Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1021/6471], Loss: 2.7410, Perplexity: 15.5021Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1022/6471], Loss: 2.7992, Perplexity: 16.4320Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1023/6471], Loss: 2.6387, Perplexity: 13.9949Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1024/6471], Loss: 2.8547, Perplexity: 17.3691Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1025/6471], Loss: 3.2570, Perplexity: 25.9720Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1026/6471], Loss: 2.8806, Perplexity: 17.8248Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1027/6471], Loss: 2.8029, Perplexity: 16.4918Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1028/6471], Loss: 2.6211, Perplexity: 13.7512Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1029/6471], Loss: 2.6238, Perplexity: 13.7874Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1030/6471], Loss: 2.9591, Perplexity: 19.2813Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1031/6471], Loss: 2.7183, Perplexity: 15.1545Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1032/6471], Loss: 2.6081, Perplexity: 13.5738Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1033/6471], Loss: 2.6933, Perplexity: 14.7806Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1034/6471], Loss: 2.7485, Perplexity: 15.6194Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1035/6471], Loss: 2.8296, Perplexity: 16.9384Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1036/6471], Loss: 2.7565, Perplexity: 15.7449Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1037/6471], Loss: 2.8916, Perplexity: 18.0223Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1038/6471], Loss: 2.7287, Perplexity: 15.3125Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1039/6471], Loss: 2.8044, Perplexity: 16.5166Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1040/6471], Loss: 2.8683, Perplexity: 17.6072Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1041/6471], Loss: 2.5827, Perplexity: 13.2324Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1042/6471], Loss: 2.6632, Perplexity: 14.3424Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1043/6471], Loss: 2.6607, Perplexity: 14.3056Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1044/6471], Loss: 2.6575, Perplexity: 14.2603Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1045/6471], Loss: 3.1256, Perplexity: 22.7728Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1046/6471], Loss: 2.7730, Perplexity: 16.0065Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1047/6471], Loss: 2.5887, Perplexity: 13.3129Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1048/6471], Loss: 2.6598, Perplexity: 14.2935Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1049/6471], Loss: 2.7544, Perplexity: 15.7121Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1050/6471], Loss: 2.6460, Perplexity: 14.0980Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1051/6471], Loss: 2.7950, Perplexity: 16.3633Shape of captions\n",
      "torch.Size([64, 23, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 24, 256])\n",
      "Epoch [1/3], Step [1052/6471], Loss: 3.6409, Perplexity: 38.1270Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1053/6471], Loss: 2.7805, Perplexity: 16.1269Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1054/6471], Loss: 2.6179, Perplexity: 13.7069Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1055/6471], Loss: 2.6632, Perplexity: 14.3416Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1056/6471], Loss: 2.9072, Perplexity: 18.3046Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1057/6471], Loss: 2.6418, Perplexity: 14.0378Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1058/6471], Loss: 2.6848, Perplexity: 14.6545Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1059/6471], Loss: 2.8017, Perplexity: 16.4729Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1060/6471], Loss: 2.6245, Perplexity: 13.7975Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1061/6471], Loss: 2.8311, Perplexity: 16.9636Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1062/6471], Loss: 2.7596, Perplexity: 15.7934Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1063/6471], Loss: 2.7914, Perplexity: 16.3030Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [1064/6471], Loss: 3.5192, Perplexity: 33.7571Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1065/6471], Loss: 3.1603, Perplexity: 23.5772Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1066/6471], Loss: 2.7065, Perplexity: 14.9772Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1067/6471], Loss: 2.7164, Perplexity: 15.1261Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1068/6471], Loss: 2.8464, Perplexity: 17.2256Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1069/6471], Loss: 2.9408, Perplexity: 18.9310Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1070/6471], Loss: 2.6715, Perplexity: 14.4612Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1071/6471], Loss: 3.1354, Perplexity: 22.9979Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1072/6471], Loss: 3.0276, Perplexity: 20.6472Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1073/6471], Loss: 3.1428, Perplexity: 23.1684Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1074/6471], Loss: 2.8316, Perplexity: 16.9719Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1075/6471], Loss: 2.8590, Perplexity: 17.4449Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1076/6471], Loss: 2.6071, Perplexity: 13.5598Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1077/6471], Loss: 2.5949, Perplexity: 13.3956Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1078/6471], Loss: 2.8299, Perplexity: 16.9439Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1079/6471], Loss: 2.9858, Perplexity: 19.8016Shape of captions\n",
      "torch.Size([64, 24, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 25, 256])\n",
      "Epoch [1/3], Step [1080/6471], Loss: 3.7315, Perplexity: 41.7403Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1081/6471], Loss: 3.0031, Perplexity: 20.1481Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1082/6471], Loss: 2.5755, Perplexity: 13.1376Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1083/6471], Loss: 2.6894, Perplexity: 14.7231Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1084/6471], Loss: 2.6894, Perplexity: 14.7232Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1085/6471], Loss: 2.7215, Perplexity: 15.2024Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1086/6471], Loss: 2.7901, Perplexity: 16.2822Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1087/6471], Loss: 2.6147, Perplexity: 13.6626Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1088/6471], Loss: 2.7783, Perplexity: 16.0921Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1089/6471], Loss: 3.0500, Perplexity: 21.1149Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1090/6471], Loss: 2.7505, Perplexity: 15.6510Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1091/6471], Loss: 3.2150, Perplexity: 24.9040Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1092/6471], Loss: 2.7785, Perplexity: 16.0950Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1093/6471], Loss: 2.7297, Perplexity: 15.3287Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1094/6471], Loss: 2.9059, Perplexity: 18.2824Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1095/6471], Loss: 2.9700, Perplexity: 19.4928Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1096/6471], Loss: 3.0129, Perplexity: 20.3456Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1097/6471], Loss: 2.7329, Perplexity: 15.3776Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1098/6471], Loss: 3.1234, Perplexity: 22.7226Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1099/6471], Loss: 2.7842, Perplexity: 16.1861Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1100/6471], Loss: 2.8343, Perplexity: 17.0181\n",
      "Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1101/6471], Loss: 2.6815, Perplexity: 14.6070Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1102/6471], Loss: 2.7667, Perplexity: 15.9053Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1103/6471], Loss: 2.7217, Perplexity: 15.2065Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1104/6471], Loss: 2.6878, Perplexity: 14.6996Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1105/6471], Loss: 3.0717, Perplexity: 21.5778Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1106/6471], Loss: 2.3819, Perplexity: 10.8259Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1107/6471], Loss: 2.7471, Perplexity: 15.5976Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1108/6471], Loss: 2.8079, Perplexity: 16.5750Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1109/6471], Loss: 2.9543, Perplexity: 19.1879Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1110/6471], Loss: 2.8868, Perplexity: 17.9357Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1111/6471], Loss: 2.6603, Perplexity: 14.3000Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1112/6471], Loss: 2.6226, Perplexity: 13.7721Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1113/6471], Loss: 2.6552, Perplexity: 14.2272Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1114/6471], Loss: 2.7896, Perplexity: 16.2741Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1115/6471], Loss: 2.8882, Perplexity: 17.9612Shape of captions\n",
      "torch.Size([64, 24, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 25, 256])\n",
      "Epoch [1/3], Step [1116/6471], Loss: 3.5732, Perplexity: 35.6315Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1117/6471], Loss: 2.6896, Perplexity: 14.7260Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1118/6471], Loss: 3.0911, Perplexity: 22.0004Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1119/6471], Loss: 2.7985, Perplexity: 16.4198Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1120/6471], Loss: 2.7334, Perplexity: 15.3848Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1121/6471], Loss: 3.2064, Perplexity: 24.6890Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1122/6471], Loss: 2.5630, Perplexity: 12.9745Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1123/6471], Loss: 2.6144, Perplexity: 13.6584Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1124/6471], Loss: 2.5729, Perplexity: 13.1042Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1125/6471], Loss: 2.6844, Perplexity: 14.6493Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1126/6471], Loss: 2.6262, Perplexity: 13.8205Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1127/6471], Loss: 2.7309, Perplexity: 15.3471Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1128/6471], Loss: 2.6642, Perplexity: 14.3560Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1129/6471], Loss: 2.6462, Perplexity: 14.1008Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1130/6471], Loss: 2.6946, Perplexity: 14.7990Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1131/6471], Loss: 2.6859, Perplexity: 14.6716Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1132/6471], Loss: 2.8184, Perplexity: 16.7503Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1133/6471], Loss: 2.6164, Perplexity: 13.6870Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1134/6471], Loss: 2.7544, Perplexity: 15.7115Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1135/6471], Loss: 2.7483, Perplexity: 15.6160Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1136/6471], Loss: 2.5232, Perplexity: 12.4688Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1137/6471], Loss: 2.7835, Perplexity: 16.1753Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1138/6471], Loss: 2.5962, Perplexity: 13.4132Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1139/6471], Loss: 2.5595, Perplexity: 12.9291Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1140/6471], Loss: 2.7714, Perplexity: 15.9809Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [1141/6471], Loss: 3.0286, Perplexity: 20.6690Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1142/6471], Loss: 2.8795, Perplexity: 17.8048Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1143/6471], Loss: 2.6969, Perplexity: 14.8341Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1144/6471], Loss: 2.7874, Perplexity: 16.2392Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1145/6471], Loss: 2.4913, Perplexity: 12.0765Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1146/6471], Loss: 3.3740, Perplexity: 29.1948Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1147/6471], Loss: 2.6578, Perplexity: 14.2645Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1148/6471], Loss: 2.4884, Perplexity: 12.0421Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1149/6471], Loss: 2.6776, Perplexity: 14.5506Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1150/6471], Loss: 2.8023, Perplexity: 16.4817Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1151/6471], Loss: 3.6055, Perplexity: 36.7998Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1152/6471], Loss: 2.7487, Perplexity: 15.6222Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1153/6471], Loss: 2.7488, Perplexity: 15.6231Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1154/6471], Loss: 2.7936, Perplexity: 16.3398Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1155/6471], Loss: 2.6906, Perplexity: 14.7398Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1156/6471], Loss: 2.6019, Perplexity: 13.4888Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1157/6471], Loss: 2.8397, Perplexity: 17.1106Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1158/6471], Loss: 2.9301, Perplexity: 18.7298Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1159/6471], Loss: 2.7522, Perplexity: 15.6765Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1160/6471], Loss: 2.6168, Perplexity: 13.6916Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1161/6471], Loss: 2.8231, Perplexity: 16.8296Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1162/6471], Loss: 2.6270, Perplexity: 13.8316Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1163/6471], Loss: 2.7050, Perplexity: 14.9541Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1164/6471], Loss: 2.8069, Perplexity: 16.5578Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1165/6471], Loss: 2.5730, Perplexity: 13.1053Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1166/6471], Loss: 2.6745, Perplexity: 14.5053Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1167/6471], Loss: 2.7265, Perplexity: 15.2791Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1168/6471], Loss: 2.4650, Perplexity: 11.7634Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1169/6471], Loss: 2.4474, Perplexity: 11.5587Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1170/6471], Loss: 2.7147, Perplexity: 15.1000Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1171/6471], Loss: 3.3326, Perplexity: 28.0099Shape of captions\n",
      "torch.Size([64, 23, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 24, 256])\n",
      "Epoch [1/3], Step [1172/6471], Loss: 3.5965, Perplexity: 36.4702Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1173/6471], Loss: 2.4404, Perplexity: 11.4780Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1174/6471], Loss: 2.6036, Perplexity: 13.5125Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1175/6471], Loss: 2.9854, Perplexity: 19.7946Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1176/6471], Loss: 2.6166, Perplexity: 13.6893Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1177/6471], Loss: 2.6940, Perplexity: 14.7906Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1178/6471], Loss: 2.6022, Perplexity: 13.4936Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1179/6471], Loss: 2.8790, Perplexity: 17.7972Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1180/6471], Loss: 2.6709, Perplexity: 14.4536Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1181/6471], Loss: 2.7108, Perplexity: 15.0407Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1182/6471], Loss: 3.1584, Perplexity: 23.5340Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1183/6471], Loss: 2.6011, Perplexity: 13.4788Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1184/6471], Loss: 2.5284, Perplexity: 12.5339Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1185/6471], Loss: 3.1885, Perplexity: 24.2509Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1186/6471], Loss: 2.7591, Perplexity: 15.7850Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1187/6471], Loss: 2.5182, Perplexity: 12.4063Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1188/6471], Loss: 2.6357, Perplexity: 13.9531Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1189/6471], Loss: 2.4741, Perplexity: 11.8710Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1190/6471], Loss: 2.9366, Perplexity: 18.8508Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1191/6471], Loss: 2.5450, Perplexity: 12.7433Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1192/6471], Loss: 3.2868, Perplexity: 26.7578Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1193/6471], Loss: 2.6023, Perplexity: 13.4953Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1194/6471], Loss: 2.4587, Perplexity: 11.6891Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1195/6471], Loss: 2.5909, Perplexity: 13.3421Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1196/6471], Loss: 2.5216, Perplexity: 12.4480Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1197/6471], Loss: 2.8403, Perplexity: 17.1205Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1198/6471], Loss: 2.9340, Perplexity: 18.8034Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1199/6471], Loss: 2.7793, Perplexity: 16.1076Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1200/6471], Loss: 2.7524, Perplexity: 15.6807\n",
      "Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1201/6471], Loss: 2.7569, Perplexity: 15.7512Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1202/6471], Loss: 2.6188, Perplexity: 13.7188Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1203/6471], Loss: 2.7695, Perplexity: 15.9509Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1204/6471], Loss: 2.6976, Perplexity: 14.8445Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1205/6471], Loss: 2.5739, Perplexity: 13.1172Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1206/6471], Loss: 2.6544, Perplexity: 14.2166Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1207/6471], Loss: 2.6060, Perplexity: 13.5442Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1208/6471], Loss: 2.8064, Perplexity: 16.5497Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1209/6471], Loss: 2.6090, Perplexity: 13.5860Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1210/6471], Loss: 2.7918, Perplexity: 16.3101Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1211/6471], Loss: 2.4277, Perplexity: 11.3329Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1212/6471], Loss: 2.5793, Perplexity: 13.1874Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1213/6471], Loss: 2.5851, Perplexity: 13.2641Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1214/6471], Loss: 2.6018, Perplexity: 13.4885Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1215/6471], Loss: 2.8409, Perplexity: 17.1305Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1216/6471], Loss: 2.8221, Perplexity: 16.8123Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1217/6471], Loss: 2.6056, Perplexity: 13.5388Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1218/6471], Loss: 2.5331, Perplexity: 12.5919Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1219/6471], Loss: 2.8512, Perplexity: 17.3077Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1220/6471], Loss: 2.7469, Perplexity: 15.5944Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1221/6471], Loss: 2.6447, Perplexity: 14.0796Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1222/6471], Loss: 2.6762, Perplexity: 14.5305Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1223/6471], Loss: 3.3829, Perplexity: 29.4547Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1224/6471], Loss: 2.8678, Perplexity: 17.5984Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1225/6471], Loss: 2.5930, Perplexity: 13.3699Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1226/6471], Loss: 2.5214, Perplexity: 12.4465Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1227/6471], Loss: 2.8284, Perplexity: 16.9179Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1228/6471], Loss: 3.0974, Perplexity: 22.1396Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1229/6471], Loss: 2.7516, Perplexity: 15.6675Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1230/6471], Loss: 2.6177, Perplexity: 13.7037Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1231/6471], Loss: 2.6133, Perplexity: 13.6433Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1232/6471], Loss: 2.7227, Perplexity: 15.2206Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1233/6471], Loss: 3.2257, Perplexity: 25.1719Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1234/6471], Loss: 2.6952, Perplexity: 14.8089Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1235/6471], Loss: 3.6482, Perplexity: 38.4057Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1236/6471], Loss: 2.9642, Perplexity: 19.3800Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1237/6471], Loss: 2.6526, Perplexity: 14.1905Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1238/6471], Loss: 2.9072, Perplexity: 18.3062Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1239/6471], Loss: 2.6939, Perplexity: 14.7899Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1240/6471], Loss: 2.8987, Perplexity: 18.1507Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1241/6471], Loss: 2.8371, Perplexity: 17.0656Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1242/6471], Loss: 3.3834, Perplexity: 29.4707Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1243/6471], Loss: 2.7911, Perplexity: 16.2985Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1244/6471], Loss: 2.7990, Perplexity: 16.4284Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1245/6471], Loss: 2.5863, Perplexity: 13.2806Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1246/6471], Loss: 2.6270, Perplexity: 13.8318Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1247/6471], Loss: 3.0122, Perplexity: 20.3321Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1248/6471], Loss: 3.0853, Perplexity: 21.8735Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1249/6471], Loss: 3.1033, Perplexity: 22.2717Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1250/6471], Loss: 2.8837, Perplexity: 17.8803Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1251/6471], Loss: 2.7774, Perplexity: 16.0774Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1252/6471], Loss: 2.5724, Perplexity: 13.0974Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1253/6471], Loss: 2.8631, Perplexity: 17.5164Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1254/6471], Loss: 2.6701, Perplexity: 14.4411Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1255/6471], Loss: 3.0699, Perplexity: 21.5394Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1256/6471], Loss: 2.8098, Perplexity: 16.6073Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1257/6471], Loss: 2.7558, Perplexity: 15.7341Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1258/6471], Loss: 2.4837, Perplexity: 11.9861Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1259/6471], Loss: 2.5781, Perplexity: 13.1718Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1260/6471], Loss: 2.5477, Perplexity: 12.7781Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1261/6471], Loss: 2.5836, Perplexity: 13.2452Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1262/6471], Loss: 2.9116, Perplexity: 18.3867Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1263/6471], Loss: 2.8311, Perplexity: 16.9634Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1264/6471], Loss: 2.7003, Perplexity: 14.8837Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1265/6471], Loss: 2.5853, Perplexity: 13.2672Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1266/6471], Loss: 2.5631, Perplexity: 12.9754Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1267/6471], Loss: 2.6351, Perplexity: 13.9441Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1268/6471], Loss: 2.6979, Perplexity: 14.8487Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1269/6471], Loss: 2.7236, Perplexity: 15.2351Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1270/6471], Loss: 3.0335, Perplexity: 20.7695Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1271/6471], Loss: 2.4788, Perplexity: 11.9265Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1272/6471], Loss: 3.0393, Perplexity: 20.8916Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1273/6471], Loss: 3.0303, Perplexity: 20.7039Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1274/6471], Loss: 2.6356, Perplexity: 13.9519Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1275/6471], Loss: 2.4871, Perplexity: 12.0269Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1276/6471], Loss: 2.6175, Perplexity: 13.7018Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1277/6471], Loss: 2.7319, Perplexity: 15.3615Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1278/6471], Loss: 2.9234, Perplexity: 18.6047Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1279/6471], Loss: 2.7803, Perplexity: 16.1235Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1280/6471], Loss: 2.8029, Perplexity: 16.4924Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [1281/6471], Loss: 2.8881, Perplexity: 17.9590Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1282/6471], Loss: 2.6458, Perplexity: 14.0941Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1283/6471], Loss: 2.5083, Perplexity: 12.2845Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1284/6471], Loss: 2.6164, Perplexity: 13.6857Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1285/6471], Loss: 2.7212, Perplexity: 15.1979Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1286/6471], Loss: 2.7318, Perplexity: 15.3604Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1287/6471], Loss: 2.7445, Perplexity: 15.5570Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1288/6471], Loss: 2.6078, Perplexity: 13.5692Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1289/6471], Loss: 2.7323, Perplexity: 15.3689Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1290/6471], Loss: 2.6049, Perplexity: 13.5298Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1291/6471], Loss: 2.6405, Perplexity: 14.0203Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1292/6471], Loss: 2.7449, Perplexity: 15.5624Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1293/6471], Loss: 2.5157, Perplexity: 12.3756Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1294/6471], Loss: 2.5249, Perplexity: 12.4891Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1295/6471], Loss: 2.7666, Perplexity: 15.9045Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1296/6471], Loss: 2.7992, Perplexity: 16.4318Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1297/6471], Loss: 2.5055, Perplexity: 12.2498Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1298/6471], Loss: 2.3653, Perplexity: 10.6474Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1299/6471], Loss: 2.7939, Perplexity: 16.3441Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1300/6471], Loss: 2.9711, Perplexity: 19.5143\n",
      "Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [1301/6471], Loss: 3.3397, Perplexity: 28.2100Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1302/6471], Loss: 2.7022, Perplexity: 14.9119Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1303/6471], Loss: 2.5904, Perplexity: 13.3356Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1304/6471], Loss: 2.7573, Perplexity: 15.7577Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1305/6471], Loss: 2.6609, Perplexity: 14.3092Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1306/6471], Loss: 2.9364, Perplexity: 18.8486Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1307/6471], Loss: 2.8035, Perplexity: 16.5018Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1308/6471], Loss: 2.5244, Perplexity: 12.4840Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1309/6471], Loss: 2.7665, Perplexity: 15.9031Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1310/6471], Loss: 2.6338, Perplexity: 13.9264Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1311/6471], Loss: 2.5519, Perplexity: 12.8321Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1312/6471], Loss: 2.7356, Perplexity: 15.4192Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1313/6471], Loss: 2.7811, Perplexity: 16.1373Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1314/6471], Loss: 2.7117, Perplexity: 15.0544Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1315/6471], Loss: 2.7870, Perplexity: 16.2315Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1316/6471], Loss: 2.8768, Perplexity: 17.7566Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1317/6471], Loss: 2.6069, Perplexity: 13.5567Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1318/6471], Loss: 2.6378, Perplexity: 13.9822Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1319/6471], Loss: 2.7868, Perplexity: 16.2293Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1320/6471], Loss: 2.8364, Perplexity: 17.0536Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1321/6471], Loss: 2.6839, Perplexity: 14.6415Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1322/6471], Loss: 3.0746, Perplexity: 21.6412Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1323/6471], Loss: 2.8028, Perplexity: 16.4911Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1324/6471], Loss: 2.8633, Perplexity: 17.5185Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1325/6471], Loss: 2.7834, Perplexity: 16.1744Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1326/6471], Loss: 2.8169, Perplexity: 16.7252Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1327/6471], Loss: 2.3684, Perplexity: 10.6803Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1328/6471], Loss: 2.4097, Perplexity: 11.1304Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1329/6471], Loss: 2.7997, Perplexity: 16.4396Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1330/6471], Loss: 3.0813, Perplexity: 21.7874Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1331/6471], Loss: 2.7035, Perplexity: 14.9315Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1332/6471], Loss: 2.7805, Perplexity: 16.1264Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1333/6471], Loss: 2.8317, Perplexity: 16.9745Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1334/6471], Loss: 2.4405, Perplexity: 11.4788Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1335/6471], Loss: 2.4880, Perplexity: 12.0367Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1336/6471], Loss: 2.5634, Perplexity: 12.9795Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1337/6471], Loss: 2.6951, Perplexity: 14.8071Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1338/6471], Loss: 2.6634, Perplexity: 14.3450Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1339/6471], Loss: 2.5050, Perplexity: 12.2439Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1340/6471], Loss: 2.8944, Perplexity: 18.0726Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1341/6471], Loss: 2.6191, Perplexity: 13.7235Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1342/6471], Loss: 2.5466, Perplexity: 12.7639Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1343/6471], Loss: 2.5556, Perplexity: 12.8795Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1344/6471], Loss: 2.9240, Perplexity: 18.6156Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1345/6471], Loss: 2.7998, Perplexity: 16.4407Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1346/6471], Loss: 2.5867, Perplexity: 13.2858Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1347/6471], Loss: 2.4527, Perplexity: 11.6195Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1348/6471], Loss: 2.6756, Perplexity: 14.5207Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1349/6471], Loss: 2.6025, Perplexity: 13.4977Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1350/6471], Loss: 2.8522, Perplexity: 17.3266Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1351/6471], Loss: 2.7582, Perplexity: 15.7708Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1352/6471], Loss: 2.7678, Perplexity: 15.9241Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1353/6471], Loss: 2.9603, Perplexity: 19.3033Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1354/6471], Loss: 2.8445, Perplexity: 17.1933Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1355/6471], Loss: 2.4765, Perplexity: 11.8992Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1356/6471], Loss: 2.4693, Perplexity: 11.8144Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1357/6471], Loss: 2.6758, Perplexity: 14.5240Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1358/6471], Loss: 2.5474, Perplexity: 12.7743Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1359/6471], Loss: 2.4675, Perplexity: 11.7928Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1360/6471], Loss: 2.5524, Perplexity: 12.8383Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1361/6471], Loss: 2.5210, Perplexity: 12.4407Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1362/6471], Loss: 2.6248, Perplexity: 13.8023Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1363/6471], Loss: 2.6551, Perplexity: 14.2264Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1364/6471], Loss: 2.6546, Perplexity: 14.2186Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1365/6471], Loss: 2.6047, Perplexity: 13.5275Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1366/6471], Loss: 2.9146, Perplexity: 18.4414Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1367/6471], Loss: 2.5758, Perplexity: 13.1419Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1368/6471], Loss: 2.4150, Perplexity: 11.1899Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1369/6471], Loss: 2.5602, Perplexity: 12.9387Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1370/6471], Loss: 2.7019, Perplexity: 14.9077Shape of captions\n",
      "torch.Size([64, 22, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 23, 256])\n",
      "Epoch [1/3], Step [1371/6471], Loss: 3.5591, Perplexity: 35.1319Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1372/6471], Loss: 2.5933, Perplexity: 13.3733Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1373/6471], Loss: 2.2571, Perplexity: 9.5551Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1374/6471], Loss: 2.5500, Perplexity: 12.8074Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1375/6471], Loss: 2.7367, Perplexity: 15.4365Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1376/6471], Loss: 2.5559, Perplexity: 12.8824Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1377/6471], Loss: 2.5926, Perplexity: 13.3639Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1378/6471], Loss: 2.6902, Perplexity: 14.7352Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1379/6471], Loss: 2.6858, Perplexity: 14.6702Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1380/6471], Loss: 2.9246, Perplexity: 18.6276Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1381/6471], Loss: 2.4400, Perplexity: 11.4735Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1382/6471], Loss: 2.5166, Perplexity: 12.3860Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1383/6471], Loss: 2.6697, Perplexity: 14.4356Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1384/6471], Loss: 2.7235, Perplexity: 15.2332Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1385/6471], Loss: 3.1258, Perplexity: 22.7772Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1386/6471], Loss: 2.7873, Perplexity: 16.2366Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1387/6471], Loss: 2.6722, Perplexity: 14.4714Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1388/6471], Loss: 2.7455, Perplexity: 15.5730Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1389/6471], Loss: 2.7616, Perplexity: 15.8256Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1390/6471], Loss: 2.4653, Perplexity: 11.7665Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1391/6471], Loss: 2.4635, Perplexity: 11.7464Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1392/6471], Loss: 2.6118, Perplexity: 13.6232Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1393/6471], Loss: 2.6440, Perplexity: 14.0697Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1394/6471], Loss: 2.4164, Perplexity: 11.2051Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1395/6471], Loss: 2.7180, Perplexity: 15.1502Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1396/6471], Loss: 2.7200, Perplexity: 15.1801Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1397/6471], Loss: 2.4899, Perplexity: 12.0604Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1398/6471], Loss: 2.5879, Perplexity: 13.3024Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1399/6471], Loss: 2.5322, Perplexity: 12.5815Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1400/6471], Loss: 2.6999, Perplexity: 14.8789\n",
      "Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1401/6471], Loss: 2.4525, Perplexity: 11.6174Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1402/6471], Loss: 2.6728, Perplexity: 14.4802Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1403/6471], Loss: 2.4886, Perplexity: 12.0440Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1404/6471], Loss: 2.4299, Perplexity: 11.3581Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1405/6471], Loss: 2.5009, Perplexity: 12.1936Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1406/6471], Loss: 2.5727, Perplexity: 13.1007Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1407/6471], Loss: 2.5679, Perplexity: 13.0386Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1408/6471], Loss: 2.4586, Perplexity: 11.6886Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1409/6471], Loss: 2.8340, Perplexity: 17.0129Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1410/6471], Loss: 2.8564, Perplexity: 17.3979Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1411/6471], Loss: 2.4804, Perplexity: 11.9458Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1412/6471], Loss: 2.6215, Perplexity: 13.7562Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1413/6471], Loss: 2.5573, Perplexity: 12.9012Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1414/6471], Loss: 2.7698, Perplexity: 15.9557Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1415/6471], Loss: 2.5187, Perplexity: 12.4121Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1416/6471], Loss: 2.4004, Perplexity: 11.0273Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1417/6471], Loss: 2.4633, Perplexity: 11.7434Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1418/6471], Loss: 2.5995, Perplexity: 13.4564Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1419/6471], Loss: 2.4992, Perplexity: 12.1727Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1420/6471], Loss: 2.6316, Perplexity: 13.8960Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1421/6471], Loss: 2.4597, Perplexity: 11.7010Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1422/6471], Loss: 2.7675, Perplexity: 15.9189Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1423/6471], Loss: 2.8040, Perplexity: 16.5101Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1424/6471], Loss: 2.5412, Perplexity: 12.6943Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1425/6471], Loss: 2.6754, Perplexity: 14.5184Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1426/6471], Loss: 2.9600, Perplexity: 19.2981Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1427/6471], Loss: 2.6365, Perplexity: 13.9646Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1428/6471], Loss: 2.6259, Perplexity: 13.8175Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1429/6471], Loss: 2.3124, Perplexity: 10.0986Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1430/6471], Loss: 2.7023, Perplexity: 14.9139Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1431/6471], Loss: 2.5817, Perplexity: 13.2194Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1432/6471], Loss: 2.2861, Perplexity: 9.8362Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1433/6471], Loss: 2.4067, Perplexity: 11.0971Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1434/6471], Loss: 2.7779, Perplexity: 16.0859Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1435/6471], Loss: 2.6790, Perplexity: 14.5706Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1436/6471], Loss: 2.6107, Perplexity: 13.6092Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1437/6471], Loss: 3.2693, Perplexity: 26.2936Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1438/6471], Loss: 2.6438, Perplexity: 14.0668Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1439/6471], Loss: 2.5646, Perplexity: 12.9954Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1440/6471], Loss: 2.5318, Perplexity: 12.5759Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1441/6471], Loss: 2.3363, Perplexity: 10.3431Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1442/6471], Loss: 2.3540, Perplexity: 10.5277Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1443/6471], Loss: 2.6348, Perplexity: 13.9411Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1444/6471], Loss: 2.8888, Perplexity: 17.9723Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1445/6471], Loss: 2.5358, Perplexity: 12.6262Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1446/6471], Loss: 2.7669, Perplexity: 15.9087Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1447/6471], Loss: 2.8094, Perplexity: 16.5993Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1448/6471], Loss: 2.8118, Perplexity: 16.6401Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1449/6471], Loss: 2.6573, Perplexity: 14.2576Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1450/6471], Loss: 2.7271, Perplexity: 15.2892Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [1451/6471], Loss: 3.3101, Perplexity: 27.3870Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1452/6471], Loss: 2.8755, Perplexity: 17.7346Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1453/6471], Loss: 2.5350, Perplexity: 12.6167Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1454/6471], Loss: 3.0403, Perplexity: 20.9106Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1455/6471], Loss: 2.5989, Perplexity: 13.4483Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1456/6471], Loss: 2.4825, Perplexity: 11.9710Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1457/6471], Loss: 2.5860, Perplexity: 13.2763Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1458/6471], Loss: 3.0581, Perplexity: 21.2863Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1459/6471], Loss: 2.5997, Perplexity: 13.4593Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1460/6471], Loss: 2.4608, Perplexity: 11.7145Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1461/6471], Loss: 2.7324, Perplexity: 15.3696Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1462/6471], Loss: 2.6100, Perplexity: 13.5989Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1463/6471], Loss: 3.3996, Perplexity: 29.9514Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1464/6471], Loss: 2.5776, Perplexity: 13.1656Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1465/6471], Loss: 2.6658, Perplexity: 14.3797Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1466/6471], Loss: 2.6824, Perplexity: 14.6202Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1467/6471], Loss: 3.2150, Perplexity: 24.9039Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1468/6471], Loss: 2.5383, Perplexity: 12.6582Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1469/6471], Loss: 2.6164, Perplexity: 13.6865Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1470/6471], Loss: 2.7501, Perplexity: 15.6449Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1471/6471], Loss: 2.6493, Perplexity: 14.1446Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1472/6471], Loss: 2.6351, Perplexity: 13.9452Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1473/6471], Loss: 3.0228, Perplexity: 20.5493Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1474/6471], Loss: 2.8188, Perplexity: 16.7563Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1475/6471], Loss: 2.3919, Perplexity: 10.9342Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1476/6471], Loss: 2.4538, Perplexity: 11.6324Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1477/6471], Loss: 2.6441, Perplexity: 14.0702Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1478/6471], Loss: 2.3783, Perplexity: 10.7865Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1479/6471], Loss: 2.5708, Perplexity: 13.0760Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1480/6471], Loss: 2.7137, Perplexity: 15.0856Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1481/6471], Loss: 2.6005, Perplexity: 13.4704Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1482/6471], Loss: 2.6049, Perplexity: 13.5292Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1483/6471], Loss: 2.6109, Perplexity: 13.6115Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1484/6471], Loss: 2.5952, Perplexity: 13.3996Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1485/6471], Loss: 2.6973, Perplexity: 14.8398Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1486/6471], Loss: 2.5618, Perplexity: 12.9595Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1487/6471], Loss: 2.5675, Perplexity: 13.0326Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1488/6471], Loss: 2.7031, Perplexity: 14.9259Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1489/6471], Loss: 2.5711, Perplexity: 13.0803Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [1490/6471], Loss: 3.0410, Perplexity: 20.9252Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1491/6471], Loss: 2.4820, Perplexity: 11.9654Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1492/6471], Loss: 2.5901, Perplexity: 13.3315Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1493/6471], Loss: 2.3544, Perplexity: 10.5318Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1494/6471], Loss: 2.5958, Perplexity: 13.4076Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1495/6471], Loss: 2.6387, Perplexity: 13.9950Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1496/6471], Loss: 2.5452, Perplexity: 12.7453Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1497/6471], Loss: 2.9927, Perplexity: 19.9394Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1498/6471], Loss: 2.5529, Perplexity: 12.8442Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1499/6471], Loss: 2.7456, Perplexity: 15.5741Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1500/6471], Loss: 2.8352, Perplexity: 17.0340\n",
      "Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1501/6471], Loss: 2.8342, Perplexity: 17.0168Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1502/6471], Loss: 2.9134, Perplexity: 18.4187Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1503/6471], Loss: 2.6351, Perplexity: 13.9443Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1504/6471], Loss: 2.6525, Perplexity: 14.1900Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1505/6471], Loss: 2.4263, Perplexity: 11.3171Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1506/6471], Loss: 2.9300, Perplexity: 18.7283Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1507/6471], Loss: 2.5044, Perplexity: 12.2357Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1508/6471], Loss: 2.6643, Perplexity: 14.3575Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1509/6471], Loss: 2.3774, Perplexity: 10.7768Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1510/6471], Loss: 2.6804, Perplexity: 14.5916Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1511/6471], Loss: 2.9828, Perplexity: 19.7437Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1512/6471], Loss: 2.5141, Perplexity: 12.3559Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1513/6471], Loss: 2.9681, Perplexity: 19.4549Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1514/6471], Loss: 2.7627, Perplexity: 15.8418Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1515/6471], Loss: 2.6225, Perplexity: 13.7703Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1516/6471], Loss: 2.7736, Perplexity: 16.0154Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1517/6471], Loss: 2.5586, Perplexity: 12.9183Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1518/6471], Loss: 2.4796, Perplexity: 11.9365Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1519/6471], Loss: 2.7894, Perplexity: 16.2705Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1520/6471], Loss: 2.5774, Perplexity: 13.1627Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1521/6471], Loss: 2.2817, Perplexity: 9.7935Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1522/6471], Loss: 2.4830, Perplexity: 11.9777Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1523/6471], Loss: 2.4561, Perplexity: 11.6589Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1524/6471], Loss: 2.8589, Perplexity: 17.4427Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1525/6471], Loss: 2.6062, Perplexity: 13.5480Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1526/6471], Loss: 2.9640, Perplexity: 19.3748Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1527/6471], Loss: 2.3748, Perplexity: 10.7486Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1528/6471], Loss: 2.7808, Perplexity: 16.1312Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1529/6471], Loss: 2.5959, Perplexity: 13.4092Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1530/6471], Loss: 2.5174, Perplexity: 12.3965Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1531/6471], Loss: 2.6934, Perplexity: 14.7825Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1532/6471], Loss: 2.5508, Perplexity: 12.8168Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1533/6471], Loss: 2.6723, Perplexity: 14.4726Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1534/6471], Loss: 2.4829, Perplexity: 11.9764Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1535/6471], Loss: 2.5469, Perplexity: 12.7670Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1536/6471], Loss: 2.6016, Perplexity: 13.4849Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1537/6471], Loss: 2.5669, Perplexity: 13.0251Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1538/6471], Loss: 2.5435, Perplexity: 12.7235Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1539/6471], Loss: 2.7298, Perplexity: 15.3305Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1540/6471], Loss: 2.5169, Perplexity: 12.3899Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1541/6471], Loss: 2.9765, Perplexity: 19.6199Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1542/6471], Loss: 2.5858, Perplexity: 13.2744Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1543/6471], Loss: 2.8832, Perplexity: 17.8709Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1544/6471], Loss: 2.5015, Perplexity: 12.2006Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1545/6471], Loss: 2.3791, Perplexity: 10.7948Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1546/6471], Loss: 3.1704, Perplexity: 23.8171Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1547/6471], Loss: 2.4690, Perplexity: 11.8109Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1548/6471], Loss: 2.4061, Perplexity: 11.0911Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1549/6471], Loss: 2.5691, Perplexity: 13.0535Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1550/6471], Loss: 2.4567, Perplexity: 11.6657Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1551/6471], Loss: 2.6824, Perplexity: 14.6197Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1552/6471], Loss: 2.6896, Perplexity: 14.7258Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1553/6471], Loss: 2.5128, Perplexity: 12.3395Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1554/6471], Loss: 2.5013, Perplexity: 12.1982Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1555/6471], Loss: 2.4369, Perplexity: 11.4376Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1556/6471], Loss: 2.4970, Perplexity: 12.1461Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1557/6471], Loss: 2.7632, Perplexity: 15.8502Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1558/6471], Loss: 2.5187, Perplexity: 12.4124Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1559/6471], Loss: 2.6807, Perplexity: 14.5948Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1560/6471], Loss: 2.5485, Perplexity: 12.7881Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1561/6471], Loss: 2.8721, Perplexity: 17.6740Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1562/6471], Loss: 2.7201, Perplexity: 15.1819Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1563/6471], Loss: 2.6990, Perplexity: 14.8649Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1564/6471], Loss: 2.8698, Perplexity: 17.6335Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1565/6471], Loss: 2.4371, Perplexity: 11.4394Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1566/6471], Loss: 2.9537, Perplexity: 19.1775Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1567/6471], Loss: 2.4312, Perplexity: 11.3727Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1568/6471], Loss: 2.2483, Perplexity: 9.4720Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1569/6471], Loss: 2.5103, Perplexity: 12.3090Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1570/6471], Loss: 2.5273, Perplexity: 12.5199Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1571/6471], Loss: 2.4051, Perplexity: 11.0796Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1572/6471], Loss: 3.0707, Perplexity: 21.5579Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1573/6471], Loss: 2.6396, Perplexity: 14.0075Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1574/6471], Loss: 2.5017, Perplexity: 12.2037Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1575/6471], Loss: 2.5209, Perplexity: 12.4402Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1576/6471], Loss: 2.4766, Perplexity: 11.9003Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1577/6471], Loss: 2.7463, Perplexity: 15.5852Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1578/6471], Loss: 2.6349, Perplexity: 13.9425Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1579/6471], Loss: 2.7545, Perplexity: 15.7139Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1580/6471], Loss: 2.6544, Perplexity: 14.2161Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1581/6471], Loss: 2.4883, Perplexity: 12.0410Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1582/6471], Loss: 2.5258, Perplexity: 12.5008Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1583/6471], Loss: 2.5566, Perplexity: 12.8923Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1584/6471], Loss: 2.6650, Perplexity: 14.3678Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1585/6471], Loss: 2.8366, Perplexity: 17.0569Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1586/6471], Loss: 2.4080, Perplexity: 11.1117Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1587/6471], Loss: 2.7682, Perplexity: 15.9301Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1588/6471], Loss: 2.6434, Perplexity: 14.0604Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1589/6471], Loss: 2.5000, Perplexity: 12.1822Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1590/6471], Loss: 2.4461, Perplexity: 11.5431Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1591/6471], Loss: 2.5560, Perplexity: 12.8842Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1592/6471], Loss: 2.6812, Perplexity: 14.6028Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1593/6471], Loss: 2.6270, Perplexity: 13.8326Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1594/6471], Loss: 2.5149, Perplexity: 12.3649Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1595/6471], Loss: 2.7138, Perplexity: 15.0871Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1596/6471], Loss: 2.4548, Perplexity: 11.6441Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1597/6471], Loss: 2.6650, Perplexity: 14.3672Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1598/6471], Loss: 2.7172, Perplexity: 15.1378Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1599/6471], Loss: 2.4603, Perplexity: 11.7089Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1600/6471], Loss: 2.4863, Perplexity: 12.0168\n",
      "Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1601/6471], Loss: 2.5470, Perplexity: 12.7690Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1602/6471], Loss: 2.7617, Perplexity: 15.8260Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1603/6471], Loss: 2.6176, Perplexity: 13.7034Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1604/6471], Loss: 2.5527, Perplexity: 12.8417Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1605/6471], Loss: 2.6437, Perplexity: 14.0654Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1606/6471], Loss: 2.4547, Perplexity: 11.6435Shape of captions\n",
      "torch.Size([64, 24, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 25, 256])\n",
      "Epoch [1/3], Step [1607/6471], Loss: 3.5900, Perplexity: 36.2336Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1608/6471], Loss: 2.3276, Perplexity: 10.2529Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1609/6471], Loss: 2.6716, Perplexity: 14.4629Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1610/6471], Loss: 2.5788, Perplexity: 13.1809Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1611/6471], Loss: 2.5186, Perplexity: 12.4113Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1612/6471], Loss: 2.5412, Perplexity: 12.6947Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1613/6471], Loss: 2.5322, Perplexity: 12.5812Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1614/6471], Loss: 2.4306, Perplexity: 11.3660Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1615/6471], Loss: 2.7159, Perplexity: 15.1182Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1616/6471], Loss: 2.8169, Perplexity: 16.7257Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1617/6471], Loss: 2.5427, Perplexity: 12.7139Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1618/6471], Loss: 2.4511, Perplexity: 11.6008Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1619/6471], Loss: 2.3747, Perplexity: 10.7480Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1620/6471], Loss: 2.4450, Perplexity: 11.5306Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1621/6471], Loss: 2.6192, Perplexity: 13.7242Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1622/6471], Loss: 2.4791, Perplexity: 11.9307Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1623/6471], Loss: 2.4966, Perplexity: 12.1416Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1624/6471], Loss: 2.5677, Perplexity: 13.0360Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1625/6471], Loss: 3.2309, Perplexity: 25.3035Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1626/6471], Loss: 2.5325, Perplexity: 12.5852Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1627/6471], Loss: 2.3626, Perplexity: 10.6182Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1628/6471], Loss: 2.5492, Perplexity: 12.7963Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1629/6471], Loss: 2.7203, Perplexity: 15.1856Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1630/6471], Loss: 2.5084, Perplexity: 12.2854Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1631/6471], Loss: 2.6047, Perplexity: 13.5275Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1632/6471], Loss: 2.6120, Perplexity: 13.6263Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1633/6471], Loss: 2.4682, Perplexity: 11.8011Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1634/6471], Loss: 2.7982, Perplexity: 16.4158Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1635/6471], Loss: 2.8709, Perplexity: 17.6530Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1636/6471], Loss: 2.7772, Perplexity: 16.0737Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1637/6471], Loss: 2.3702, Perplexity: 10.6992Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1638/6471], Loss: 2.5118, Perplexity: 12.3273Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1639/6471], Loss: 2.3392, Perplexity: 10.3727Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1640/6471], Loss: 2.5878, Perplexity: 13.3007Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1641/6471], Loss: 2.5872, Perplexity: 13.2921Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1642/6471], Loss: 2.6889, Perplexity: 14.7158Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1643/6471], Loss: 2.5357, Perplexity: 12.6255Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1644/6471], Loss: 2.8279, Perplexity: 16.9097Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1645/6471], Loss: 2.4723, Perplexity: 11.8497Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1646/6471], Loss: 2.5453, Perplexity: 12.7475Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1647/6471], Loss: 2.7663, Perplexity: 15.9004Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1648/6471], Loss: 2.6838, Perplexity: 14.6401Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1649/6471], Loss: 2.7667, Perplexity: 15.9058Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1650/6471], Loss: 3.0294, Perplexity: 20.6845Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1651/6471], Loss: 2.6622, Perplexity: 14.3282Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [1652/6471], Loss: 3.0742, Perplexity: 21.6319Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1653/6471], Loss: 2.5050, Perplexity: 12.2433Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1654/6471], Loss: 2.5884, Perplexity: 13.3085Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1655/6471], Loss: 2.4537, Perplexity: 11.6319Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1656/6471], Loss: 2.6281, Perplexity: 13.8477Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1657/6471], Loss: 2.4183, Perplexity: 11.2266Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1658/6471], Loss: 2.4522, Perplexity: 11.6142Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1659/6471], Loss: 2.6026, Perplexity: 13.4993Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1660/6471], Loss: 2.5094, Perplexity: 12.2978Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1661/6471], Loss: 2.7199, Perplexity: 15.1789Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1662/6471], Loss: 2.4406, Perplexity: 11.4795Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1663/6471], Loss: 2.4691, Perplexity: 11.8116Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1664/6471], Loss: 2.5285, Perplexity: 12.5344Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1665/6471], Loss: 2.5950, Perplexity: 13.3968Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1666/6471], Loss: 2.6898, Perplexity: 14.7285Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1667/6471], Loss: 2.3573, Perplexity: 10.5629Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1668/6471], Loss: 2.5143, Perplexity: 12.3577Shape of captions\n",
      "torch.Size([64, 22, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 23, 256])\n",
      "Epoch [1/3], Step [1669/6471], Loss: 3.5746, Perplexity: 35.6812Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1670/6471], Loss: 2.6419, Perplexity: 14.0395Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1671/6471], Loss: 2.3146, Perplexity: 10.1207Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1672/6471], Loss: 2.5972, Perplexity: 13.4261Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1673/6471], Loss: 2.3735, Perplexity: 10.7353Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1674/6471], Loss: 2.5516, Perplexity: 12.8271Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1675/6471], Loss: 2.6369, Perplexity: 13.9701Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1676/6471], Loss: 2.5697, Perplexity: 13.0616Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1677/6471], Loss: 2.6298, Perplexity: 13.8703Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1678/6471], Loss: 2.8056, Perplexity: 16.5378Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1679/6471], Loss: 2.5172, Perplexity: 12.3935Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1680/6471], Loss: 2.2864, Perplexity: 9.8396Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1681/6471], Loss: 3.1137, Perplexity: 22.5037Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1682/6471], Loss: 2.4557, Perplexity: 11.6547Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1683/6471], Loss: 2.4541, Perplexity: 11.6365Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1684/6471], Loss: 2.4204, Perplexity: 11.2503Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1685/6471], Loss: 2.4481, Perplexity: 11.5662Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1686/6471], Loss: 2.4032, Perplexity: 11.0590Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1687/6471], Loss: 2.5944, Perplexity: 13.3879Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1688/6471], Loss: 2.6733, Perplexity: 14.4879Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1689/6471], Loss: 2.4262, Perplexity: 11.3162Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1690/6471], Loss: 2.9146, Perplexity: 18.4423Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1691/6471], Loss: 2.5713, Perplexity: 13.0829Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1692/6471], Loss: 2.7817, Perplexity: 16.1461Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1693/6471], Loss: 2.9567, Perplexity: 19.2351Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1694/6471], Loss: 3.3313, Perplexity: 27.9740Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1695/6471], Loss: 2.6850, Perplexity: 14.6585Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1696/6471], Loss: 2.2429, Perplexity: 9.4204Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1697/6471], Loss: 2.6899, Perplexity: 14.7301Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1698/6471], Loss: 2.5195, Perplexity: 12.4226Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1699/6471], Loss: 2.5303, Perplexity: 12.5573Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1700/6471], Loss: 2.7151, Perplexity: 15.1059\n",
      "Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1701/6471], Loss: 2.3601, Perplexity: 10.5924Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1702/6471], Loss: 2.6441, Perplexity: 14.0708Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1703/6471], Loss: 2.6478, Perplexity: 14.1235Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1704/6471], Loss: 2.4415, Perplexity: 11.4901Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1705/6471], Loss: 2.4511, Perplexity: 11.6016Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1706/6471], Loss: 2.4942, Perplexity: 12.1115Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1707/6471], Loss: 2.4109, Perplexity: 11.1443Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1708/6471], Loss: 2.2269, Perplexity: 9.2711Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1709/6471], Loss: 3.1651, Perplexity: 23.6916Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1710/6471], Loss: 2.4818, Perplexity: 11.9630Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1711/6471], Loss: 2.2779, Perplexity: 9.7560Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1712/6471], Loss: 2.8783, Perplexity: 17.7834Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1713/6471], Loss: 3.0462, Perplexity: 21.0354Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1714/6471], Loss: 2.1978, Perplexity: 9.0055Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1715/6471], Loss: 2.4489, Perplexity: 11.5757Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1716/6471], Loss: 2.6798, Perplexity: 14.5817Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1717/6471], Loss: 2.7350, Perplexity: 15.4097Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1718/6471], Loss: 2.4011, Perplexity: 11.0358Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1719/6471], Loss: 2.4848, Perplexity: 11.9988Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1720/6471], Loss: 2.4596, Perplexity: 11.6999Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1721/6471], Loss: 2.4921, Perplexity: 12.0862Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1722/6471], Loss: 2.5195, Perplexity: 12.4221Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1723/6471], Loss: 2.4512, Perplexity: 11.6018Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1724/6471], Loss: 2.4602, Perplexity: 11.7066Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1725/6471], Loss: 2.4661, Perplexity: 11.7762Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1726/6471], Loss: 2.9105, Perplexity: 18.3659Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1727/6471], Loss: 2.3861, Perplexity: 10.8714Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1728/6471], Loss: 2.6734, Perplexity: 14.4890Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1729/6471], Loss: 2.6890, Perplexity: 14.7164Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1730/6471], Loss: 2.5374, Perplexity: 12.6469Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1731/6471], Loss: 2.4658, Perplexity: 11.7733Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1732/6471], Loss: 2.6188, Perplexity: 13.7194Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1733/6471], Loss: 2.8027, Perplexity: 16.4885Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1734/6471], Loss: 2.5943, Perplexity: 13.3869Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1735/6471], Loss: 2.2415, Perplexity: 9.4072Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1736/6471], Loss: 2.6181, Perplexity: 13.7095Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1737/6471], Loss: 2.5901, Perplexity: 13.3311Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1738/6471], Loss: 2.7287, Perplexity: 15.3122Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1739/6471], Loss: 2.6041, Perplexity: 13.5186Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1740/6471], Loss: 2.7842, Perplexity: 16.1870Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1741/6471], Loss: 2.5032, Perplexity: 12.2216Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1742/6471], Loss: 2.7656, Perplexity: 15.8880Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1743/6471], Loss: 2.4574, Perplexity: 11.6741Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1744/6471], Loss: 2.7723, Perplexity: 15.9952Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1745/6471], Loss: 3.0302, Perplexity: 20.7017Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1746/6471], Loss: 2.6838, Perplexity: 14.6403Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1747/6471], Loss: 2.9737, Perplexity: 19.5650Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1748/6471], Loss: 2.3303, Perplexity: 10.2809Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [1749/6471], Loss: 2.9303, Perplexity: 18.7339Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1750/6471], Loss: 2.7285, Perplexity: 15.3094Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1751/6471], Loss: 2.5295, Perplexity: 12.5477Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1752/6471], Loss: 2.5622, Perplexity: 12.9640Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1753/6471], Loss: 2.5929, Perplexity: 13.3690Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1754/6471], Loss: 2.6469, Perplexity: 14.1106Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1755/6471], Loss: 2.5766, Perplexity: 13.1524Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1756/6471], Loss: 2.4539, Perplexity: 11.6337Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1757/6471], Loss: 2.5418, Perplexity: 12.7028Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1758/6471], Loss: 2.4611, Perplexity: 11.7179Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1759/6471], Loss: 2.6230, Perplexity: 13.7771Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1760/6471], Loss: 2.3333, Perplexity: 10.3122Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1761/6471], Loss: 2.4457, Perplexity: 11.5381Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1762/6471], Loss: 2.7784, Perplexity: 16.0926Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1763/6471], Loss: 2.5588, Perplexity: 12.9205Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1764/6471], Loss: 2.5884, Perplexity: 13.3082Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1765/6471], Loss: 2.7208, Perplexity: 15.1922Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1766/6471], Loss: 2.5614, Perplexity: 12.9540Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1767/6471], Loss: 2.9276, Perplexity: 18.6820Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1768/6471], Loss: 2.4325, Perplexity: 11.3878Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1769/6471], Loss: 2.3097, Perplexity: 10.0713Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1770/6471], Loss: 2.5493, Perplexity: 12.7986Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1771/6471], Loss: 2.4248, Perplexity: 11.2998Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1772/6471], Loss: 2.4575, Perplexity: 11.6759Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1773/6471], Loss: 2.3828, Perplexity: 10.8350Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1774/6471], Loss: 2.4176, Perplexity: 11.2191Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1775/6471], Loss: 2.3755, Perplexity: 10.7568Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1776/6471], Loss: 2.4279, Perplexity: 11.3348Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1777/6471], Loss: 2.4081, Perplexity: 11.1131Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [1778/6471], Loss: 2.8096, Perplexity: 16.6032Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1779/6471], Loss: 2.5849, Perplexity: 13.2620Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1780/6471], Loss: 2.5395, Perplexity: 12.6728Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1781/6471], Loss: 2.5065, Perplexity: 12.2622Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1782/6471], Loss: 2.5602, Perplexity: 12.9383Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1783/6471], Loss: 2.5624, Perplexity: 12.9668Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1784/6471], Loss: 2.3682, Perplexity: 10.6784Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1785/6471], Loss: 2.5856, Perplexity: 13.2707Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1786/6471], Loss: 2.3494, Perplexity: 10.4795Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1787/6471], Loss: 2.5644, Perplexity: 12.9933Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1788/6471], Loss: 2.8419, Perplexity: 17.1482Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1789/6471], Loss: 2.4228, Perplexity: 11.2774Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1790/6471], Loss: 2.7540, Perplexity: 15.7056Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [1791/6471], Loss: 3.1826, Perplexity: 24.1100Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1792/6471], Loss: 2.7472, Perplexity: 15.5996Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1793/6471], Loss: 2.5215, Perplexity: 12.4468Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1794/6471], Loss: 2.4582, Perplexity: 11.6839Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1795/6471], Loss: 2.7408, Perplexity: 15.5001Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1796/6471], Loss: 2.6943, Perplexity: 14.7945Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1797/6471], Loss: 2.6670, Perplexity: 14.3964Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1798/6471], Loss: 2.4311, Perplexity: 11.3709Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1799/6471], Loss: 2.7987, Perplexity: 16.4231Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1800/6471], Loss: 2.6225, Perplexity: 13.7703\n",
      "Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1801/6471], Loss: 2.3332, Perplexity: 10.3109Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1802/6471], Loss: 2.5974, Perplexity: 13.4282Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1803/6471], Loss: 2.6539, Perplexity: 14.2093Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1804/6471], Loss: 2.5426, Perplexity: 12.7123Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1805/6471], Loss: 2.5058, Perplexity: 12.2536Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1806/6471], Loss: 2.6435, Perplexity: 14.0624Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1807/6471], Loss: 2.5591, Perplexity: 12.9247Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1808/6471], Loss: 3.0136, Perplexity: 20.3602Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1809/6471], Loss: 2.3920, Perplexity: 10.9350Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1810/6471], Loss: 2.6793, Perplexity: 14.5748Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1811/6471], Loss: 2.5424, Perplexity: 12.7102Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1812/6471], Loss: 2.6022, Perplexity: 13.4934Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1813/6471], Loss: 2.4503, Perplexity: 11.5915Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1814/6471], Loss: 2.1909, Perplexity: 8.9437Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1815/6471], Loss: 2.4467, Perplexity: 11.5504Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1816/6471], Loss: 2.5564, Perplexity: 12.8891Shape of captions\n",
      "torch.Size([64, 21, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 22, 256])\n",
      "Epoch [1/3], Step [1817/6471], Loss: 3.3439, Perplexity: 28.3307Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1818/6471], Loss: 2.4717, Perplexity: 11.8427Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1819/6471], Loss: 2.8549, Perplexity: 17.3721Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1820/6471], Loss: 2.6445, Perplexity: 14.0760Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1821/6471], Loss: 2.5952, Perplexity: 13.3994Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1822/6471], Loss: 2.6011, Perplexity: 13.4785Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1823/6471], Loss: 3.0683, Perplexity: 21.5045Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1824/6471], Loss: 2.5565, Perplexity: 12.8911Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1825/6471], Loss: 2.7645, Perplexity: 15.8706Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1826/6471], Loss: 2.5971, Perplexity: 13.4242Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1827/6471], Loss: 2.5518, Perplexity: 12.8307Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1828/6471], Loss: 2.6223, Perplexity: 13.7673Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1829/6471], Loss: 2.6143, Perplexity: 13.6579Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1830/6471], Loss: 2.5924, Perplexity: 13.3616Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1831/6471], Loss: 2.7024, Perplexity: 14.9160Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1832/6471], Loss: 2.6873, Perplexity: 14.6918Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1833/6471], Loss: 2.5903, Perplexity: 13.3338Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1834/6471], Loss: 2.5275, Perplexity: 12.5223Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1835/6471], Loss: 2.5005, Perplexity: 12.1884Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1836/6471], Loss: 2.7040, Perplexity: 14.9398Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1837/6471], Loss: 2.7252, Perplexity: 15.2601Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1838/6471], Loss: 2.4891, Perplexity: 12.0507Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1839/6471], Loss: 2.4980, Perplexity: 12.1585Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1840/6471], Loss: 2.5763, Perplexity: 13.1479Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1841/6471], Loss: 2.1492, Perplexity: 8.5782Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1842/6471], Loss: 2.7684, Perplexity: 15.9336Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1843/6471], Loss: 2.4743, Perplexity: 11.8739Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1844/6471], Loss: 2.3085, Perplexity: 10.0594Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1845/6471], Loss: 2.4178, Perplexity: 11.2209Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1846/6471], Loss: 2.5398, Perplexity: 12.6777Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1847/6471], Loss: 2.1084, Perplexity: 8.2354Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1848/6471], Loss: 2.6759, Perplexity: 14.5251Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1849/6471], Loss: 2.5666, Perplexity: 13.0218Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1850/6471], Loss: 2.4915, Perplexity: 12.0797Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1851/6471], Loss: 2.4955, Perplexity: 12.1275Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1852/6471], Loss: 2.3789, Perplexity: 10.7927Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1853/6471], Loss: 2.6268, Perplexity: 13.8292Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1854/6471], Loss: 2.6500, Perplexity: 14.1534Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1855/6471], Loss: 3.1518, Perplexity: 23.3775Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1856/6471], Loss: 2.6684, Perplexity: 14.4163Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1857/6471], Loss: 2.6043, Perplexity: 13.5223Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1858/6471], Loss: 2.5401, Perplexity: 12.6805Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1859/6471], Loss: 2.6190, Perplexity: 13.7224Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1860/6471], Loss: 2.6705, Perplexity: 14.4475Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1861/6471], Loss: 2.5828, Perplexity: 13.2343Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1862/6471], Loss: 2.5512, Perplexity: 12.8220Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1863/6471], Loss: 2.5450, Perplexity: 12.7431Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1864/6471], Loss: 2.7948, Perplexity: 16.3594Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1865/6471], Loss: 2.3659, Perplexity: 10.6538Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1866/6471], Loss: 2.3273, Perplexity: 10.2500Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1867/6471], Loss: 2.5342, Perplexity: 12.6057Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1868/6471], Loss: 2.2081, Perplexity: 9.0981Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1869/6471], Loss: 2.3790, Perplexity: 10.7936Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1870/6471], Loss: 2.4329, Perplexity: 11.3917Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1871/6471], Loss: 2.4193, Perplexity: 11.2375Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1872/6471], Loss: 2.8707, Perplexity: 17.6501Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1873/6471], Loss: 2.3412, Perplexity: 10.3932Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1874/6471], Loss: 2.6040, Perplexity: 13.5178Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1875/6471], Loss: 2.5550, Perplexity: 12.8710Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1876/6471], Loss: 2.4850, Perplexity: 12.0011Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1877/6471], Loss: 2.6487, Perplexity: 14.1354Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1878/6471], Loss: 2.6547, Perplexity: 14.2211Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1879/6471], Loss: 2.4958, Perplexity: 12.1320Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1880/6471], Loss: 2.4079, Perplexity: 11.1112Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1881/6471], Loss: 2.5158, Perplexity: 12.3764Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1882/6471], Loss: 2.3558, Perplexity: 10.5467Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1883/6471], Loss: 2.2130, Perplexity: 9.1430Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1884/6471], Loss: 2.3566, Perplexity: 10.5547Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1885/6471], Loss: 2.6146, Perplexity: 13.6618Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1886/6471], Loss: 2.5917, Perplexity: 13.3521Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1887/6471], Loss: 2.5591, Perplexity: 12.9247Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1888/6471], Loss: 2.5364, Perplexity: 12.6338Shape of captions\n",
      "torch.Size([64, 23, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 24, 256])\n",
      "Epoch [1/3], Step [1889/6471], Loss: 3.5136, Perplexity: 33.5686Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1890/6471], Loss: 2.4921, Perplexity: 12.0866Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1891/6471], Loss: 2.2434, Perplexity: 9.4255Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1892/6471], Loss: 2.4141, Perplexity: 11.1795Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1893/6471], Loss: 2.4494, Perplexity: 11.5811Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1894/6471], Loss: 2.6252, Perplexity: 13.8079Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1895/6471], Loss: 2.6791, Perplexity: 14.5714Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1896/6471], Loss: 2.7117, Perplexity: 15.0544Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1897/6471], Loss: 2.4990, Perplexity: 12.1706Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1898/6471], Loss: 2.4842, Perplexity: 11.9912Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1899/6471], Loss: 2.3907, Perplexity: 10.9217Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1900/6471], Loss: 2.5995, Perplexity: 13.4568\n",
      "Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1901/6471], Loss: 2.2434, Perplexity: 9.4258Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1902/6471], Loss: 2.3314, Perplexity: 10.2926Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1903/6471], Loss: 2.5401, Perplexity: 12.6804Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1904/6471], Loss: 2.4976, Perplexity: 12.1528Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1905/6471], Loss: 2.4121, Perplexity: 11.1575Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1906/6471], Loss: 2.4830, Perplexity: 11.9769Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1907/6471], Loss: 2.3997, Perplexity: 11.0201Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1908/6471], Loss: 2.3006, Perplexity: 9.9800Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1909/6471], Loss: 2.5489, Perplexity: 12.7930Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [1910/6471], Loss: 3.2762, Perplexity: 26.4760Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1911/6471], Loss: 2.3913, Perplexity: 10.9275Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [1912/6471], Loss: 3.2101, Perplexity: 24.7818Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1913/6471], Loss: 2.3475, Perplexity: 10.4590Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1914/6471], Loss: 2.3489, Perplexity: 10.4736Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1915/6471], Loss: 2.4028, Perplexity: 11.0546Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1916/6471], Loss: 2.4011, Perplexity: 11.0352Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1917/6471], Loss: 2.6412, Perplexity: 14.0303Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1918/6471], Loss: 2.3921, Perplexity: 10.9366Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1919/6471], Loss: 2.4734, Perplexity: 11.8632Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1920/6471], Loss: 2.3710, Perplexity: 10.7085Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1921/6471], Loss: 2.5467, Perplexity: 12.7646Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1922/6471], Loss: 2.2567, Perplexity: 9.5515Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1923/6471], Loss: 2.5631, Perplexity: 12.9759Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1924/6471], Loss: 2.8952, Perplexity: 18.0867Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1925/6471], Loss: 2.5987, Perplexity: 13.4469Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1926/6471], Loss: 2.2687, Perplexity: 9.6668Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1927/6471], Loss: 2.6397, Perplexity: 14.0091Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1928/6471], Loss: 2.5677, Perplexity: 13.0361Shape of captions\n",
      "torch.Size([64, 30, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 31, 256])\n",
      "Epoch [1/3], Step [1929/6471], Loss: 3.9706, Perplexity: 53.0144Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1930/6471], Loss: 2.2867, Perplexity: 9.8428Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1931/6471], Loss: 2.4570, Perplexity: 11.6695Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1932/6471], Loss: 2.7341, Perplexity: 15.3954Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1933/6471], Loss: 2.3636, Perplexity: 10.6293Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1934/6471], Loss: 2.4359, Perplexity: 11.4261Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1935/6471], Loss: 2.4957, Perplexity: 12.1306Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1936/6471], Loss: 2.4741, Perplexity: 11.8708Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1937/6471], Loss: 2.5268, Perplexity: 12.5136Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1938/6471], Loss: 2.9057, Perplexity: 18.2773Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1939/6471], Loss: 2.3854, Perplexity: 10.8636Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1940/6471], Loss: 2.5868, Perplexity: 13.2873Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1941/6471], Loss: 2.6238, Perplexity: 13.7873Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1942/6471], Loss: 2.3883, Perplexity: 10.8950Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1943/6471], Loss: 2.4720, Perplexity: 11.8465Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1944/6471], Loss: 2.4086, Perplexity: 11.1180Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1945/6471], Loss: 2.5958, Perplexity: 13.4075Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1946/6471], Loss: 2.6466, Perplexity: 14.1064Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1947/6471], Loss: 2.4066, Perplexity: 11.0960Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1948/6471], Loss: 2.4125, Perplexity: 11.1620Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [1949/6471], Loss: 2.8953, Perplexity: 18.0886Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1950/6471], Loss: 2.9182, Perplexity: 18.5082Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1951/6471], Loss: 2.4802, Perplexity: 11.9441Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1952/6471], Loss: 2.3899, Perplexity: 10.9128Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1953/6471], Loss: 2.5491, Perplexity: 12.7956Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1954/6471], Loss: 2.3959, Perplexity: 10.9786Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1955/6471], Loss: 2.3041, Perplexity: 10.0151Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1956/6471], Loss: 2.6249, Perplexity: 13.8036Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1957/6471], Loss: 2.4861, Perplexity: 12.0146Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1958/6471], Loss: 2.9372, Perplexity: 18.8629Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1959/6471], Loss: 2.3076, Perplexity: 10.0507Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1960/6471], Loss: 2.5458, Perplexity: 12.7533Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1961/6471], Loss: 2.5675, Perplexity: 13.0337Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [1962/6471], Loss: 3.0731, Perplexity: 21.6096Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1963/6471], Loss: 2.5398, Perplexity: 12.6768Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1964/6471], Loss: 2.6358, Perplexity: 13.9546Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1965/6471], Loss: 2.7849, Perplexity: 16.1981Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1966/6471], Loss: 2.3716, Perplexity: 10.7146Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1967/6471], Loss: 2.6660, Perplexity: 14.3816Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1968/6471], Loss: 2.7804, Perplexity: 16.1254Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1969/6471], Loss: 2.2117, Perplexity: 9.1308Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1970/6471], Loss: 2.4536, Perplexity: 11.6307Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1971/6471], Loss: 2.4114, Perplexity: 11.1500Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1972/6471], Loss: 2.7504, Perplexity: 15.6494Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1973/6471], Loss: 2.3097, Perplexity: 10.0718Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1974/6471], Loss: 2.3761, Perplexity: 10.7627Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1975/6471], Loss: 2.3488, Perplexity: 10.4732Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [1976/6471], Loss: 2.5324, Perplexity: 12.5842Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1977/6471], Loss: 2.4754, Perplexity: 11.8870Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [1978/6471], Loss: 2.9703, Perplexity: 19.4971Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [1979/6471], Loss: 2.6250, Perplexity: 13.8047Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1980/6471], Loss: 2.2319, Perplexity: 9.3178Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [1981/6471], Loss: 2.6613, Perplexity: 14.3147Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [1982/6471], Loss: 2.5782, Perplexity: 13.1731Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1983/6471], Loss: 2.3200, Perplexity: 10.1760Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1984/6471], Loss: 2.4132, Perplexity: 11.1694Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1985/6471], Loss: 2.4629, Perplexity: 11.7385Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [1986/6471], Loss: 2.5239, Perplexity: 12.4767Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1987/6471], Loss: 2.3072, Perplexity: 10.0458Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1988/6471], Loss: 2.5698, Perplexity: 13.0629Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1989/6471], Loss: 2.5914, Perplexity: 13.3487Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1990/6471], Loss: 2.2541, Perplexity: 9.5266Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1991/6471], Loss: 2.4289, Perplexity: 11.3459Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1992/6471], Loss: 2.2218, Perplexity: 9.2238Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1993/6471], Loss: 2.4043, Perplexity: 11.0710Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1994/6471], Loss: 2.2742, Perplexity: 9.7202Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1995/6471], Loss: 2.1922, Perplexity: 8.9553Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [1996/6471], Loss: 2.7730, Perplexity: 16.0065Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [1997/6471], Loss: 2.4981, Perplexity: 12.1591Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1998/6471], Loss: 2.3577, Perplexity: 10.5665Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [1999/6471], Loss: 2.5523, Perplexity: 12.8366Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2000/6471], Loss: 2.3961, Perplexity: 10.9806\n",
      "Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2001/6471], Loss: 2.3503, Perplexity: 10.4886Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2002/6471], Loss: 2.6866, Perplexity: 14.6814Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2003/6471], Loss: 2.4786, Perplexity: 11.9241Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2004/6471], Loss: 2.4449, Perplexity: 11.5292Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2005/6471], Loss: 2.5050, Perplexity: 12.2433Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2006/6471], Loss: 2.5982, Perplexity: 13.4398Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2007/6471], Loss: 2.4736, Perplexity: 11.8651Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2008/6471], Loss: 2.6924, Perplexity: 14.7667Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2009/6471], Loss: 2.3731, Perplexity: 10.7306Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2010/6471], Loss: 2.4334, Perplexity: 11.3970Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2011/6471], Loss: 2.3633, Perplexity: 10.6255Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2012/6471], Loss: 2.6332, Perplexity: 13.9182Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2013/6471], Loss: 2.2927, Perplexity: 9.9015Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2014/6471], Loss: 2.5639, Perplexity: 12.9869Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2015/6471], Loss: 2.5237, Perplexity: 12.4748Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2016/6471], Loss: 2.4809, Perplexity: 11.9520Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2017/6471], Loss: 2.3877, Perplexity: 10.8888Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2018/6471], Loss: 2.6583, Perplexity: 14.2725Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2019/6471], Loss: 2.5057, Perplexity: 12.2527Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2020/6471], Loss: 2.4647, Perplexity: 11.7605Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2021/6471], Loss: 2.6262, Perplexity: 13.8215Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2022/6471], Loss: 2.5032, Perplexity: 12.2210Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2023/6471], Loss: 2.4944, Perplexity: 12.1139Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2024/6471], Loss: 2.6446, Perplexity: 14.0777Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2025/6471], Loss: 2.5993, Perplexity: 13.4542Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2026/6471], Loss: 2.4217, Perplexity: 11.2647Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2027/6471], Loss: 2.4747, Perplexity: 11.8779Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2028/6471], Loss: 2.4456, Perplexity: 11.5372Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2029/6471], Loss: 2.3622, Perplexity: 10.6138Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2030/6471], Loss: 2.2510, Perplexity: 9.4972Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2031/6471], Loss: 2.4769, Perplexity: 11.9044Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2032/6471], Loss: 2.3208, Perplexity: 10.1836Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2033/6471], Loss: 2.3572, Perplexity: 10.5616Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2034/6471], Loss: 2.5008, Perplexity: 12.1918Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2035/6471], Loss: 2.2942, Perplexity: 9.9162Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2036/6471], Loss: 2.5187, Perplexity: 12.4122Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2037/6471], Loss: 2.3942, Perplexity: 10.9590Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2038/6471], Loss: 2.5049, Perplexity: 12.2429Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2039/6471], Loss: 2.7600, Perplexity: 15.8002Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2040/6471], Loss: 2.7280, Perplexity: 15.3024Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2041/6471], Loss: 2.5147, Perplexity: 12.3634Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [2042/6471], Loss: 3.4897, Perplexity: 32.7777Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2043/6471], Loss: 2.3759, Perplexity: 10.7605Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2044/6471], Loss: 2.3948, Perplexity: 10.9661Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2045/6471], Loss: 2.2868, Perplexity: 9.8438Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2046/6471], Loss: 2.4526, Perplexity: 11.6183Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2047/6471], Loss: 2.4932, Perplexity: 12.0998Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2048/6471], Loss: 2.9064, Perplexity: 18.2899Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2049/6471], Loss: 2.4183, Perplexity: 11.2265Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2050/6471], Loss: 2.3127, Perplexity: 10.1013Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2051/6471], Loss: 2.2937, Perplexity: 9.9115Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2052/6471], Loss: 2.4259, Perplexity: 11.3123Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2053/6471], Loss: 2.3012, Perplexity: 9.9865Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2054/6471], Loss: 2.3495, Perplexity: 10.4808Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2055/6471], Loss: 2.7910, Perplexity: 16.2970Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2056/6471], Loss: 2.0491, Perplexity: 7.7606Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2057/6471], Loss: 2.5581, Perplexity: 12.9109Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2058/6471], Loss: 2.6137, Perplexity: 13.6488Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2059/6471], Loss: 2.6924, Perplexity: 14.7665Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2060/6471], Loss: 2.3216, Perplexity: 10.1916Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2061/6471], Loss: 2.4555, Perplexity: 11.6520Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2062/6471], Loss: 2.4909, Perplexity: 12.0721Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2063/6471], Loss: 2.2788, Perplexity: 9.7653Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2064/6471], Loss: 2.3093, Perplexity: 10.0677Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2065/6471], Loss: 2.4036, Perplexity: 11.0627Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2066/6471], Loss: 2.3047, Perplexity: 10.0209Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2067/6471], Loss: 2.4887, Perplexity: 12.0459Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2068/6471], Loss: 2.7046, Perplexity: 14.9490Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [2069/6471], Loss: 3.1540, Perplexity: 23.4288Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2070/6471], Loss: 2.2931, Perplexity: 9.9056Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2071/6471], Loss: 2.1835, Perplexity: 8.8773Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2072/6471], Loss: 2.4840, Perplexity: 11.9887Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2073/6471], Loss: 2.4836, Perplexity: 11.9844Shape of captions\n",
      "torch.Size([64, 24, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 25, 256])\n",
      "Epoch [1/3], Step [2074/6471], Loss: 3.5065, Perplexity: 33.3300Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2075/6471], Loss: 2.4775, Perplexity: 11.9109Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [2076/6471], Loss: 2.6203, Perplexity: 13.7396Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2077/6471], Loss: 2.6079, Perplexity: 13.5704Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2078/6471], Loss: 2.4996, Perplexity: 12.1773Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2079/6471], Loss: 2.5462, Perplexity: 12.7580Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2080/6471], Loss: 2.4160, Perplexity: 11.2010Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2081/6471], Loss: 2.4728, Perplexity: 11.8558Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2082/6471], Loss: 2.5781, Perplexity: 13.1722Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2083/6471], Loss: 2.4091, Perplexity: 11.1245Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2084/6471], Loss: 2.4483, Perplexity: 11.5689Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2085/6471], Loss: 2.0958, Perplexity: 8.1323Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2086/6471], Loss: 2.3223, Perplexity: 10.1990Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2087/6471], Loss: 2.3217, Perplexity: 10.1928Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2088/6471], Loss: 2.6902, Perplexity: 14.7346Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2089/6471], Loss: 2.4524, Perplexity: 11.6165Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2090/6471], Loss: 2.6812, Perplexity: 14.6023Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2091/6471], Loss: 2.5541, Perplexity: 12.8593Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2092/6471], Loss: 2.4298, Perplexity: 11.3571Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2093/6471], Loss: 2.3377, Perplexity: 10.3578Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2094/6471], Loss: 2.3719, Perplexity: 10.7175Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2095/6471], Loss: 2.5250, Perplexity: 12.4908Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2096/6471], Loss: 2.3198, Perplexity: 10.1737Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2097/6471], Loss: 2.1243, Perplexity: 8.3672Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2098/6471], Loss: 2.3734, Perplexity: 10.7337Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2099/6471], Loss: 2.2381, Perplexity: 9.3757Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2100/6471], Loss: 2.3605, Perplexity: 10.5962\n",
      "Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2101/6471], Loss: 2.5715, Perplexity: 13.0848Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2102/6471], Loss: 2.9855, Perplexity: 19.7963Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2103/6471], Loss: 2.5521, Perplexity: 12.8346Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2104/6471], Loss: 2.3771, Perplexity: 10.7736Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2105/6471], Loss: 2.5730, Perplexity: 13.1049Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2106/6471], Loss: 2.5946, Perplexity: 13.3910Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2107/6471], Loss: 2.5347, Perplexity: 12.6123Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2108/6471], Loss: 2.4894, Perplexity: 12.0545Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2109/6471], Loss: 2.4150, Perplexity: 11.1901Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2110/6471], Loss: 2.9738, Perplexity: 19.5663Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2111/6471], Loss: 2.3541, Perplexity: 10.5283Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2112/6471], Loss: 2.4817, Perplexity: 11.9617Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2113/6471], Loss: 2.2085, Perplexity: 9.1024Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2114/6471], Loss: 2.3230, Perplexity: 10.2057Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2115/6471], Loss: 2.3966, Perplexity: 10.9862Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2116/6471], Loss: 2.5130, Perplexity: 12.3417Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2117/6471], Loss: 2.4979, Perplexity: 12.1569Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2118/6471], Loss: 2.9140, Perplexity: 18.4308Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2119/6471], Loss: 2.3888, Perplexity: 10.9001Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2120/6471], Loss: 2.5829, Perplexity: 13.2361Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2121/6471], Loss: 2.4594, Perplexity: 11.6984Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2122/6471], Loss: 2.5468, Perplexity: 12.7659Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2123/6471], Loss: 2.5833, Perplexity: 13.2402Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2124/6471], Loss: 2.5387, Perplexity: 12.6628Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2125/6471], Loss: 2.4216, Perplexity: 11.2643Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2126/6471], Loss: 2.5984, Perplexity: 13.4423Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2127/6471], Loss: 2.3365, Perplexity: 10.3452Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2128/6471], Loss: 2.3235, Perplexity: 10.2112Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2129/6471], Loss: 2.4850, Perplexity: 12.0014Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2130/6471], Loss: 2.5387, Perplexity: 12.6626Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2131/6471], Loss: 2.4565, Perplexity: 11.6638Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2132/6471], Loss: 2.5533, Perplexity: 12.8498Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2133/6471], Loss: 2.8088, Perplexity: 16.5906Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2134/6471], Loss: 2.4731, Perplexity: 11.8595Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2135/6471], Loss: 2.4317, Perplexity: 11.3783Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2136/6471], Loss: 2.6023, Perplexity: 13.4941Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2137/6471], Loss: 2.3251, Perplexity: 10.2273Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2138/6471], Loss: 2.4436, Perplexity: 11.5149Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2139/6471], Loss: 2.4634, Perplexity: 11.7443Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2140/6471], Loss: 2.2445, Perplexity: 9.4353Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2141/6471], Loss: 2.5898, Perplexity: 13.3269Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2142/6471], Loss: 3.0797, Perplexity: 21.7525Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2143/6471], Loss: 2.6238, Perplexity: 13.7875Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2144/6471], Loss: 2.3976, Perplexity: 10.9965Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2145/6471], Loss: 2.5488, Perplexity: 12.7915Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2146/6471], Loss: 2.8187, Perplexity: 16.7556Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2147/6471], Loss: 2.6941, Perplexity: 14.7918Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2148/6471], Loss: 2.6275, Perplexity: 13.8386Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2149/6471], Loss: 2.4628, Perplexity: 11.7376Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2150/6471], Loss: 2.4250, Perplexity: 11.3024Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2151/6471], Loss: 2.4627, Perplexity: 11.7370Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2152/6471], Loss: 2.4324, Perplexity: 11.3858Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2153/6471], Loss: 2.4446, Perplexity: 11.5256Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2154/6471], Loss: 2.2102, Perplexity: 9.1173Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2155/6471], Loss: 2.5166, Perplexity: 12.3870Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2156/6471], Loss: 2.2743, Perplexity: 9.7208Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2157/6471], Loss: 2.1405, Perplexity: 8.5034Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2158/6471], Loss: 2.6060, Perplexity: 13.5448Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2159/6471], Loss: 2.3747, Perplexity: 10.7475Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2160/6471], Loss: 2.7781, Perplexity: 16.0877Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2161/6471], Loss: 2.3349, Perplexity: 10.3283Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2162/6471], Loss: 2.4453, Perplexity: 11.5343Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2163/6471], Loss: 2.4755, Perplexity: 11.8882Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2164/6471], Loss: 2.4445, Perplexity: 11.5250Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2165/6471], Loss: 2.2341, Perplexity: 9.3383Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2166/6471], Loss: 2.2574, Perplexity: 9.5582Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2167/6471], Loss: 2.3796, Perplexity: 10.8011Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2168/6471], Loss: 2.5242, Perplexity: 12.4809Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2169/6471], Loss: 2.4060, Perplexity: 11.0899Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2170/6471], Loss: 2.7619, Perplexity: 15.8301Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2171/6471], Loss: 2.6396, Perplexity: 14.0075Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2172/6471], Loss: 2.3565, Perplexity: 10.5537Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2173/6471], Loss: 2.4345, Perplexity: 11.4105Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2174/6471], Loss: 2.5099, Perplexity: 12.3031Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2175/6471], Loss: 2.4564, Perplexity: 11.6623Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2176/6471], Loss: 2.1233, Perplexity: 8.3584Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2177/6471], Loss: 2.6851, Perplexity: 14.6593Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2178/6471], Loss: 2.4710, Perplexity: 11.8340Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2179/6471], Loss: 2.6645, Perplexity: 14.3609Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2180/6471], Loss: 2.5717, Perplexity: 13.0880Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2181/6471], Loss: 2.4097, Perplexity: 11.1310Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2182/6471], Loss: 2.3254, Perplexity: 10.2309Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2183/6471], Loss: 2.3975, Perplexity: 10.9956Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2184/6471], Loss: 2.2741, Perplexity: 9.7195Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2185/6471], Loss: 2.3058, Perplexity: 10.0317Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2186/6471], Loss: 3.1221, Perplexity: 22.6943Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2187/6471], Loss: 2.0597, Perplexity: 7.8434Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2188/6471], Loss: 2.2811, Perplexity: 9.7873Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2189/6471], Loss: 2.4108, Perplexity: 11.1428Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2190/6471], Loss: 2.1229, Perplexity: 8.3557Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2191/6471], Loss: 2.3218, Perplexity: 10.1940Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2192/6471], Loss: 2.3545, Perplexity: 10.5333Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2193/6471], Loss: 2.5653, Perplexity: 13.0049Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2194/6471], Loss: 2.6593, Perplexity: 14.2868Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2195/6471], Loss: 2.4617, Perplexity: 11.7253Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2196/6471], Loss: 2.3640, Perplexity: 10.6338Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2197/6471], Loss: 2.2751, Perplexity: 9.7290Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2198/6471], Loss: 2.2969, Perplexity: 9.9437Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2199/6471], Loss: 2.3042, Perplexity: 10.0157Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2200/6471], Loss: 2.3972, Perplexity: 10.9925\n",
      "Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2201/6471], Loss: 2.4491, Perplexity: 11.5783Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2202/6471], Loss: 2.5514, Perplexity: 12.8250Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2203/6471], Loss: 2.7764, Perplexity: 16.0606Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2204/6471], Loss: 2.5498, Perplexity: 12.8049Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2205/6471], Loss: 2.3599, Perplexity: 10.5904Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2206/6471], Loss: 2.4340, Perplexity: 11.4050Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2207/6471], Loss: 2.4729, Perplexity: 11.8562Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2208/6471], Loss: 2.6422, Perplexity: 14.0445Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2209/6471], Loss: 2.4887, Perplexity: 12.0458Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2210/6471], Loss: 2.5541, Perplexity: 12.8599Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2211/6471], Loss: 2.4740, Perplexity: 11.8702Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2212/6471], Loss: 2.7115, Perplexity: 15.0513Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2213/6471], Loss: 2.4147, Perplexity: 11.1866Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2214/6471], Loss: 2.6481, Perplexity: 14.1277Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [2215/6471], Loss: 3.2404, Perplexity: 25.5431Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2216/6471], Loss: 2.4223, Perplexity: 11.2714Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2217/6471], Loss: 2.3759, Perplexity: 10.7605Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2218/6471], Loss: 2.4849, Perplexity: 12.0003Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2219/6471], Loss: 2.3221, Perplexity: 10.1976Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2220/6471], Loss: 2.4312, Perplexity: 11.3721Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2221/6471], Loss: 2.2693, Perplexity: 9.6725Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2222/6471], Loss: 2.6495, Perplexity: 14.1465Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2223/6471], Loss: 2.4968, Perplexity: 12.1435Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2224/6471], Loss: 2.7754, Perplexity: 16.0458Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2225/6471], Loss: 2.3555, Perplexity: 10.5433Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2226/6471], Loss: 2.4748, Perplexity: 11.8789Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2227/6471], Loss: 2.6479, Perplexity: 14.1242Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2228/6471], Loss: 2.3852, Perplexity: 10.8616Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2229/6471], Loss: 2.3930, Perplexity: 10.9463Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2230/6471], Loss: 2.3009, Perplexity: 9.9832Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [2231/6471], Loss: 3.0563, Perplexity: 21.2497Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2232/6471], Loss: 2.3306, Perplexity: 10.2844Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2233/6471], Loss: 2.3677, Perplexity: 10.6724Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2234/6471], Loss: 2.2547, Perplexity: 9.5326Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2235/6471], Loss: 2.3397, Perplexity: 10.3784Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2236/6471], Loss: 2.2900, Perplexity: 9.8745Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2237/6471], Loss: 2.6075, Perplexity: 13.5655Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2238/6471], Loss: 2.7665, Perplexity: 15.9034Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2239/6471], Loss: 2.2562, Perplexity: 9.5466Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2240/6471], Loss: 2.2438, Perplexity: 9.4294Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2241/6471], Loss: 2.4891, Perplexity: 12.0499Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2242/6471], Loss: 2.5108, Perplexity: 12.3152Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2243/6471], Loss: 3.0583, Perplexity: 21.2916Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2244/6471], Loss: 2.3786, Perplexity: 10.7897Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2245/6471], Loss: 2.6671, Perplexity: 14.3980Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2246/6471], Loss: 2.1892, Perplexity: 8.9278Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2247/6471], Loss: 2.3717, Perplexity: 10.7156Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2248/6471], Loss: 2.6868, Perplexity: 14.6846Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2249/6471], Loss: 2.4645, Perplexity: 11.7571Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2250/6471], Loss: 2.4413, Perplexity: 11.4880Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2251/6471], Loss: 2.2655, Perplexity: 9.6362Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2252/6471], Loss: 2.5006, Perplexity: 12.1896Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2253/6471], Loss: 2.5270, Perplexity: 12.5155Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2254/6471], Loss: 2.3644, Perplexity: 10.6375Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2255/6471], Loss: 2.4074, Perplexity: 11.1049Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2256/6471], Loss: 2.5474, Perplexity: 12.7744Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2257/6471], Loss: 2.4152, Perplexity: 11.1925Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2258/6471], Loss: 2.4627, Perplexity: 11.7370Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2259/6471], Loss: 2.4693, Perplexity: 11.8144Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2260/6471], Loss: 2.2598, Perplexity: 9.5813Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2261/6471], Loss: 2.3907, Perplexity: 10.9207Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2262/6471], Loss: 2.4068, Perplexity: 11.0981Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2263/6471], Loss: 2.6156, Perplexity: 13.6755Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2264/6471], Loss: 2.3663, Perplexity: 10.6579Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2265/6471], Loss: 2.5473, Perplexity: 12.7730Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2266/6471], Loss: 2.4799, Perplexity: 11.9402Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2267/6471], Loss: 2.3321, Perplexity: 10.3000Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2268/6471], Loss: 2.4301, Perplexity: 11.3601Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2269/6471], Loss: 2.7528, Perplexity: 15.6869Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2270/6471], Loss: 2.4489, Perplexity: 11.5761Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2271/6471], Loss: 2.6222, Perplexity: 13.7654Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2272/6471], Loss: 2.3140, Perplexity: 10.1148Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2273/6471], Loss: 2.1390, Perplexity: 8.4911Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2274/6471], Loss: 2.4402, Perplexity: 11.4749Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2275/6471], Loss: 2.2542, Perplexity: 9.5275Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2276/6471], Loss: 2.6061, Perplexity: 13.5466Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2277/6471], Loss: 2.6349, Perplexity: 13.9415Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2278/6471], Loss: 2.3212, Perplexity: 10.1875Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2279/6471], Loss: 2.2649, Perplexity: 9.6302Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2280/6471], Loss: 2.4926, Perplexity: 12.0927Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2281/6471], Loss: 2.8434, Perplexity: 17.1747Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2282/6471], Loss: 2.2412, Perplexity: 9.4049Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2283/6471], Loss: 2.3643, Perplexity: 10.6370Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2284/6471], Loss: 2.4533, Perplexity: 11.6263Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2285/6471], Loss: 2.4473, Perplexity: 11.5570Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2286/6471], Loss: 2.3333, Perplexity: 10.3123Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2287/6471], Loss: 2.4655, Perplexity: 11.7688Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2288/6471], Loss: 2.4662, Perplexity: 11.7781Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2289/6471], Loss: 2.4537, Perplexity: 11.6313Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2290/6471], Loss: 2.7091, Perplexity: 15.0155Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2291/6471], Loss: 2.2429, Perplexity: 9.4207Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2292/6471], Loss: 2.2928, Perplexity: 9.9022Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2293/6471], Loss: 2.5066, Perplexity: 12.2630Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2294/6471], Loss: 2.6015, Perplexity: 13.4843Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2295/6471], Loss: 2.3511, Perplexity: 10.4975Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2296/6471], Loss: 2.8093, Perplexity: 16.5979Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2297/6471], Loss: 2.4057, Perplexity: 11.0864Shape of captions\n",
      "torch.Size([64, 22, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 23, 256])\n",
      "Epoch [1/3], Step [2298/6471], Loss: 3.3671, Perplexity: 28.9935Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2299/6471], Loss: 2.3871, Perplexity: 10.8823Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2300/6471], Loss: 2.2998, Perplexity: 9.9720\n",
      "Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2301/6471], Loss: 2.6767, Perplexity: 14.5364Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2302/6471], Loss: 2.4690, Perplexity: 11.8104Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2303/6471], Loss: 3.0773, Perplexity: 21.6988Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2304/6471], Loss: 2.4229, Perplexity: 11.2789Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2305/6471], Loss: 2.3353, Perplexity: 10.3329Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2306/6471], Loss: 2.7443, Perplexity: 15.5538Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2307/6471], Loss: 2.4887, Perplexity: 12.0450Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2308/6471], Loss: 2.4472, Perplexity: 11.5555Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2309/6471], Loss: 2.3488, Perplexity: 10.4733Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2310/6471], Loss: 2.2414, Perplexity: 9.4067Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2311/6471], Loss: 2.3974, Perplexity: 10.9951Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2312/6471], Loss: 2.3693, Perplexity: 10.6901Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2313/6471], Loss: 2.3246, Perplexity: 10.2228Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2314/6471], Loss: 3.0507, Perplexity: 21.1307Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2315/6471], Loss: 2.7506, Perplexity: 15.6525Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2316/6471], Loss: 2.3054, Perplexity: 10.0281Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2317/6471], Loss: 2.3037, Perplexity: 10.0116Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2318/6471], Loss: 2.3731, Perplexity: 10.7301Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2319/6471], Loss: 2.5223, Perplexity: 12.4574Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2320/6471], Loss: 3.0990, Perplexity: 22.1754Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2321/6471], Loss: 2.3812, Perplexity: 10.8181Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2322/6471], Loss: 2.2745, Perplexity: 9.7226Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2323/6471], Loss: 2.5104, Perplexity: 12.3096Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2324/6471], Loss: 2.4177, Perplexity: 11.2205Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2325/6471], Loss: 2.4006, Perplexity: 11.0296Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2326/6471], Loss: 2.5355, Perplexity: 12.6232Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2327/6471], Loss: 2.4841, Perplexity: 11.9898Shape of captions\n",
      "torch.Size([64, 21, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 22, 256])\n",
      "Epoch [1/3], Step [2328/6471], Loss: 3.1908, Perplexity: 24.3082Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2329/6471], Loss: 2.3892, Perplexity: 10.9043Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2330/6471], Loss: 2.5416, Perplexity: 12.7000Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2331/6471], Loss: 2.4672, Perplexity: 11.7898Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2332/6471], Loss: 2.1350, Perplexity: 8.4568Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2333/6471], Loss: 2.5133, Perplexity: 12.3459Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2334/6471], Loss: 2.3109, Perplexity: 10.0831Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2335/6471], Loss: 2.5009, Perplexity: 12.1936Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2336/6471], Loss: 2.1041, Perplexity: 8.1996Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2337/6471], Loss: 3.0774, Perplexity: 21.7029Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2338/6471], Loss: 2.2405, Perplexity: 9.3978Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2339/6471], Loss: 2.5939, Perplexity: 13.3815Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2340/6471], Loss: 2.2838, Perplexity: 9.8134Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2341/6471], Loss: 2.4213, Perplexity: 11.2605Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2342/6471], Loss: 2.7839, Perplexity: 16.1823Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2343/6471], Loss: 2.4502, Perplexity: 11.5908Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2344/6471], Loss: 2.9141, Perplexity: 18.4329Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2345/6471], Loss: 2.2142, Perplexity: 9.1539Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2346/6471], Loss: 2.7774, Perplexity: 16.0771Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2347/6471], Loss: 2.1469, Perplexity: 8.5579Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2348/6471], Loss: 2.6321, Perplexity: 13.9035Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2349/6471], Loss: 2.3734, Perplexity: 10.7340Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2350/6471], Loss: 2.7923, Perplexity: 16.3177Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2351/6471], Loss: 2.4324, Perplexity: 11.3861Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2352/6471], Loss: 2.3173, Perplexity: 10.1478Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2353/6471], Loss: 2.5343, Perplexity: 12.6077Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2354/6471], Loss: 2.3925, Perplexity: 10.9406Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2355/6471], Loss: 2.4487, Perplexity: 11.5729Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2356/6471], Loss: 2.4383, Perplexity: 11.4536Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2357/6471], Loss: 2.3796, Perplexity: 10.8003Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2358/6471], Loss: 2.3133, Perplexity: 10.1081Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2359/6471], Loss: 2.4184, Perplexity: 11.2280Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2360/6471], Loss: 2.3899, Perplexity: 10.9125Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2361/6471], Loss: 2.3716, Perplexity: 10.7146Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2362/6471], Loss: 2.4225, Perplexity: 11.2743Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2363/6471], Loss: 2.3619, Perplexity: 10.6112Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2364/6471], Loss: 2.5051, Perplexity: 12.2446Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2365/6471], Loss: 2.9967, Perplexity: 20.0184Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2366/6471], Loss: 2.4156, Perplexity: 11.1970Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2367/6471], Loss: 2.4202, Perplexity: 11.2479Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2368/6471], Loss: 2.4734, Perplexity: 11.8626Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2369/6471], Loss: 2.5803, Perplexity: 13.2015Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2370/6471], Loss: 2.4357, Perplexity: 11.4240Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2371/6471], Loss: 2.3479, Perplexity: 10.4631Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2372/6471], Loss: 2.4064, Perplexity: 11.0944Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2373/6471], Loss: 2.2379, Perplexity: 9.3733Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2374/6471], Loss: 2.2570, Perplexity: 9.5546Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2375/6471], Loss: 2.5938, Perplexity: 13.3808Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2376/6471], Loss: 2.3040, Perplexity: 10.0146Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2377/6471], Loss: 2.7285, Perplexity: 15.3097Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2378/6471], Loss: 2.4118, Perplexity: 11.1540Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2379/6471], Loss: 2.3965, Perplexity: 10.9851Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2380/6471], Loss: 2.3260, Perplexity: 10.2372Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2381/6471], Loss: 2.7437, Perplexity: 15.5450Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2382/6471], Loss: 2.3023, Perplexity: 9.9974Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2383/6471], Loss: 2.5021, Perplexity: 12.2078Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2384/6471], Loss: 2.8527, Perplexity: 17.3345Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2385/6471], Loss: 2.4683, Perplexity: 11.8028Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2386/6471], Loss: 2.2403, Perplexity: 9.3964Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2387/6471], Loss: 2.3792, Perplexity: 10.7963Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2388/6471], Loss: 2.4044, Perplexity: 11.0714Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2389/6471], Loss: 2.3228, Perplexity: 10.2044Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2390/6471], Loss: 2.6021, Perplexity: 13.4919Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2391/6471], Loss: 2.4745, Perplexity: 11.8755Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2392/6471], Loss: 2.4855, Perplexity: 12.0067Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2393/6471], Loss: 2.2013, Perplexity: 9.0364Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2394/6471], Loss: 2.3361, Perplexity: 10.3406Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2395/6471], Loss: 2.8627, Perplexity: 17.5084Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2396/6471], Loss: 2.7360, Perplexity: 15.4245Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2397/6471], Loss: 2.4773, Perplexity: 11.9094Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2398/6471], Loss: 2.4872, Perplexity: 12.0277Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2399/6471], Loss: 2.2640, Perplexity: 9.6215Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2400/6471], Loss: 2.3239, Perplexity: 10.2159\n",
      "Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2401/6471], Loss: 2.3846, Perplexity: 10.8549Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2402/6471], Loss: 2.1455, Perplexity: 8.5462Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2403/6471], Loss: 2.4379, Perplexity: 11.4485Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2404/6471], Loss: 2.3802, Perplexity: 10.8074Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2405/6471], Loss: 2.2697, Perplexity: 9.6769Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2406/6471], Loss: 2.4546, Perplexity: 11.6422Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2407/6471], Loss: 2.9256, Perplexity: 18.6452Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2408/6471], Loss: 2.1704, Perplexity: 8.7621Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2409/6471], Loss: 2.2182, Perplexity: 9.1904Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2410/6471], Loss: 2.7914, Perplexity: 16.3032Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2411/6471], Loss: 2.4226, Perplexity: 11.2748Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2412/6471], Loss: 2.4418, Perplexity: 11.4936Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2413/6471], Loss: 2.8454, Perplexity: 17.2090Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2414/6471], Loss: 2.7406, Perplexity: 15.4959Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2415/6471], Loss: 2.4139, Perplexity: 11.1777Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2416/6471], Loss: 2.4021, Perplexity: 11.0460Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2417/6471], Loss: 2.4395, Perplexity: 11.4667Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2418/6471], Loss: 2.3351, Perplexity: 10.3300Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2419/6471], Loss: 2.7420, Perplexity: 15.5186Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2420/6471], Loss: 2.2213, Perplexity: 9.2189Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2421/6471], Loss: 2.4416, Perplexity: 11.4916Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2422/6471], Loss: 2.5626, Perplexity: 12.9695Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2423/6471], Loss: 2.5824, Perplexity: 13.2293Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2424/6471], Loss: 2.3406, Perplexity: 10.3877Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2425/6471], Loss: 2.4307, Perplexity: 11.3669Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2426/6471], Loss: 2.4226, Perplexity: 11.2754Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2427/6471], Loss: 2.2327, Perplexity: 9.3249Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2428/6471], Loss: 2.4550, Perplexity: 11.6462Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2429/6471], Loss: 2.4860, Perplexity: 12.0126Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2430/6471], Loss: 2.5301, Perplexity: 12.5545Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2431/6471], Loss: 2.7335, Perplexity: 15.3863Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2432/6471], Loss: 2.3053, Perplexity: 10.0272Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2433/6471], Loss: 2.3802, Perplexity: 10.8072Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2434/6471], Loss: 2.2180, Perplexity: 9.1893Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2435/6471], Loss: 2.8818, Perplexity: 17.8467Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2436/6471], Loss: 2.2439, Perplexity: 9.4303Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2437/6471], Loss: 2.3947, Perplexity: 10.9649Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2438/6471], Loss: 2.7338, Perplexity: 15.3906Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2439/6471], Loss: 2.4461, Perplexity: 11.5427Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2440/6471], Loss: 2.3077, Perplexity: 10.0516Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2441/6471], Loss: 2.7926, Perplexity: 16.3236Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2442/6471], Loss: 2.0615, Perplexity: 7.8578Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2443/6471], Loss: 2.5939, Perplexity: 13.3814Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2444/6471], Loss: 2.3683, Perplexity: 10.6791Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2445/6471], Loss: 2.2788, Perplexity: 9.7653Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2446/6471], Loss: 2.6649, Perplexity: 14.3659Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2447/6471], Loss: 2.5285, Perplexity: 12.5349Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2448/6471], Loss: 2.4545, Perplexity: 11.6410Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2449/6471], Loss: 2.2648, Perplexity: 9.6294Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2450/6471], Loss: 2.3434, Perplexity: 10.4163Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2451/6471], Loss: 2.5599, Perplexity: 12.9349Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2452/6471], Loss: 2.6627, Perplexity: 14.3342Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2453/6471], Loss: 2.8494, Perplexity: 17.2776Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2454/6471], Loss: 2.4011, Perplexity: 11.0354Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2455/6471], Loss: 2.3407, Perplexity: 10.3880Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2456/6471], Loss: 2.3456, Perplexity: 10.4397Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2457/6471], Loss: 2.4571, Perplexity: 11.6711Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2458/6471], Loss: 2.3306, Perplexity: 10.2838Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2459/6471], Loss: 2.4342, Perplexity: 11.4064Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2460/6471], Loss: 2.5309, Perplexity: 12.5650Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2461/6471], Loss: 2.5508, Perplexity: 12.8175Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2462/6471], Loss: 2.4227, Perplexity: 11.2763Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2463/6471], Loss: 2.7024, Perplexity: 14.9154Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2464/6471], Loss: 2.4661, Perplexity: 11.7766Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2465/6471], Loss: 2.3604, Perplexity: 10.5956Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2466/6471], Loss: 2.2941, Perplexity: 9.9158Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2467/6471], Loss: 2.8724, Perplexity: 17.6799Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2468/6471], Loss: 2.4027, Perplexity: 11.0530Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2469/6471], Loss: 2.8080, Perplexity: 16.5765Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2470/6471], Loss: 2.5715, Perplexity: 13.0850Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2471/6471], Loss: 2.4494, Perplexity: 11.5815Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2472/6471], Loss: 2.4678, Perplexity: 11.7965Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2473/6471], Loss: 2.3774, Perplexity: 10.7768Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [2474/6471], Loss: 3.2289, Perplexity: 25.2526Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2475/6471], Loss: 2.3619, Perplexity: 10.6108Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2476/6471], Loss: 2.4110, Perplexity: 11.1448Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2477/6471], Loss: 2.5027, Perplexity: 12.2150Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2478/6471], Loss: 2.7863, Perplexity: 16.2216Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2479/6471], Loss: 2.5633, Perplexity: 12.9782Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2480/6471], Loss: 2.5759, Perplexity: 13.1434Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2481/6471], Loss: 2.8875, Perplexity: 17.9492Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2482/6471], Loss: 2.4421, Perplexity: 11.4970Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2483/6471], Loss: 2.7539, Perplexity: 15.7045Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2484/6471], Loss: 2.2163, Perplexity: 9.1736Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2485/6471], Loss: 2.5609, Perplexity: 12.9479Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2486/6471], Loss: 2.3832, Perplexity: 10.8394Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2487/6471], Loss: 2.5640, Perplexity: 12.9878Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2488/6471], Loss: 2.8673, Perplexity: 17.5900Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2489/6471], Loss: 2.4342, Perplexity: 11.4062Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2490/6471], Loss: 2.3675, Perplexity: 10.6712Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2491/6471], Loss: 2.3144, Perplexity: 10.1184Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2492/6471], Loss: 2.5420, Perplexity: 12.7047Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2493/6471], Loss: 2.8908, Perplexity: 18.0068Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2494/6471], Loss: 2.3643, Perplexity: 10.6367Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2495/6471], Loss: 2.4283, Perplexity: 11.3399Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2496/6471], Loss: 2.2166, Perplexity: 9.1757Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2497/6471], Loss: 2.4379, Perplexity: 11.4491Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2498/6471], Loss: 2.3409, Perplexity: 10.3903Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2499/6471], Loss: 2.4409, Perplexity: 11.4829Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2500/6471], Loss: 2.4209, Perplexity: 11.2564\n",
      "Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2501/6471], Loss: 2.1850, Perplexity: 8.8904Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2502/6471], Loss: 2.4064, Perplexity: 11.0939Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2503/6471], Loss: 2.3999, Perplexity: 11.0223Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2504/6471], Loss: 2.4206, Perplexity: 11.2523Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2505/6471], Loss: 2.5755, Perplexity: 13.1375Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2506/6471], Loss: 2.3542, Perplexity: 10.5302Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2507/6471], Loss: 2.3690, Perplexity: 10.6867Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2508/6471], Loss: 2.2677, Perplexity: 9.6574Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2509/6471], Loss: 2.3253, Perplexity: 10.2295Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2510/6471], Loss: 2.3005, Perplexity: 9.9792Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2511/6471], Loss: 2.3203, Perplexity: 10.1784Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2512/6471], Loss: 2.2855, Perplexity: 9.8306Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2513/6471], Loss: 2.6597, Perplexity: 14.2926Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2514/6471], Loss: 2.1169, Perplexity: 8.3054Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2515/6471], Loss: 2.2168, Perplexity: 9.1782Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2516/6471], Loss: 2.3069, Perplexity: 10.0429Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2517/6471], Loss: 2.3272, Perplexity: 10.2497Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2518/6471], Loss: 2.4159, Perplexity: 11.1996Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2519/6471], Loss: 2.6319, Perplexity: 13.8999Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2520/6471], Loss: 2.2809, Perplexity: 9.7854Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2521/6471], Loss: 2.3956, Perplexity: 10.9744Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2522/6471], Loss: 2.2114, Perplexity: 9.1284Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [2523/6471], Loss: 3.0650, Perplexity: 21.4350Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2524/6471], Loss: 2.6834, Perplexity: 14.6344Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2525/6471], Loss: 2.6314, Perplexity: 13.8930Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2526/6471], Loss: 2.1140, Perplexity: 8.2811Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2527/6471], Loss: 2.2693, Perplexity: 9.6726Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2528/6471], Loss: 2.2669, Perplexity: 9.6498Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2529/6471], Loss: 2.5132, Perplexity: 12.3440Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2530/6471], Loss: 2.9023, Perplexity: 18.2157Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2531/6471], Loss: 2.1083, Perplexity: 8.2343Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2532/6471], Loss: 2.4075, Perplexity: 11.1059Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2533/6471], Loss: 2.6874, Perplexity: 14.6938Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2534/6471], Loss: 2.6427, Perplexity: 14.0513Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2535/6471], Loss: 2.4295, Perplexity: 11.3532Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2536/6471], Loss: 2.3502, Perplexity: 10.4879Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2537/6471], Loss: 2.7648, Perplexity: 15.8758Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2538/6471], Loss: 2.4292, Perplexity: 11.3500Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2539/6471], Loss: 2.2302, Perplexity: 9.3022Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2540/6471], Loss: 2.1917, Perplexity: 8.9508Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2541/6471], Loss: 2.5657, Perplexity: 13.0098Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2542/6471], Loss: 2.7280, Perplexity: 15.3030Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2543/6471], Loss: 2.4008, Perplexity: 11.0320Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2544/6471], Loss: 2.5145, Perplexity: 12.3599Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2545/6471], Loss: 2.5763, Perplexity: 13.1482Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2546/6471], Loss: 2.4315, Perplexity: 11.3758Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2547/6471], Loss: 2.1188, Perplexity: 8.3214Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2548/6471], Loss: 2.4882, Perplexity: 12.0400Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2549/6471], Loss: 2.9179, Perplexity: 18.5021Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2550/6471], Loss: 2.4195, Perplexity: 11.2399Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2551/6471], Loss: 2.4414, Perplexity: 11.4896Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2552/6471], Loss: 2.8982, Perplexity: 18.1408Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2553/6471], Loss: 2.2960, Perplexity: 9.9345Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2554/6471], Loss: 2.3147, Perplexity: 10.1221Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2555/6471], Loss: 2.5063, Perplexity: 12.2591Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2556/6471], Loss: 2.2766, Perplexity: 9.7439Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2557/6471], Loss: 2.6808, Perplexity: 14.5974Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2558/6471], Loss: 2.4304, Perplexity: 11.3629Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2559/6471], Loss: 2.7285, Perplexity: 15.3093Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2560/6471], Loss: 2.3110, Perplexity: 10.0844Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2561/6471], Loss: 2.3517, Perplexity: 10.5029Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2562/6471], Loss: 2.2556, Perplexity: 9.5411Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2563/6471], Loss: 2.4128, Perplexity: 11.1649Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2564/6471], Loss: 2.5167, Perplexity: 12.3878Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2565/6471], Loss: 2.2633, Perplexity: 9.6148Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2566/6471], Loss: 2.7611, Perplexity: 15.8176Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2567/6471], Loss: 2.5313, Perplexity: 12.5693Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2568/6471], Loss: 2.1311, Perplexity: 8.4238Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2569/6471], Loss: 2.4618, Perplexity: 11.7263Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2570/6471], Loss: 2.4140, Perplexity: 11.1791Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2571/6471], Loss: 2.3564, Perplexity: 10.5529Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2572/6471], Loss: 2.2576, Perplexity: 9.5603Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2573/6471], Loss: 2.2167, Perplexity: 9.1766Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2574/6471], Loss: 2.4015, Perplexity: 11.0402Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2575/6471], Loss: 2.2696, Perplexity: 9.6752Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2576/6471], Loss: 2.4095, Perplexity: 11.1279Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2577/6471], Loss: 2.2558, Perplexity: 9.5432Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2578/6471], Loss: 2.5273, Perplexity: 12.5192Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2579/6471], Loss: 2.4493, Perplexity: 11.5804Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2580/6471], Loss: 2.6994, Perplexity: 14.8712Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2581/6471], Loss: 2.3235, Perplexity: 10.2113Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2582/6471], Loss: 2.3094, Perplexity: 10.0687Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2583/6471], Loss: 2.4172, Perplexity: 11.2143Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2584/6471], Loss: 2.3693, Perplexity: 10.6901Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2585/6471], Loss: 2.1313, Perplexity: 8.4260Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2586/6471], Loss: 2.2735, Perplexity: 9.7135Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2587/6471], Loss: 2.5439, Perplexity: 12.7286Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2588/6471], Loss: 2.2105, Perplexity: 9.1202Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2589/6471], Loss: 2.2532, Perplexity: 9.5183Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2590/6471], Loss: 2.3144, Perplexity: 10.1193Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2591/6471], Loss: 2.5322, Perplexity: 12.5808Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2592/6471], Loss: 2.3826, Perplexity: 10.8329Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2593/6471], Loss: 2.2912, Perplexity: 9.8868Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2594/6471], Loss: 2.3257, Perplexity: 10.2340Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2595/6471], Loss: 2.2786, Perplexity: 9.7631Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2596/6471], Loss: 2.2825, Perplexity: 9.8010Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2597/6471], Loss: 2.3744, Perplexity: 10.7443Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2598/6471], Loss: 2.3321, Perplexity: 10.2998Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2599/6471], Loss: 2.3233, Perplexity: 10.2092Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2600/6471], Loss: 2.4115, Perplexity: 11.1502\n",
      "Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2601/6471], Loss: 2.1239, Perplexity: 8.3635Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2602/6471], Loss: 2.5650, Perplexity: 13.0011Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2603/6471], Loss: 2.3351, Perplexity: 10.3304Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2604/6471], Loss: 2.1461, Perplexity: 8.5512Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2605/6471], Loss: 2.3806, Perplexity: 10.8118Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2606/6471], Loss: 2.4528, Perplexity: 11.6213Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2607/6471], Loss: 2.4246, Perplexity: 11.2980Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2608/6471], Loss: 2.6154, Perplexity: 13.6733Shape of captions\n",
      "torch.Size([64, 21, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 22, 256])\n",
      "Epoch [1/3], Step [2609/6471], Loss: 3.3512, Perplexity: 28.5375Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2610/6471], Loss: 2.4846, Perplexity: 11.9967Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2611/6471], Loss: 2.4005, Perplexity: 11.0291Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2612/6471], Loss: 2.6992, Perplexity: 14.8683Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2613/6471], Loss: 2.4009, Perplexity: 11.0336Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2614/6471], Loss: 2.4949, Perplexity: 12.1208Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2615/6471], Loss: 2.5242, Perplexity: 12.4810Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2616/6471], Loss: 2.3513, Perplexity: 10.4987Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2617/6471], Loss: 2.1395, Perplexity: 8.4953Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2618/6471], Loss: 2.5457, Perplexity: 12.7516Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2619/6471], Loss: 2.3235, Perplexity: 10.2113Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2620/6471], Loss: 2.7271, Perplexity: 15.2891Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2621/6471], Loss: 2.3439, Perplexity: 10.4217Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2622/6471], Loss: 2.6977, Perplexity: 14.8457Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2623/6471], Loss: 2.2963, Perplexity: 9.9378Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2624/6471], Loss: 2.3822, Perplexity: 10.8283Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2625/6471], Loss: 2.4565, Perplexity: 11.6639Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2626/6471], Loss: 2.4215, Perplexity: 11.2625Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2627/6471], Loss: 2.2997, Perplexity: 9.9716Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2628/6471], Loss: 2.6695, Perplexity: 14.4331Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2629/6471], Loss: 2.2802, Perplexity: 9.7783Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2630/6471], Loss: 2.1948, Perplexity: 8.9779Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2631/6471], Loss: 2.7043, Perplexity: 14.9443Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2632/6471], Loss: 2.3002, Perplexity: 9.9759Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2633/6471], Loss: 2.3013, Perplexity: 9.9871Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2634/6471], Loss: 2.4593, Perplexity: 11.6967Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2635/6471], Loss: 2.3691, Perplexity: 10.6875Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2636/6471], Loss: 2.2429, Perplexity: 9.4206Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2637/6471], Loss: 2.4173, Perplexity: 11.2152Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [2638/6471], Loss: 3.0453, Perplexity: 21.0160Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2639/6471], Loss: 2.3778, Perplexity: 10.7814Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2640/6471], Loss: 2.1503, Perplexity: 8.5875Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2641/6471], Loss: 2.6645, Perplexity: 14.3611Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2642/6471], Loss: 2.8424, Perplexity: 17.1577Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2643/6471], Loss: 2.4776, Perplexity: 11.9131Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2644/6471], Loss: 2.3627, Perplexity: 10.6191Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2645/6471], Loss: 2.5572, Perplexity: 12.8997Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2646/6471], Loss: 2.3747, Perplexity: 10.7476Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2647/6471], Loss: 2.2152, Perplexity: 9.1629Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2648/6471], Loss: 2.6148, Perplexity: 13.6642Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2649/6471], Loss: 2.4650, Perplexity: 11.7639Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2650/6471], Loss: 2.5187, Perplexity: 12.4125Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2651/6471], Loss: 2.5103, Perplexity: 12.3086Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2652/6471], Loss: 2.3986, Perplexity: 11.0074Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2653/6471], Loss: 2.3800, Perplexity: 10.8049Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2654/6471], Loss: 2.3581, Perplexity: 10.5708Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2655/6471], Loss: 2.6467, Perplexity: 14.1071Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2656/6471], Loss: 2.3395, Perplexity: 10.3762Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2657/6471], Loss: 2.4693, Perplexity: 11.8139Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2658/6471], Loss: 2.4227, Perplexity: 11.2762Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2659/6471], Loss: 2.1172, Perplexity: 8.3081Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2660/6471], Loss: 2.3262, Perplexity: 10.2391Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2661/6471], Loss: 2.4091, Perplexity: 11.1244Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2662/6471], Loss: 2.2146, Perplexity: 9.1581Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2663/6471], Loss: 2.2109, Perplexity: 9.1239Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2664/6471], Loss: 2.3299, Perplexity: 10.2767Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2665/6471], Loss: 2.3106, Perplexity: 10.0806Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2666/6471], Loss: 2.5064, Perplexity: 12.2603Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2667/6471], Loss: 2.3017, Perplexity: 9.9915Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2668/6471], Loss: 2.6239, Perplexity: 13.7900Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2669/6471], Loss: 2.2721, Perplexity: 9.7002Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2670/6471], Loss: 2.2747, Perplexity: 9.7246Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2671/6471], Loss: 2.4437, Perplexity: 11.5152Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2672/6471], Loss: 2.4088, Perplexity: 11.1204Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2673/6471], Loss: 2.4247, Perplexity: 11.2986Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2674/6471], Loss: 2.8499, Perplexity: 17.2855Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2675/6471], Loss: 2.3159, Perplexity: 10.1343Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2676/6471], Loss: 2.2637, Perplexity: 9.6185Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2677/6471], Loss: 2.9986, Perplexity: 20.0566Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2678/6471], Loss: 2.5780, Perplexity: 13.1704Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2679/6471], Loss: 2.3280, Perplexity: 10.2578Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2680/6471], Loss: 2.4230, Perplexity: 11.2802Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2681/6471], Loss: 2.3386, Perplexity: 10.3663Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2682/6471], Loss: 2.6314, Perplexity: 13.8930Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2683/6471], Loss: 2.4599, Perplexity: 11.7042Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2684/6471], Loss: 2.5316, Perplexity: 12.5735Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2685/6471], Loss: 2.2975, Perplexity: 9.9489Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2686/6471], Loss: 2.4118, Perplexity: 11.1540Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2687/6471], Loss: 2.1573, Perplexity: 8.6476Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2688/6471], Loss: 2.3796, Perplexity: 10.8006Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2689/6471], Loss: 2.3057, Perplexity: 10.0314Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2690/6471], Loss: 2.4897, Perplexity: 12.0582Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2691/6471], Loss: 2.3995, Perplexity: 11.0177Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2692/6471], Loss: 2.1830, Perplexity: 8.8727Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2693/6471], Loss: 2.3422, Perplexity: 10.4041Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [2694/6471], Loss: 2.9316, Perplexity: 18.7573Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2695/6471], Loss: 2.4370, Perplexity: 11.4382Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2696/6471], Loss: 2.2720, Perplexity: 9.6992Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2697/6471], Loss: 2.2093, Perplexity: 9.1095Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2698/6471], Loss: 2.4059, Perplexity: 11.0884Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2699/6471], Loss: 2.5061, Perplexity: 12.2567Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2700/6471], Loss: 2.0975, Perplexity: 8.1457\n",
      "Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2701/6471], Loss: 2.1947, Perplexity: 8.9769Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2702/6471], Loss: 2.3412, Perplexity: 10.3934Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2703/6471], Loss: 2.4787, Perplexity: 11.9261Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2704/6471], Loss: 2.7952, Perplexity: 16.3654Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [2705/6471], Loss: 2.9073, Perplexity: 18.3075Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2706/6471], Loss: 2.3015, Perplexity: 9.9894Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2707/6471], Loss: 2.1820, Perplexity: 8.8639Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2708/6471], Loss: 2.4913, Perplexity: 12.0765Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2709/6471], Loss: 2.5595, Perplexity: 12.9295Shape of captions\n",
      "torch.Size([64, 36, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 37, 256])\n",
      "Epoch [1/3], Step [2710/6471], Loss: 4.0882, Perplexity: 59.6309Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2711/6471], Loss: 2.2541, Perplexity: 9.5267Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2712/6471], Loss: 2.2606, Perplexity: 9.5889Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2713/6471], Loss: 2.2183, Perplexity: 9.1921Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2714/6471], Loss: 2.4637, Perplexity: 11.7479Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2715/6471], Loss: 2.4007, Perplexity: 11.0311Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2716/6471], Loss: 2.3572, Perplexity: 10.5612Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2717/6471], Loss: 2.4494, Perplexity: 11.5808Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2718/6471], Loss: 2.3672, Perplexity: 10.6672Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2719/6471], Loss: 2.3696, Perplexity: 10.6935Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2720/6471], Loss: 2.2252, Perplexity: 9.2555Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2721/6471], Loss: 2.2890, Perplexity: 9.8655Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2722/6471], Loss: 2.2701, Perplexity: 9.6799Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2723/6471], Loss: 2.4171, Perplexity: 11.2128Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2724/6471], Loss: 2.2911, Perplexity: 9.8859Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2725/6471], Loss: 2.4494, Perplexity: 11.5816Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2726/6471], Loss: 2.3867, Perplexity: 10.8779Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2727/6471], Loss: 2.3618, Perplexity: 10.6103Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2728/6471], Loss: 2.3226, Perplexity: 10.2024Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2729/6471], Loss: 2.5727, Perplexity: 13.1009Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2730/6471], Loss: 2.4063, Perplexity: 11.0924Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2731/6471], Loss: 2.3432, Perplexity: 10.4148Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2732/6471], Loss: 2.2061, Perplexity: 9.0804Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2733/6471], Loss: 2.4257, Perplexity: 11.3105Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2734/6471], Loss: 2.1729, Perplexity: 8.7835Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2735/6471], Loss: 2.4937, Perplexity: 12.1062Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2736/6471], Loss: 2.3449, Perplexity: 10.4324Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2737/6471], Loss: 2.2807, Perplexity: 9.7831Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2738/6471], Loss: 2.2326, Perplexity: 9.3245Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2739/6471], Loss: 2.5299, Perplexity: 12.5520Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2740/6471], Loss: 2.2443, Perplexity: 9.4336Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2741/6471], Loss: 2.3946, Perplexity: 10.9639Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2742/6471], Loss: 2.4644, Perplexity: 11.7565Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2743/6471], Loss: 2.1037, Perplexity: 8.1966Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2744/6471], Loss: 2.4284, Perplexity: 11.3403Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2745/6471], Loss: 2.2010, Perplexity: 9.0337Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2746/6471], Loss: 2.5606, Perplexity: 12.9434Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2747/6471], Loss: 2.4074, Perplexity: 11.1045Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2748/6471], Loss: 2.3092, Perplexity: 10.0660Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2749/6471], Loss: 2.2744, Perplexity: 9.7217Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2750/6471], Loss: 2.2543, Perplexity: 9.5291Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2751/6471], Loss: 2.2683, Perplexity: 9.6634Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2752/6471], Loss: 2.2740, Perplexity: 9.7180Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2753/6471], Loss: 2.3406, Perplexity: 10.3873Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2754/6471], Loss: 2.4581, Perplexity: 11.6827Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2755/6471], Loss: 2.2886, Perplexity: 9.8608Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2756/6471], Loss: 2.4865, Perplexity: 12.0193Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2757/6471], Loss: 2.3375, Perplexity: 10.3550Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2758/6471], Loss: 2.5158, Perplexity: 12.3770Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2759/6471], Loss: 2.3554, Perplexity: 10.5425Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2760/6471], Loss: 2.2001, Perplexity: 9.0259Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2761/6471], Loss: 2.1760, Perplexity: 8.8110Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2762/6471], Loss: 2.3753, Perplexity: 10.7540Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2763/6471], Loss: 2.3208, Perplexity: 10.1839Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2764/6471], Loss: 2.1166, Perplexity: 8.3030Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2765/6471], Loss: 2.3737, Perplexity: 10.7370Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2766/6471], Loss: 2.2959, Perplexity: 9.9339Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2767/6471], Loss: 2.7415, Perplexity: 15.5098Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2768/6471], Loss: 2.6781, Perplexity: 14.5570Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2769/6471], Loss: 2.2896, Perplexity: 9.8712Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2770/6471], Loss: 2.6623, Perplexity: 14.3292Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2771/6471], Loss: 2.4298, Perplexity: 11.3568Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2772/6471], Loss: 2.3707, Perplexity: 10.7047Shape of captions\n",
      "torch.Size([64, 25, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 26, 256])\n",
      "Epoch [1/3], Step [2773/6471], Loss: 3.5520, Perplexity: 34.8847Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2774/6471], Loss: 1.9733, Perplexity: 7.1944Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2775/6471], Loss: 2.2167, Perplexity: 9.1768Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2776/6471], Loss: 2.6356, Perplexity: 13.9511Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2777/6471], Loss: 2.3621, Perplexity: 10.6136Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2778/6471], Loss: 2.2676, Perplexity: 9.6559Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2779/6471], Loss: 2.2868, Perplexity: 9.8432Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2780/6471], Loss: 2.4473, Perplexity: 11.5572Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2781/6471], Loss: 2.4428, Perplexity: 11.5047Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2782/6471], Loss: 2.4206, Perplexity: 11.2530Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2783/6471], Loss: 2.2970, Perplexity: 9.9443Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2784/6471], Loss: 2.5166, Perplexity: 12.3859Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2785/6471], Loss: 2.1510, Perplexity: 8.5932Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2786/6471], Loss: 2.3279, Perplexity: 10.2562Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2787/6471], Loss: 2.5049, Perplexity: 12.2422Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2788/6471], Loss: 2.2952, Perplexity: 9.9269Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2789/6471], Loss: 2.4693, Perplexity: 11.8144Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2790/6471], Loss: 2.3705, Perplexity: 10.7025Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2791/6471], Loss: 2.3493, Perplexity: 10.4785Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2792/6471], Loss: 2.1133, Perplexity: 8.2757Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2793/6471], Loss: 2.7515, Perplexity: 15.6660Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2794/6471], Loss: 2.5454, Perplexity: 12.7485Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2795/6471], Loss: 2.3788, Perplexity: 10.7919Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2796/6471], Loss: 2.2398, Perplexity: 9.3913Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2797/6471], Loss: 2.3257, Perplexity: 10.2335Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2798/6471], Loss: 2.3204, Perplexity: 10.1794Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2799/6471], Loss: 2.7016, Perplexity: 14.9040Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2800/6471], Loss: 2.4987, Perplexity: 12.1668\n",
      "Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2801/6471], Loss: 2.3155, Perplexity: 10.1299Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2802/6471], Loss: 2.2550, Perplexity: 9.5356Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2803/6471], Loss: 2.2505, Perplexity: 9.4923Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2804/6471], Loss: 2.4456, Perplexity: 11.5380Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2805/6471], Loss: 2.5087, Perplexity: 12.2890Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2806/6471], Loss: 2.4028, Perplexity: 11.0539Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2807/6471], Loss: 2.6531, Perplexity: 14.1981Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2808/6471], Loss: 2.2068, Perplexity: 9.0868Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2809/6471], Loss: 2.4885, Perplexity: 12.0431Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2810/6471], Loss: 2.2774, Perplexity: 9.7516Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2811/6471], Loss: 2.5810, Perplexity: 13.2100Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2812/6471], Loss: 2.2750, Perplexity: 9.7283Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2813/6471], Loss: 2.3006, Perplexity: 9.9799Shape of captions\n",
      "torch.Size([64, 20, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 21, 256])\n",
      "Epoch [1/3], Step [2814/6471], Loss: 3.0491, Perplexity: 21.0962Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2815/6471], Loss: 2.6370, Perplexity: 13.9706Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2816/6471], Loss: 2.4348, Perplexity: 11.4138Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2817/6471], Loss: 2.2855, Perplexity: 9.8307Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2818/6471], Loss: 2.4249, Perplexity: 11.3012Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2819/6471], Loss: 2.7030, Perplexity: 14.9246Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2820/6471], Loss: 2.2911, Perplexity: 9.8856Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2821/6471], Loss: 2.4365, Perplexity: 11.4334Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2822/6471], Loss: 2.4482, Perplexity: 11.5672Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2823/6471], Loss: 2.6316, Perplexity: 13.8965Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2824/6471], Loss: 2.2845, Perplexity: 9.8203Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2825/6471], Loss: 2.6078, Perplexity: 13.5687Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2826/6471], Loss: 2.3587, Perplexity: 10.5777Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2827/6471], Loss: 2.0517, Perplexity: 7.7810Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2828/6471], Loss: 2.3847, Perplexity: 10.8554Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2829/6471], Loss: 2.1649, Perplexity: 8.7139Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2830/6471], Loss: 2.3303, Perplexity: 10.2812Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2831/6471], Loss: 2.2540, Perplexity: 9.5257Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2832/6471], Loss: 2.3808, Perplexity: 10.8134Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2833/6471], Loss: 2.2185, Perplexity: 9.1933Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2834/6471], Loss: 2.2370, Perplexity: 9.3648Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2835/6471], Loss: 2.4624, Perplexity: 11.7329Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2836/6471], Loss: 2.3642, Perplexity: 10.6359Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2837/6471], Loss: 2.1636, Perplexity: 8.7025Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2838/6471], Loss: 2.6787, Perplexity: 14.5663Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2839/6471], Loss: 2.4218, Perplexity: 11.2661Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2840/6471], Loss: 2.3701, Perplexity: 10.6981Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2841/6471], Loss: 2.5244, Perplexity: 12.4834Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2842/6471], Loss: 2.4343, Perplexity: 11.4075Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2843/6471], Loss: 1.9690, Perplexity: 7.1632Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2844/6471], Loss: 2.4598, Perplexity: 11.7030Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2845/6471], Loss: 2.9301, Perplexity: 18.7290Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2846/6471], Loss: 2.1107, Perplexity: 8.2540Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2847/6471], Loss: 2.4730, Perplexity: 11.8582Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2848/6471], Loss: 2.4560, Perplexity: 11.6579Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2849/6471], Loss: 2.2001, Perplexity: 9.0260Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2850/6471], Loss: 2.2843, Perplexity: 9.8185Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2851/6471], Loss: 2.4666, Perplexity: 11.7820Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2852/6471], Loss: 2.3825, Perplexity: 10.8320Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2853/6471], Loss: 2.4455, Perplexity: 11.5363Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2854/6471], Loss: 2.8982, Perplexity: 18.1418Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2855/6471], Loss: 2.4571, Perplexity: 11.6704Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2856/6471], Loss: 2.3219, Perplexity: 10.1952Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2857/6471], Loss: 2.2108, Perplexity: 9.1226Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2858/6471], Loss: 2.4259, Perplexity: 11.3129Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2859/6471], Loss: 2.1821, Perplexity: 8.8650Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2860/6471], Loss: 2.4549, Perplexity: 11.6453Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2861/6471], Loss: 2.1768, Perplexity: 8.8181Shape of captions\n",
      "torch.Size([64, 31, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 32, 256])\n",
      "Epoch [1/3], Step [2862/6471], Loss: 4.0032, Perplexity: 54.7752Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2863/6471], Loss: 2.5214, Perplexity: 12.4462Shape of captions\n",
      "torch.Size([64, 21, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 22, 256])\n",
      "Epoch [1/3], Step [2864/6471], Loss: 3.1152, Perplexity: 22.5379Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2865/6471], Loss: 2.3185, Perplexity: 10.1606Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2866/6471], Loss: 2.1599, Perplexity: 8.6703Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2867/6471], Loss: 2.3552, Perplexity: 10.5402Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2868/6471], Loss: 2.3452, Perplexity: 10.4358Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2869/6471], Loss: 1.9937, Perplexity: 7.3424Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2870/6471], Loss: 2.2811, Perplexity: 9.7870Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2871/6471], Loss: 2.3475, Perplexity: 10.4593Shape of captions\n",
      "torch.Size([64, 19, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 20, 256])\n",
      "Epoch [1/3], Step [2872/6471], Loss: 3.0402, Perplexity: 20.9092Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2873/6471], Loss: 2.3131, Perplexity: 10.1062Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2874/6471], Loss: 2.3226, Perplexity: 10.2017Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2875/6471], Loss: 2.4455, Perplexity: 11.5359Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2876/6471], Loss: 2.1768, Perplexity: 8.8177Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2877/6471], Loss: 2.4060, Perplexity: 11.0891Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2878/6471], Loss: 2.4024, Perplexity: 11.0500Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2879/6471], Loss: 2.3447, Perplexity: 10.4304Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2880/6471], Loss: 2.4473, Perplexity: 11.5567Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2881/6471], Loss: 2.2011, Perplexity: 9.0350Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2882/6471], Loss: 2.1246, Perplexity: 8.3694Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2883/6471], Loss: 2.4281, Perplexity: 11.3370Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2884/6471], Loss: 2.5626, Perplexity: 12.9700Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2885/6471], Loss: 2.1843, Perplexity: 8.8848Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2886/6471], Loss: 2.2851, Perplexity: 9.8266Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2887/6471], Loss: 2.2744, Perplexity: 9.7218Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2888/6471], Loss: 2.5419, Perplexity: 12.7038Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2889/6471], Loss: 2.2408, Perplexity: 9.4004Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2890/6471], Loss: 2.3277, Perplexity: 10.2543Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2891/6471], Loss: 2.3710, Perplexity: 10.7078Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2892/6471], Loss: 2.6838, Perplexity: 14.6403Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2893/6471], Loss: 2.2747, Perplexity: 9.7255Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2894/6471], Loss: 2.2898, Perplexity: 9.8733Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2895/6471], Loss: 2.1282, Perplexity: 8.4000Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2896/6471], Loss: 2.6419, Perplexity: 14.0405Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2897/6471], Loss: 2.2730, Perplexity: 9.7088Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2898/6471], Loss: 2.3294, Perplexity: 10.2714Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2899/6471], Loss: 2.5106, Perplexity: 12.3123Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2900/6471], Loss: 2.3704, Perplexity: 10.7013\n",
      "Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2901/6471], Loss: 2.2575, Perplexity: 9.5592Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2902/6471], Loss: 2.2434, Perplexity: 9.4255Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2903/6471], Loss: 2.5609, Perplexity: 12.9479Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2904/6471], Loss: 2.5149, Perplexity: 12.3650Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2905/6471], Loss: 2.3954, Perplexity: 10.9728Shape of captions\n",
      "torch.Size([64, 8, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 9, 256])\n",
      "Epoch [1/3], Step [2906/6471], Loss: 2.6618, Perplexity: 14.3217Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2907/6471], Loss: 2.3702, Perplexity: 10.6993Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2908/6471], Loss: 2.2451, Perplexity: 9.4413Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2909/6471], Loss: 2.2432, Perplexity: 9.4232Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2910/6471], Loss: 2.3903, Perplexity: 10.9171Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2911/6471], Loss: 2.1981, Perplexity: 9.0077Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2912/6471], Loss: 2.2722, Perplexity: 9.7012Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2913/6471], Loss: 2.5325, Perplexity: 12.5849Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2914/6471], Loss: 2.2144, Perplexity: 9.1557Shape of captions\n",
      "torch.Size([64, 9, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 10, 256])\n",
      "Epoch [1/3], Step [2915/6471], Loss: 2.4546, Perplexity: 11.6417Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [2916/6471], Loss: 2.2321, Perplexity: 9.3192Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2917/6471], Loss: 2.4252, Perplexity: 11.3050Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2918/6471], Loss: 2.1903, Perplexity: 8.9377Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2919/6471], Loss: 2.4243, Perplexity: 11.2943Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2920/6471], Loss: 2.4338, Perplexity: 11.4022Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2921/6471], Loss: 2.4565, Perplexity: 11.6641Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2922/6471], Loss: 2.3740, Perplexity: 10.7407Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2923/6471], Loss: 2.2997, Perplexity: 9.9716Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2924/6471], Loss: 3.0530, Perplexity: 21.1788Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2925/6471], Loss: 2.5343, Perplexity: 12.6070Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2926/6471], Loss: 2.4015, Perplexity: 11.0399Shape of captions\n",
      "torch.Size([64, 14, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 15, 256])\n",
      "Epoch [1/3], Step [2927/6471], Loss: 2.4346, Perplexity: 11.4114Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2928/6471], Loss: 2.0214, Perplexity: 7.5487Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2929/6471], Loss: 2.4263, Perplexity: 11.3172Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2930/6471], Loss: 2.3668, Perplexity: 10.6631Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2931/6471], Loss: 2.2400, Perplexity: 9.3937Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2932/6471], Loss: 2.7403, Perplexity: 15.4914Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2933/6471], Loss: 2.1908, Perplexity: 8.9421Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2934/6471], Loss: 2.2838, Perplexity: 9.8138Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2935/6471], Loss: 2.4460, Perplexity: 11.5415Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2936/6471], Loss: 2.4052, Perplexity: 11.0809Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2937/6471], Loss: 2.1391, Perplexity: 8.4919Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2938/6471], Loss: 2.3024, Perplexity: 9.9977Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2939/6471], Loss: 2.2252, Perplexity: 9.2550Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2940/6471], Loss: 2.4643, Perplexity: 11.7558Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2941/6471], Loss: 2.2681, Perplexity: 9.6608Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2942/6471], Loss: 2.2664, Perplexity: 9.6449Shape of captions\n",
      "torch.Size([64, 15, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 16, 256])\n",
      "Epoch [1/3], Step [2943/6471], Loss: 2.3658, Perplexity: 10.6521Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2944/6471], Loss: 2.1449, Perplexity: 8.5409Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2945/6471], Loss: 2.2313, Perplexity: 9.3124Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2946/6471], Loss: 2.7887, Perplexity: 16.2597Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2947/6471], Loss: 2.2970, Perplexity: 9.9445Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2948/6471], Loss: 2.5026, Perplexity: 12.2136Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2949/6471], Loss: 2.2167, Perplexity: 9.1766Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2950/6471], Loss: 2.1801, Perplexity: 8.8473Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2951/6471], Loss: 2.4740, Perplexity: 11.8694Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2952/6471], Loss: 2.1154, Perplexity: 8.2928Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2953/6471], Loss: 2.2672, Perplexity: 9.6527Shape of captions\n",
      "torch.Size([64, 17, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 18, 256])\n",
      "Epoch [1/3], Step [2954/6471], Loss: 2.7599, Perplexity: 15.7979Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2955/6471], Loss: 2.2621, Perplexity: 9.6032Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2956/6471], Loss: 2.5028, Perplexity: 12.2172Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2957/6471], Loss: 2.3709, Perplexity: 10.7067Shape of captions\n",
      "torch.Size([64, 12, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 13, 256])\n",
      "Epoch [1/3], Step [2958/6471], Loss: 2.0146, Perplexity: 7.4979Shape of captions\n",
      "torch.Size([64, 18, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 19, 256])\n",
      "Epoch [1/3], Step [2959/6471], Loss: 2.7826, Perplexity: 16.1610Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2960/6471], Loss: 2.1174, Perplexity: 8.3096Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2961/6471], Loss: 2.4927, Perplexity: 12.0934Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2962/6471], Loss: 2.3222, Perplexity: 10.1986Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2963/6471], Loss: 2.4898, Perplexity: 12.0593Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2964/6471], Loss: 2.1854, Perplexity: 8.8940Shape of captions\n",
      "torch.Size([64, 13, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 14, 256])\n",
      "Epoch [1/3], Step [2965/6471], Loss: 2.2879, Perplexity: 9.8541Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2966/6471], Loss: 2.2628, Perplexity: 9.6104Shape of captions\n",
      "torch.Size([64, 10, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 11, 256])\n",
      "Epoch [1/3], Step [2967/6471], Loss: 2.3327, Perplexity: 10.3053Shape of captions\n",
      "torch.Size([64, 11, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 12, 256])\n",
      "Epoch [1/3], Step [2968/6471], Loss: 2.2087, Perplexity: 9.1040Shape of captions\n",
      "torch.Size([64, 16, 256])\n",
      "Shape of inputs\n",
      "torch.Size([64, 17, 256])\n",
      "Epoch [1/3], Step [2969/6471], Loss: 2.6565, Perplexity: 14.2462"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
